{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/ivan/distribution_connector')\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from connector_utils import test_models, gather_statistics, test_func\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from connector import Connector\n",
    "# from one_layer_utils import samples, make_dataset, get_model, get_b\n",
    "from utils import test_model\n",
    "from flows.models.utils import test_flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are going to run models on the test set. Are you sure?\n"
     ]
    }
   ],
   "source": [
    "import models\n",
    "architecture = getattr(models, \"LinearOneLayer\") #LinearOneLayer LogRegression\n",
    "\n",
    "import data\n",
    "loaders, num_classes = data.loaders(\n",
    "    \"MNIST\",\n",
    "    \"data\",\n",
    "    1024,\n",
    "    1,\n",
    "    \"VGG\",\n",
    "    True)\n",
    "\n",
    "model1 = architecture.base(num_classes=10, **architecture.kwargs)\n",
    "model2 = architecture.base(num_classes=10, **architecture.kwargs)\n",
    "\n",
    "model1.load_state_dict(torch.load('curves_mnist/LinearOneLayer/LongTraining/curve16/checkpoint-30.pt')['model_state'])\n",
    "model2.load_state_dict(torch.load('curves_mnist/LinearOneLayer/LongTraining/curve17/checkpoint-30.pt')['model_state'])\n",
    "\n",
    "import pickle\n",
    "data_path = '/home/ivan/dnn-mode-connectivity/data/MNIST.pickle'\n",
    "with open(data_path, 'rb') as handle:\n",
    "    dataset, B = pickle.load(handle)\n",
    "b2 = torch.FloatTensor([np.array(B).mean(0)])\n",
    "b = np.array(B).mean(0)\n",
    "\n",
    "train_dataset, test_dataset = dataset[:-8000], dataset[-8000:]\n",
    "modes = [dataset[-4000:-2000], dataset[-2000:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def samples(model):\n",
    "    p = [list(model.parameters())[i].data.cpu().numpy() for i in range(len(list(model.parameters())))]\n",
    "    return p\n",
    "\n",
    "def samples_per_layer(model, bias=True):\n",
    "    p = samples(model)\n",
    "    if bias:\n",
    "        p = [np.hstack([p[i], p[i+1][:, None]]) for i in range(0, len(p), 2)]        \n",
    "    return p\n",
    "\n",
    "def samples_butterfly(model, bias=True):\n",
    "    if bias:\n",
    "        return None\n",
    "    else:   \n",
    "        p = samples_per_layer(model, bias=bias)\n",
    "        parameters = [np.hstack([p[i], p[i+1].T]) for i in range(0, len(p), 2)]\n",
    "    return parameters\n",
    "\n",
    "def get_model(W, architecture, bias=False, per_layer=True):\n",
    "    model_sampled = architecture.base(num_classes=10, **architecture.kwargs)\n",
    "    model_samples = np.array(W)  \n",
    "\n",
    "    if per_layer:\n",
    "        for parameter, w in zip(model_sampled.parameters(), W):\n",
    "            parameter.data.copy_(torch.from_numpy(w))\n",
    "    else:\n",
    "        for i, parameter in enumerate(model_sampled.parameters()):\n",
    "            w = W[i//2]\n",
    "            if i % 2 == 0:\n",
    "                offset = 0\n",
    "            N = parameter.data.shape[1]\n",
    "            w_part = w[:, offset:offset+N]\n",
    "            offset = N\n",
    "            if i % 2 == 0:\n",
    "                parameter.data.copy_(torch.from_numpy(w_part))\n",
    "            else:\n",
    "                parameter.data.copy_(torch.from_numpy(w_part.T))\n",
    "            \n",
    "\n",
    "    return model_sampled\n",
    "\n",
    "def get_model(W, B, architecture):\n",
    "    model_sampled = architecture.base(num_classes=10, **architecture.kwargs)\n",
    "    model_samples = np.array(W)  # .cpu().data.numpy()\n",
    "    SIZE = model_sampled.middle_dim\n",
    "\n",
    "    offset = 0\n",
    "    for parameter in list(model_sampled.parameters())[:-1]:\n",
    "        size = int(np.prod(parameter.size()) / SIZE)\n",
    "        value = model_samples[:, offset:offset + size]\n",
    "        if size == 10 or size == 1:\n",
    "            value = value.T\n",
    "        value = value.reshape(parameter.size())\n",
    "        parameter.data.copy_(torch.from_numpy(value))\n",
    "        offset += size\n",
    "\n",
    "    list(model_sampled.parameters())[-1].data.copy_(B.mean(0))  # torch.from_numpy(\n",
    "\n",
    "    return model_sampled\n",
    "\n",
    "def samples(model):\n",
    "    p1 = list(model.parameters())[0].data.cpu().numpy()\n",
    "    p2 = list(model.parameters())[1].data.cpu().numpy()\n",
    "    p3 = list(model.parameters())[2].transpose(0, 1).data.cpu().numpy()\n",
    "    samples = np.hstack([p1, p2[:, None], p3])\n",
    "    return samples\n",
    "\n",
    "def transform(x1, x2, E12, E22_inv):\n",
    "#     print(x1.shape, x2.shape, E12.shape, E22_inv.shape)\n",
    "    y1 = x1 - E12 @ E22_inv @ x2\n",
    "    return np.concatenate([y1, x2]).T\n",
    "   \n",
    "def inv_transform(y1, y2, E12, E22_inv):\n",
    "#     print(x1.shape, x2.shape, E12.shape, E22_inv.shape)\n",
    "    x1 = y1 + E12 @ E22_inv @ y2\n",
    "    return np.concatenate([x1, y2]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters1 = samples(model1)\n",
    "parameters2 = samples(model2)\n",
    "\n",
    "parameters = np.concatenate([parameters1, parameters2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_simple(W1, W2, lines=True, func='arc_connect', mean=0, compute=True):\n",
    "    \n",
    "        \n",
    "    W1 = W1.T\n",
    "    W2 = W2.T\n",
    "    if compute:\n",
    "        W = np.vstack([W1, W2])\n",
    "        print('W', W.shape)\n",
    "        mean = W.mean(0)\n",
    "        \n",
    "    W1 -= mean\n",
    "    W2 -= mean  \n",
    "    W1 = W1.T\n",
    "    W2 = W2.T\n",
    "    \n",
    "    if lines:    \n",
    "        print('W1', W1.shape)\n",
    "        cntr = Connector(W1, W2)\n",
    "        f = getattr(cntr, func)\n",
    "        p_res = f()[1]\n",
    "    else:\n",
    "        print('W1', W1.T.shape)\n",
    "        cntr = Connector(W1.T, W2.T)\n",
    "        f = getattr(cntr, func)\n",
    "        p_res = f()[1].T\n",
    "    \n",
    "    p_res = p_res.T\n",
    "    p_res += mean\n",
    "    p_res = p_res.T\n",
    "    \n",
    "    return p_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "param1 = [parameters1[:, :-10].T, parameters1[:, -10:]]\n",
    "param2 = [parameters2[:, :-10].T, parameters2[:, -10:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((785, 2000), (2000, 10))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param1[0].shape, param1[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W (4000, 785)\n",
      "W1 (2000, 785)\n",
      "W1 (2000, 10)\n",
      "train results {'nll': 0.08186667322715123, 'loss': 0.08186667322715123, 'accuracy': 98.15166666666667}\n",
      "test results {'nll': 0.10232745043039322, 'loss': 0.10232745043039322, 'accuracy': 97.37}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'nll': 0.08186667322715123,\n",
       "  'loss': 0.08186667322715123,\n",
       "  'accuracy': 98.15166666666667},\n",
       " {'nll': 0.10232745043039322, 'loss': 0.10232745043039322, 'accuracy': 97.37})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pres = []\n",
    "pres.append(connect_simple(param1[0], param2[0], lines=False, func='arc_connect_PCA', compute=True))\n",
    "pres.append(connect_simple(param1[1], param2[1], lines=True, func='arc_connect_PCA',  compute=False))\n",
    "p_res = np.hstack([pres[0].T, pres[1]])\n",
    "model = get_model(p_res, b2, architecture)\n",
    "model.cuda();\n",
    "model.eval();\n",
    "test_model(model, loaders, cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "funcs = ['arc_connect']\n",
    "\n",
    "for func in funcs:\n",
    "    parameters_res = []\n",
    "    print(func)\n",
    "    for p1, p2 in zip(param1, param2):\n",
    "        cntr = Connector(p1, p2)\n",
    "        print(p1.shape)\n",
    "        f = getattr(cntr, func)\n",
    "        if 'PCA' in func:\n",
    "            K = min(300, p1.shape[0], p1.shape[1])\n",
    "            res = f(K=K)[1]\n",
    "        elif 'third_cumulant' in func:\n",
    "            K = min(100, p1.shape[0], p1.shape[1])\n",
    "            res = f(K=K)[1] \n",
    "        else:\n",
    "            res = f()[1]\n",
    "            \n",
    "        print('res', res.shape)\n",
    "        parameters_res.append(res)\n",
    "        \n",
    "    parameters_res = np.hstack([parameters_res[0].T, parameters_res[1]])\n",
    "    model = get_model(parameters_res, b2, architecture)\n",
    "    model.cuda();\n",
    "    model.eval();\n",
    "    test_model(model, loaders, cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arc_connect\n"
     ]
    }
   ],
   "source": [
    "func = 'arc_connect'\n",
    "print(func)\n",
    "cntr = Connector(parameters1_tr, parameters2_tr)\n",
    "f = getattr(cntr, func)\n",
    "parameters_res = f()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_res_tr = inv_transform(parameters_res[:, :-10].T, parameters_res[:, -10:].T, E12,  E22_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train results {'nll': 0.07982834839820861, 'loss': 0.07982834839820861, 'accuracy': 97.99666666666667}\n",
      "test results {'nll': 0.10293639920949936, 'loss': 0.10293639920949936, 'accuracy': 97.14}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'nll': 0.07982834839820861,\n",
       "  'loss': 0.07982834839820861,\n",
       "  'accuracy': 97.99666666666667},\n",
       " {'nll': 0.10293639920949936, 'loss': 0.10293639920949936, 'accuracy': 97.14})"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model(parameters_res_tr, b2, architecture)\n",
    "model.cuda();\n",
    "model.eval();\n",
    "test_model(model, loaders, cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters_res_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_new = parameters1[:3]+parameters2[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(param_new, architecture, per_layer=True)\n",
    "model.cuda();\n",
    "model.eval();\n",
    "test_model(model, loaders, cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for func in ['lin_connect', 'arc_connect', 'arc_connect_PCA']:\n",
    "    parameters_res = []\n",
    "    print(func)\n",
    "    for p1, p2 in zip(parameters1, parameters2):\n",
    "        cntr = Connector(p1, p2)\n",
    "        f = getattr(cntr, func)\n",
    "        if 'PCA' in func:\n",
    "            K = min(300, p1.shape[0], p1.shape[1])\n",
    "            res = f(K=K)[1]\n",
    "        elif 'third_cumulant' in func:\n",
    "            K = min(100, p1.shape[0], p1.shape[1])\n",
    "            res = f(K=K)[1] \n",
    "        else:\n",
    "            res = f()[1]\n",
    "        parameters_res.append(res)\n",
    "\n",
    "    model = get_model(parameters_res, architecture, per_layer=True)\n",
    "    model.cuda();\n",
    "    model.eval();\n",
    "    test_model(model, loaders, cuda=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "You are going to run models on the test set. Are you sure?\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import models\n",
    "architecture = getattr(models, \"LinearOneLayerCF\") #LinearOneLayer LogRegression\n",
    "\n",
    "import data\n",
    "loaders, num_classes = data.loaders(\n",
    "    \"CIFAR10\",\n",
    "    \"data\",\n",
    "    1024,\n",
    "    1,\n",
    "    \"VGG\",\n",
    "    False)\n",
    "\n",
    "model1 = architecture.base(num_classes=10, **architecture.kwargs)\n",
    "model2 = architecture.base(num_classes=10, **architecture.kwargs)\n",
    "\n",
    "model1.load_state_dict(torch.load('curves/LinearOneLayer/curve16/checkpoint-400.pt')['model_state'])\n",
    "model2.load_state_dict(torch.load('curves/LinearOneLayer/curve17/checkpoint-400.pt')['model_state'])\n",
    "\n",
    "import pickle\n",
    "data_path = '/home/ivan/dnn-mode-connectivity/data/CIFAR.pickle'\n",
    "with open(data_path, 'rb') as handle:\n",
    "    dataset, B = pickle.load(handle)\n",
    "b2 =  torch.FloatTensor([np.array(B).mean(0)])\n",
    "b = np.array(B).mean(0)\n",
    "\n",
    "train_dataset, test_dataset = dataset[:-8000], dataset[-8000:]\n",
    "modes = [dataset[-4000:-2000], dataset[-2000:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters1 = samples(model1)\n",
    "parameters2 = samples(model2)\n",
    "\n",
    "parameters = np.concatenate([parameters1, parameters2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "param1 = [parameters1[:, :-10].T, parameters1[:, -10:]]\n",
    "param2 = [parameters2[:, :-10].T, parameters2[:, -10:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 (2000, 3073)\n",
      "W1 (2000, 10)\n",
      "train results {'nll': 1.4840123331832886, 'loss': 1.4840123331832886, 'accuracy': 51.31}\n",
      "test results {'nll': 2.6923051845550536, 'loss': 2.6923051845550536, 'accuracy': 40.93}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'nll': 1.4840123331832886, 'loss': 1.4840123331832886, 'accuracy': 51.31},\n",
       " {'nll': 2.6923051845550536, 'loss': 2.6923051845550536, 'accuracy': 40.93})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pres = []\n",
    "pres.append(connect_simple(param1[0], param2[0], lines=False, func='arc_connect', compute=False))\n",
    "pres.append(connect_simple(param1[1], param2[1], lines=True, func='arc_connect',  compute=False))\n",
    "p_res = np.hstack([pres[0].T, pres[1]])\n",
    "model = get_model(p_res, b2, architecture)\n",
    "model.cuda();\n",
    "model.eval();\n",
    "test_model(model, loaders, cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lin_connect\n",
      "(2000, 3073)\n",
      "res (2000, 3073)\n",
      "(2000, 10)\n",
      "res (2000, 10)\n",
      "train results {'nll': 1.8912518212890626, 'loss': 1.8912518212890626, 'accuracy': 32.088}\n",
      "test results {'nll': 2.0686955657958985, 'loss': 2.0686955657958985, 'accuracy': 37.79}\n",
      "arc_connect\n",
      "(2000, 3073)\n",
      "res (2000, 3073)\n",
      "(2000, 10)\n",
      "res (2000, 10)\n",
      "train results {'nll': 1.4912290412139892, 'loss': 1.4912290412139892, 'accuracy': 50.816}\n",
      "test results {'nll': 2.6923051845550536, 'loss': 2.6923051845550536, 'accuracy': 40.93}\n",
      "arc_connect_PCA\n",
      "(2000, 3073)\n",
      "res (2000, 3073)\n",
      "(2000, 10)\n",
      "res (2000, 10)\n",
      "train results {'nll': 1.4851501541519165, 'loss': 1.4851501541519165, 'accuracy': 51.288}\n",
      "test results {'nll': 2.8195617031097413, 'loss': 2.8195617031097413, 'accuracy': 40.16}\n"
     ]
    }
   ],
   "source": [
    "param1 = [parameters1[:, :-10], parameters1[:, -10:]]\n",
    "param2 = [parameters2[:, :-10], parameters2[:, -10:]]\n",
    "\n",
    "for func in ['lin_connect', 'arc_connect', 'arc_connect_PCA']:\n",
    "    parameters_res = []\n",
    "    print(func)\n",
    "    for p1, p2 in zip(param1, param2):\n",
    "        cntr = Connector(p1, p2)\n",
    "        print(p1.shape)\n",
    "        f = getattr(cntr, func)\n",
    "        if 'PCA' in func:\n",
    "            K = min(300, p1.shape[0], p1.shape[1])\n",
    "            res = f(K=K)[1]\n",
    "        elif 'third_cumulant' in func:\n",
    "            K = min(100, p1.shape[0], p1.shape[1])\n",
    "            res = f(K=K)[1] \n",
    "        else:\n",
    "            res = f()[1]\n",
    "            \n",
    "        print('res', res.shape)\n",
    "        parameters_res.append(res)\n",
    "        \n",
    "    parameters_res = np.hstack([parameters_res[0], parameters_res[1]])\n",
    "    model = get_model(parameters_res, b2, architecture)\n",
    "    model.cuda();\n",
    "    model.eval();\n",
    "    test_model(model, loaders, cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lin_connect\n",
      "(3073, 2000)\n",
      "res (3073, 2000)\n",
      "(2000, 10)\n",
      "res (2000, 10)\n",
      "train results {'nll': 1.8950114845657349, 'loss': 1.8950114845657349, 'accuracy': 32.046}\n",
      "test results {'nll': 2.0686955657958985, 'loss': 2.0686955657958985, 'accuracy': 37.79}\n",
      "arc_connect\n",
      "(3073, 2000)\n",
      "res (3073, 2000)\n",
      "(2000, 10)\n",
      "res (2000, 10)\n",
      "train results {'nll': 1.6132043946456909, 'loss': 1.6132043946456909, 'accuracy': 43.942}\n",
      "test results {'nll': 2.6095668628692628, 'loss': 2.6095668628692628, 'accuracy': 41.38}\n",
      "arc_connect_PCA\n",
      "(3073, 2000)\n",
      "res (3073, 2000)\n",
      "(2000, 10)\n",
      "res (2000, 10)\n",
      "train results {'nll': 1.6867427646255493, 'loss': 1.6867427646255493, 'accuracy': 40.956}\n",
      "test results {'nll': 2.651808978652954, 'loss': 2.651808978652954, 'accuracy': 40.74}\n"
     ]
    }
   ],
   "source": [
    "param1 = [parameters1[:, :-10].T, parameters1[:, -10:]]\n",
    "param2 = [parameters2[:, :-10].T, parameters2[:, -10:]]\n",
    "\n",
    "for func in ['lin_connect', 'arc_connect', 'arc_connect_PCA']:\n",
    "    parameters_res = []\n",
    "    print(func)\n",
    "    for p1, p2 in zip(param1, param2):\n",
    "        cntr = Connector(p1, p2)\n",
    "        print(p1.shape)\n",
    "        f = getattr(cntr, func)\n",
    "        if 'PCA' in func:\n",
    "            K = min(300, p1.shape[0], p1.shape[1])\n",
    "            res = f(K=K)[1]\n",
    "        elif 'third_cumulant' in func:\n",
    "            K = min(100, p1.shape[0], p1.shape[1])\n",
    "            res = f(K=K)[1] \n",
    "        else:\n",
    "            res = f()[1]\n",
    "            \n",
    "        print('res', res.shape)\n",
    "        parameters_res.append(res)\n",
    "        \n",
    "    parameters_res = np.hstack([parameters_res[0].T, parameters_res[1]])\n",
    "    model = get_model(parameters_res, b2, architecture)\n",
    "    model.cuda();\n",
    "    model.eval();\n",
    "    test_model(model, loaders, cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lin_connect\n",
      "(3073, 2000)\n",
      "res (3073, 2000)\n",
      "(10, 2000)\n",
      "res (10, 2000)\n",
      "train results {'nll': 1.894404046974182, 'loss': 1.894404046974182, 'accuracy': 32.104}\n",
      "test results {'nll': 2.0686955657958985, 'loss': 2.0686955657958985, 'accuracy': 37.79}\n",
      "arc_connect\n",
      "(3073, 2000)\n",
      "res (3073, 2000)\n",
      "(10, 2000)\n",
      "res (10, 2000)\n",
      "train results {'nll': 1.5941276955795287, 'loss': 1.5941276955795287, 'accuracy': 44.44}\n",
      "test results {'nll': 2.962168966674805, 'loss': 2.962168966674805, 'accuracy': 41.61}\n",
      "arc_connect_PCA\n",
      "(3073, 2000)\n",
      "res (3073, 2000)\n",
      "(10, 2000)\n",
      "res (10, 2000)\n",
      "train results {'nll': 1.7525887490463257, 'loss': 1.7525887490463257, 'accuracy': 37.204}\n",
      "test results {'nll': 2.861420792388916, 'loss': 2.861420792388916, 'accuracy': 37.24}\n"
     ]
    }
   ],
   "source": [
    "param1 = [parameters1[:, :-10].T, parameters1[:, -10:].T]\n",
    "param2 = [parameters2[:, :-10].T, parameters2[:, -10:].T]\n",
    "\n",
    "for func in ['lin_connect', 'arc_connect', 'arc_connect_PCA']:\n",
    "    parameters_res = []\n",
    "    print(func)\n",
    "    for p1, p2 in zip(param1, param2):\n",
    "        cntr = Connector(p1, p2)\n",
    "        print(p1.shape)\n",
    "        f = getattr(cntr, func)\n",
    "        if 'PCA' in func:\n",
    "            K = min(300, p1.shape[0], p1.shape[1])\n",
    "            res = f(K=K)[1]\n",
    "        elif 'third_cumulant' in func:\n",
    "            K = min(100, p1.shape[0], p1.shape[1])\n",
    "            res = f(K=K)[1] \n",
    "        else:\n",
    "            res = f()[1]\n",
    "            \n",
    "        print('res', res.shape)\n",
    "        parameters_res.append(res)\n",
    "        \n",
    "    parameters_res = np.hstack([parameters_res[0].T, parameters_res[1].T])\n",
    "    model = get_model(parameters_res, b2, architecture)\n",
    "    model.cuda();\n",
    "    model.eval();\n",
    "    test_model(model, loaders, cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train results {'nll': 0.8493014687347412, 'loss': 0.8493014687347412, 'accuracy': 70.424}\n",
      "test results {'nll': 1.313883560180664, 'loss': 1.313883560180664, 'accuracy': 58.9}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'nll': 0.8493014687347412, 'loss': 0.8493014687347412, 'accuracy': 70.424},\n",
       " {'nll': 1.313883560180664, 'loss': 1.313883560180664, 'accuracy': 58.9})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.cuda();\n",
    "model1.eval();\n",
    "test_model(model1, loaders, cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arc_connect\n"
     ]
    }
   ],
   "source": [
    "func = 'arc_connect'\n",
    "parameters_res = []\n",
    "print(func)\n",
    "cntr = Connector(parameters1_tr, parameters2_tr)\n",
    "f = getattr(cntr, func)\n",
    "parameters_res = f()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_res_tr = inv_transform(parameters_res[:, :-10].T, parameters_res[:, -10:].T, E12,  E22_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train results {'nll': 1.4964728350067138, 'loss': 1.4964728350067138, 'accuracy': 51.208}\n",
      "test results {'nll': 2.692305062484741, 'loss': 2.692305062484741, 'accuracy': 40.93}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'nll': 1.4964728350067138, 'loss': 1.4964728350067138, 'accuracy': 51.208},\n",
       " {'nll': 2.692305062484741, 'loss': 2.692305062484741, 'accuracy': 40.93})"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model(parameters_res_tr, b2, architecture)\n",
    "model.cuda();\n",
    "model.eval();\n",
    "test_model(model, loaders, cuda=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gavering sample and error time plots on CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for func_name in funcs:\n",
    "#     t = np.linspace(0,1, 61)[1:-1]\n",
    "#     stat = test_func(modes, loaders, b2, architecture, func_name, flow=None, K=400, t=t, \n",
    "#                      show=False, verbose=False, save_pic=True, path='CIFAR', save_samples=False)\n",
    "#     t = np.linspace(0,1, 5)[1:-1]\n",
    "#     stat = test_func(modes, loaders, b2, architecture, func_name, flow=None, K=400, t=t, \n",
    "#                      show=False, verbose=False, save_pic=False, path='CIFAR', save_samples=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNVP flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = np.linspace(0,1, 61)[1:-1]\n",
    "# stat = test_func(modes, loaders, b2, architecture, func_name='flow_connect', flow=flow, K=400, t=t, \n",
    "#                  show=False, verbose=False, save_pic=True, test_models=True, path='CIFAR', save_samples=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = np.linspace(0,1, 5)[1:-1]\n",
    "# stat = test_func(modes, loaders, b2, architecture, func_name='flow_connect', flow=flow, K=400, t=t, \n",
    "#                  show=False, verbose=False, save_pic=False, path='CIFAR', save_samples=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing mean and std for different methods on CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train results {'nll': 0.8489676392555237, 'loss': 0.8489676392555237, 'accuracy': 70.572}\n",
      "test results {'nll': 1.313883560180664, 'loss': 1.313883560180664, 'accuracy': 58.9}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'nll': 0.8489676392555237, 'loss': 0.8489676392555237, 'accuracy': 70.572},\n",
       " {'nll': 1.313883560180664, 'loss': 1.313883560180664, 'accuracy': 58.9})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.cuda()\n",
    "test_model(model1, loaders, cuda=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask len 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flows.models import RealNVP, RealNVP_OneLayer_full, IAF_OneLayer_full\n",
    "\n",
    "flow = RealNVP_OneLayer_full(in_dim=3083, dim_middle=3000, N_layers=1, batch_norm=False, data_b2=b)\n",
    "flow.load_state_dict(torch.load('/home/ivan/distribution_connector/flow_models/RealNVP/CIFAR_test1/checkpoint-7.pt')['model_state'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from flows.models import RealNVP, RealNVP_OneLayer_full, IAF_OneLayer_full\n",
    "# flow = IAF_OneLayer_full(in_dim=3083, dim_middle=3000, N_layers=1, batch_norm=False, data_b2=b)\n",
    "# flow.load_state_dict(torch.load('/home/ivan/distribution_connector/flow_models/RealNVP/CIFAR_test1/checkpoint-7.pt')['model_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_models 4\n",
      "flow_connect\n",
      "0.5\n",
      "train results {'nll': 1.0533692544174194, 'loss': 1.0533692544174194, 'accuracy': 63.456}\n",
      "test results {'nll': 1.6187260831832886, 'loss': 1.6187260831832886, 'accuracy': 53.59}\n",
      "flow_connect\n",
      "0.5\n",
      "train results {'nll': 1.0545070586013794, 'loss': 1.0545070586013794, 'accuracy': 63.1}\n",
      "test results {'nll': 1.7111023202896118, 'loss': 1.7111023202896118, 'accuracy': 52.64}\n",
      "flow_connect\n",
      "0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 25%|██▌       | 1/4 [01:00<03:01, 60.47s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train results {'nll': 1.0488071635627747, 'loss': 1.0488071635627747, 'accuracy': 63.788}\n",
      "test results {'nll': 1.5592954841613769, 'loss': 1.5592954841613769, 'accuracy': 55.26}\n",
      "flow_connect\n",
      "0.5\n",
      "train results {'nll': 1.0633495126342773, 'loss': 1.0633495126342773, 'accuracy': 63.462}\n",
      "test results {'nll': 1.5593252670288087, 'loss': 1.5593252670288087, 'accuracy': 54.64}\n",
      "flow_connect\n",
      "0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 50%|█████     | 2/4 [01:41<01:49, 54.79s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train results {'nll': 1.0475879463577271, 'loss': 1.0475879463577271, 'accuracy': 63.818}\n",
      "test results {'nll': 1.5472380882263184, 'loss': 1.5472380882263184, 'accuracy': 54.58}\n",
      "flow_connect\n",
      "0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 75%|███████▌  | 3/4 [02:03<00:44, 44.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 4/4 [02:03<00:00, 30.96s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train results {'nll': 1.0577251321029664, 'loss': 1.0577251321029664, 'accuracy': 63.144}\n",
      "test results {'nll': 1.6692164546966552, 'loss': 1.6692164546966552, 'accuracy': 52.93}\n",
      "saving to  data/stat/CIFAR/bijectionerror_stat.pickle\n"
     ]
    }
   ],
   "source": [
    "flow.cuda();\n",
    "stat_dict, stat_dict_mean, stat_dict_std = gather_statistics(dataset[-8000:], \n",
    "                                                             loaders, b2, architecture, \n",
    "                                                             flow=flow, K=80, t=0.5, \n",
    "                                                             verbose=True, func_name=['flow_connect'],\n",
    "                                                             save_stat=True, path='stat/CIFAR/bijection')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## basic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = dataset[-8000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcs = [func for func in dir(cntr) if callable(getattr(cntr, func)) and 'connect' in func \n",
    "         and 'flow' not in func and 'third_cumulant' in func]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['third_cumulant_connect']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_models 4\n",
      "third_cumulant_connect\n",
      "c 49339.753945420765 8000000\n",
      "0.5\n",
      "train results {'nll': 192.03328536132813, 'loss': 192.03328536132813, 'accuracy': 10.95}\n",
      "test results {'nll': 159.18884404296875, 'loss': 159.18884404296875, 'accuracy': 11.4}\n",
      "third_cumulant_connect\n",
      "c 49147.18525962689 8000000\n",
      "0.5\n",
      "train results {'nll': 197.92421240234376, 'loss': 197.92421240234376, 'accuracy': 10.81}\n",
      "test results {'nll': 172.68769267578125, 'loss': 172.68769267578125, 'accuracy': 11.54}\n",
      "third_cumulant_connect\n",
      "c 49338.789716830164 8000000\n",
      "0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 1/4 [19:02<57:07, 1142.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train results {'nll': 200.2789377734375, 'loss': 200.2789377734375, 'accuracy': 11.184}\n",
      "test results {'nll': 174.5269504638672, 'loss': 174.5269504638672, 'accuracy': 12.38}\n",
      "third_cumulant_connect\n",
      "c 49031.59461684667 8000000\n",
      "0.5\n",
      "train results {'nll': 196.78189912109374, 'loss': 196.78189912109374, 'accuracy': 10.758}\n",
      "test results {'nll': 166.34349104003905, 'loss': 166.34349104003905, 'accuracy': 11.96}\n",
      "third_cumulant_connect\n",
      "c 49216.40067193843 8000000\n",
      "0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 2/4 [32:55<34:59, 1049.84s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train results {'nll': 203.76456399902344, 'loss': 203.76456399902344, 'accuracy': 10.178}\n",
      "test results {'nll': 165.93680776367188, 'loss': 165.93680776367188, 'accuracy': 11.31}\n",
      "third_cumulant_connect\n",
      "c 49634.76412962114 8000000\n",
      "0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 3/4 [39:04<14:05, 845.57s/it] \u001b[A\n",
      "100%|██████████| 4/4 [39:04<00:00, 586.23s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train results {'nll': 204.2034564892578, 'loss': 204.2034564892578, 'accuracy': 10.938}\n",
      "test results {'nll': 168.1272219970703, 'loss': 168.1272219970703, 'accuracy': 12.78}\n",
      "saving to  data/stat/CIFAR/third_cumulanterror_stat.pickle\n"
     ]
    }
   ],
   "source": [
    "stat_dict, stat_dict_mean, stat_dict_std = gather_statistics(test_dataset, \n",
    "                                                             loaders, b2, architecture, \n",
    "                                                             flow=None, K=200, t=0.5, \n",
    "                                                             verbose=True, func_name=funcs,\n",
    "                                                             save_stat=True, path='stat/CIFAR/third_cumulant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/stat/CIFAR/third_cumulanterror_stat.pickle', 'rb') as handle:\n",
    "        load = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': {'third_cumulant_connect': 10.802999999999999},\n",
       " 'test': {'third_cumulant_connect': 11.895000000000001}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': {'third_cumulant_connect': 0.31029394665918486},\n",
       " 'test': {'third_cumulant_connect': 0.5378893938348291}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'train': {'flow_connect': 63.60966666666667},\n",
       "  'test': {'flow_connect': 53.94}},\n",
       " {'train': {'flow_connect': 0.353156087618808},\n",
       "  'test': {'flow_connect': 0.9552137631615929}})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_dict_mean, stat_dict_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
