{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "import tabulate\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn\n",
    "\n",
    "import data\n",
    "import models\n",
    "import curves\n",
    "import utils\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "import utils\n",
    "import time\n",
    "from torch import nn\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from torch import distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture = getattr(models, \"LinearOneLayer\") #LinearOneLayer LogRegression\n",
    "model1 = architecture.base(num_classes=10, **architecture.kwargs)\n",
    "model2 = architecture.base(num_classes=10, **architecture.kwargs)\n",
    "\n",
    "model11 = architecture.base(num_classes=10, **architecture.kwargs)\n",
    "model12 = architecture.base(num_classes=10, **architecture.kwargs)\n",
    "m = architecture.base(num_classes=10, **architecture.kwargs)\n",
    "\n",
    "model1.load_state_dict(torch.load('curves_mnist/LinearOneLayer/LongTraining/curve3/checkpoint-30.pt')['model_state'])\n",
    "model2.load_state_dict(torch.load('curves_mnist/LinearOneLayer/LongTraining/curve4/checkpoint-30.pt')['model_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are going to run models on the test set. Are you sure?\n"
     ]
    }
   ],
   "source": [
    "loaders, num_classes = data.loaders(\n",
    "    \"MNIST\",\n",
    "    \"data\",\n",
    "    128,\n",
    "    1,\n",
    "    \"VGG\",\n",
    "    True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(model1, model2):\n",
    "    par1 = np.concatenate([p.data.cpu().numpy().ravel() for p in model1.parameters()])\n",
    "    par2 = np.concatenate([p.data.cpu().numpy().ravel() for p in model2.parameters()])\n",
    "    u = par2 - par1\n",
    "    dx = np.linalg.norm(u)\n",
    "    return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ind = 1\n",
    "# T = True\n",
    "# S = []\n",
    "# B = []\n",
    "# while ind<20:\n",
    "\n",
    "#     ckpt = 'curves_mnist/LinearOneLayer/LongTraining/curve'+str(ind)+'/checkpoint-30.pt'\n",
    "#     checkpoint = torch.load(ckpt)\n",
    "#     m.load_state_dict(checkpoint['model_state'])\n",
    "    \n",
    "#     S.append(samples(m))\n",
    "#     B.append(list(m.parameters())[-1].data.numpy())\n",
    "#     ind+=1\n",
    "    \n",
    "# S = np.concatenate(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flow Generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm(nn.Module):\n",
    "    def __init__(self, dim_in):\n",
    "        super(BatchNorm, self).__init__()\n",
    "\n",
    "        self.mu = torch.zeros(dim_in).cuda()\n",
    "        self.sig2 = torch.zeros(dim_in).cuda()+0.1\n",
    "        self.momentum=0.1\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        if self.training:\n",
    "            mu = x.mean(0)\n",
    "            sig2 = (x-mu).pow(2).mean(0)  \n",
    "            x = (x-mu)/(sig2 + 1.0e-6 ).sqrt()\n",
    "            self.mu = self.momentum*mu + (1-self.momentum)*self.mu\n",
    "            self.sig2 =  self.momentum*sig2 + (1-self.momentum)*self.sig2\n",
    "            return x, sig2+1.0e-6 \n",
    "        else: \n",
    "            x = (x-self.mu)/(self.sig2+1.0e-6).sqrt()\n",
    "            return x, self.sig2+1.0e-6 \n",
    "        \n",
    "        \n",
    "class SNet(nn.Module):\n",
    "    def __init__(self, dim_in, dim_middle):\n",
    "        super(SNet, self).__init__()\n",
    "        affine = True\n",
    "        self.h = nn.Tanh() #nn.LeakyReLU() #nn.Tanh()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(dim_in, dim_middle),\n",
    "            self.h,\n",
    "            nn.BatchNorm1d(dim_middle, affine=affine),\n",
    "            nn.Linear(dim_middle, dim_middle),\n",
    "            self.h,\n",
    "            nn.BatchNorm1d(dim_middle, affine=affine),\n",
    "            nn.Linear(dim_middle, dim_in)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):   \n",
    "        x = self.fc(x)\n",
    "#         x = torch.clamp(x, -1, 1) \n",
    "        return x\n",
    "    \n",
    "class TNet(nn.Module):\n",
    "    def __init__(self,  dim_in, dim_middle):\n",
    "        super(TNet, self).__init__()\n",
    "        affine = True\n",
    "        self.h = nn.Tanh()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(dim_in, dim_middle),\n",
    "            self.h,\n",
    "            nn.BatchNorm1d(dim_middle, affine=affine),\n",
    "            nn.Linear(dim_middle, dim_middle),\n",
    "            self.h,\n",
    "            nn.BatchNorm1d(dim_middle, affine=affine),\n",
    "            nn.Linear(dim_middle, dim_in),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):   \n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([2, 795]))"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "N_layers = 1\n",
    "n_dim = 795\n",
    "onezero = [0, 1]*n_dim\n",
    "masks = torch.Tensor([[onezero[:n_dim], onezero[1:n_dim+1]]]*N_layers)\n",
    "masks = masks.view(2*N_layers, -1)\n",
    "len(masks), masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealNVP(nn.Module):\n",
    "    def __init__(self, mask, prior):\n",
    "        super(RealNVP, self).__init__()\n",
    "        \n",
    "        # Create a flow\n",
    "        # nets:  a function that return a pytocrn neurel network e.g., nn.Sequential, s = nets(), s: dim(X) -> dim(X)\n",
    "        # nett:  a function that return a pytocrn neurel network e.g., nn.Sequential, t = nett(), t: dim(X) -> dim(X)\n",
    "        # mask:  a torch.Tensor of size #number_of_coupling_layers x #dim(X)\n",
    "        # prior: an object from torch.distributions e.g., torch.distributions.MultivariateNormal\n",
    "        \n",
    "        self.prior = prior \n",
    "        self.mask = nn.Parameter(mask, requires_grad=False).cuda()\n",
    "        self.t = torch.nn.ModuleList([SNet(dim_in=795, dim_middle=795*2) for _ in range(len(mask))])\n",
    "        self.s = torch.nn.ModuleList([TNet(dim_in=795, dim_middle=795*2) for _ in range(len(mask))])\n",
    "        self.b = torch.nn.ModuleList([BatchNorm(dim_in=795) for _ in range(len(mask))])\n",
    "        self.batch_norm = True\n",
    "        self.verbose = False\n",
    "        \n",
    "        \n",
    "        self.A = nn.Linear(n_dim, n_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.in_dim = n_dim\n",
    "        data_mean = torch.FloatTensor(np.random.normal(size=(n_dim, )))\n",
    "        self.mean= nn.Parameter(data = data_mean, requires_grad=True)\n",
    "\n",
    "        \n",
    "        \n",
    "    def g(self, z):\n",
    "        # Compute and return g(z) = x, \n",
    "        #    where self.mask[i], self.t[i], self.s[i] define a i-th masked coupling layer   \n",
    "        # z: a torch.Tensor of shape batchSize x 1 x dim(X)\n",
    "        # return x: a torch.Tensor of shape batchSize x 1 x dim(X)\n",
    "        for i, (s, t, b) in enumerate(zip(reversed(self.s), reversed(self.t), reversed(self.b))):\n",
    "            m = self.mask[-i-1]\n",
    "#             print('i', i, 'm', m)\n",
    "            \n",
    "            if self.verbose:\n",
    "                print('z1', z)\n",
    "            z = (m*z +(1-m)*(z-t(m*z))*(-s(m*z)).exp()).detach()\n",
    "#             print('z1', z)\n",
    "            if self.batch_norm:\n",
    "                z = (z*(b.sig2+1.0e-6).sqrt()+b.mu).detach()\n",
    "            if self.verbose:\n",
    "                print('z2', z)\n",
    "        \n",
    "        x = z\n",
    "        return x\n",
    "\n",
    "    def f(self, x):\n",
    "        # Compute f(x) = z and log_det_Jakobian of f, \n",
    "        #    where self.mask[i], self.t[i], self.s[i] define a i-th masked coupling layer   \n",
    "        # x: a torch.Tensor, of shape batchSize x dim(X), is a datapoint\n",
    "        # return z: a torch.Tensor of shape batchSize x dim(X), a hidden representations\n",
    "        # return log_det_J: a torch.Tensor of len batchSize\n",
    "        \n",
    "        z = x\n",
    "        log_det_J = 0\n",
    "        for s, t, m, b in zip(self.s, self.t, self.mask, self.b):\n",
    "\n",
    "            if self.batch_norm:\n",
    "                z, sig2 = b(z)\n",
    "#             print(m.shape, z.shape)\n",
    "            s_res = s(m*z)\n",
    "            z = m*z +(1-m)*(z*s_res.exp()+t(m*z))\n",
    "           \n",
    "            if self.batch_norm:\n",
    "                log_det_J += ((1-m)*s_res-0.5*sig2.log()).sum(-1)\n",
    "            else:\n",
    "                log_det_J += ((1-m)*s_res).sum(-1)\n",
    "        \n",
    "        return z, log_det_J\n",
    "    \n",
    "    def log_prob(self,x):\n",
    "        # Compute and return log p(x)\n",
    "        # using the change of variable formula and log_det_J computed by f\n",
    "        # return logp: torch.Tensor of len batchSize\n",
    "        z, log_det_J = self.f(x)\n",
    "        \n",
    "#         logp = -0.5*np.log(np.pi*2)-0.5*z.pow(2)\n",
    "#         logp = logp.sum(-1)\n",
    "#         logp = self.prior.log_prob(z)\n",
    "        logp = self.prior.log_prob(z.cpu()).cuda()\n",
    "#         shape = torch.Size((K, self.in_dim))\n",
    "#         logp = torch.cuda.FloatTensor(x.shape[0])\n",
    "#         self.prior.log_prob(z.cpu(), out=logp)\n",
    "        \n",
    "#         logp = self.prior.log_prob(z.cpu()).cuda()\n",
    "#         print('logp', logp.shape)\n",
    "        \n",
    "        return logp+log_det_J\n",
    "        \n",
    "    def sample(self, K): \n",
    "        # Draw and return batchSize samples from flow using implementation of g\n",
    "        # return x: torch.Tensor of shape batchSize x 1 x dim(X)\n",
    "\n",
    "        shape = torch.Size((K, 795))\n",
    "        e = torch.cuda.FloatTensor(shape)\n",
    "        torch.randn(shape, out=e)   \n",
    "#         e = (1/2000)*e\n",
    "#         e[:, :785] = (1/28)*e[:, :785]\n",
    "#         e[:, 785:] = (1/np.sqrt(2000))*e[:, 785:]\n",
    "#         e = (self.mean + self.A(e))   \n",
    "        x = self.f(e)[0]\n",
    "#         x = self.g(e)\n",
    "        \n",
    "#         z = self.prior.sample((K, )).cuda()\n",
    "#         x = self.g(z)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gaussian_Flow(nn.Module):\n",
    "    def __init__(self, n_dim=795, N_layers=10):\n",
    "        super(Gaussian_Flow, self).__init__()\n",
    "        \n",
    "        onezero = [0, 1]*n_dim\n",
    "        masks = torch.Tensor([[onezero[:n_dim], onezero[1:n_dim+1]]]*N_layers)\n",
    "        masks = masks.view(2*N_layers, -1)\n",
    "        print('masks', masks, masks.shape)\n",
    "        prior = distributions.MultivariateNormal(torch.zeros(n_dim), torch.eye(n_dim))\n",
    "        \n",
    "        self.nvp = RealNVP(masks, prior)\n",
    "        self.relu = nn.ReLU()\n",
    "        data_b2 = torch.FloatTensor(np.random.normal(size=(10, ))).cuda()\n",
    "        self.b2 = nn.Parameter(data = data_b2, requires_grad=True)\n",
    "        \n",
    "        self.verbose = False\n",
    "        self.l2 = 0\n",
    "\n",
    "    def forward(self, x, K=2000):\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        W = self.nvp.sample(K)\n",
    "        W1 = W[:, :784]\n",
    "        b1 = W[:, 784:785]\n",
    "        W2 =  W[:, 785:].transpose(0,1)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('x', x.shape)\n",
    "            print('W1', W1.shape)\n",
    "            print('b1', b1.shape)\n",
    "            \n",
    "        x = F.linear(x, W1, b1[:, 0])\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('x', x.shape)\n",
    "            print(x.shape)\n",
    "            \n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = F.linear(x, W2, self.b2) \n",
    "#         x = 1/K*x\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "        \n",
    "#         print(W1.shape, b1.shape)\n",
    "        self.l2 = W1.pow(2).sum()+W2.pow(2).sum() +b1.sum(-1).pow(2).sum()\n",
    "#         print(self.L2)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masks tensor([[0., 1., 0.,  ..., 0., 1., 0.],\n",
      "        [1., 0., 1.,  ..., 1., 0., 1.]]) torch.Size([2, 795])\n"
     ]
    }
   ],
   "source": [
    "GF = Gaussian_Flow(n_dim=795, N_layers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = F.cross_entropy\n",
    "regularizer = None \n",
    "optimizer = torch.optim.Adam(\n",
    "    filter(lambda param: param.requires_grad, GF.parameters()),\n",
    "    lr=1e-5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "GF.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_regularizer(weight_decay):\n",
    "    return lambda model: 0.5 * weight_decay * GF.l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularizer = l2_regularizer(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ep    tr_loss     tr_acc     te_nll     te_acc       time\n",
      "----  ---------  ---------  ---------  ---------  ---------\n",
      "   0    46.8448    51.8517     2.2464    53.5900    21.0392\n",
      "  ep    tr_loss     tr_acc     te_nll     te_acc       time\n",
      "----  ---------  ---------  ---------  ---------  ---------\n",
      "   1    44.7431    56.1950     1.8373    59.5700    21.0512\n",
      "  ep    tr_loss     tr_acc     te_nll     te_acc       time\n",
      "----  ---------  ---------  ---------  ---------  ---------\n",
      "   2    43.8603    62.5450     1.4306    66.6600    21.1004\n",
      "  ep    tr_loss     tr_acc     te_nll     te_acc       time\n",
      "----  ---------  ---------  ---------  ---------  ---------\n",
      "   3    43.2576    66.7733     1.3396    68.4200    21.1063\n",
      "  ep    tr_loss     tr_acc     te_nll     te_acc       time\n",
      "----  ---------  ---------  ---------  ---------  ---------\n",
      "   4    42.8129    70.0117     1.1611    71.0400    21.1465\n",
      "  ep    tr_loss     tr_acc     te_nll     te_acc       time\n",
      "----  ---------  ---------  ---------  ---------  ---------\n",
      "   5    42.5073    72.4817     1.0593    73.9700    21.2043\n",
      "  ep    tr_loss     tr_acc     te_nll     te_acc       time\n",
      "----  ---------  ---------  ---------  ---------  ---------\n",
      "   6    42.2373    74.0283     0.9674    76.2500    21.2185\n",
      "  ep    tr_loss     tr_acc     te_nll     te_acc       time\n",
      "----  ---------  ---------  ---------  ---------  ---------\n",
      "   7    42.0503    75.0200     0.9255    76.7900    21.1941\n",
      "  ep    tr_loss     tr_acc     te_nll     te_acc       time\n",
      "----  ---------  ---------  ---------  ---------  ---------\n",
      "   8    41.9127    76.2800     0.8233    78.7300    21.2613\n",
      "  ep    tr_loss     tr_acc     te_nll     te_acc       time\n",
      "----  ---------  ---------  ---------  ---------  ---------\n",
      "   9    41.7481    77.1967     0.8368    80.0600    21.2174\n",
      "  ep    tr_loss     tr_acc     te_nll     te_acc       time\n",
      "----  ---------  ---------  ---------  ---------  ---------\n",
      "  10    41.6389    78.1167     0.7851    80.5600    21.2245\n"
     ]
    }
   ],
   "source": [
    "columns = ['ep', 'tr_loss', 'tr_acc', 'te_nll', 'te_acc', 'time']\n",
    "for epoch in range(0, 10 + 1):\n",
    "    time_ep = time.time()\n",
    "\n",
    "    train_res = utils.train(loaders['train'], GF, optimizer, criterion, regularizer, cuda=True)\n",
    "    test_res = utils.test(loaders['test'], GF, criterion, regularizer, cuda=True)\n",
    "\n",
    "    time_ep = time.time() - time_ep\n",
    "    values = [epoch, train_res['loss'], train_res['accuracy'], test_res['nll'],\n",
    "              test_res['accuracy'], time_ep]\n",
    "\n",
    "    table = tabulate.tabulate([values], columns, tablefmt='simple', floatfmt='9.4f')\n",
    "    print(table)\n",
    "#     test_flow(model1, model2, GF, N=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def samples(model):\n",
    "    p1 = list(model.parameters())[0].data.cpu().numpy()\n",
    "    p2 = list(model.parameters())[1].data.cpu().numpy()\n",
    "    p3 = list(model.parameters())[2].transpose(0,1).data.cpu().numpy()\n",
    "    samples = np.hstack([p1, p2[:, None], p3])\n",
    "    \n",
    "    return samples\n",
    "\n",
    "def get_model(W, B):\n",
    "    model_sampled = architecture.base(num_classes=10, **architecture.kwargs)\n",
    "    model_samples = W.cpu().data.numpy()\n",
    "    SIZE = 2000\n",
    "\n",
    "    offset = 0\n",
    "    for parameter in list(model_sampled.parameters())[:-1]:\n",
    "        size = int(np.prod(parameter.size())/SIZE)\n",
    "        value = model_samples[:, offset:offset+size]\n",
    "        if size==10 or size==1:\n",
    "             value = value.T\n",
    "#         if size == 10:\n",
    "#             value = 1/2000*value\n",
    "#         else:\n",
    "#             value = value\n",
    "#         print(value.shape)\n",
    "        value = value.reshape(parameter.size())\n",
    "#         print(value.shape)\n",
    "        parameter.data.copy_(torch.from_numpy(value))\n",
    "        offset += size\n",
    "\n",
    "    list(model_sampled.parameters())[-1].data.copy_(torch.from_numpy(B.mean(0)))\n",
    "    \n",
    "    return model_sampled\n",
    "\n",
    "def test(model):\n",
    "    criterion = F.cross_entropy\n",
    "    regularizer = None \n",
    "    train_res = utils.test(loaders['train'], model, criterion, regularizer)\n",
    "    test_res = utils.test(loaders['test'], model, criterion, regularizer) \n",
    "    print(train_res)\n",
    "    print(test_res)\n",
    "\n",
    "def test_flow(model1, model2, flow, N=2000):\n",
    "    \n",
    "#     rcParams['figure.figsize'] = 12, 10\n",
    "#     rcParams['figure.dpi'] = 100\n",
    "\n",
    "    flow.cuda()\n",
    "    flow.eval()\n",
    "#     print('copmuting samples...')\n",
    "#     X = torch.FloatTensor(S[:N]).cuda()\n",
    "#     X_sample = X.data.cpu().numpy()\n",
    "#     X_prior = prior.sample((N,)).cpu().data.numpy()\n",
    "#     X_flow = flow.sample(N, ).data.cpu().numpy()\n",
    "#     X_sample_prior = flow.f(torch.FloatTensor(X_sample).cuda())[0].data.cpu().numpy()\n",
    "    \n",
    "#     print('drawing...')\n",
    "#     i, j = 500, -1\n",
    "#     fig, axes = plt.subplots(2, 2,)\n",
    "#     axes[0, 0].set_title('Samples')\n",
    "#     axes[0, 0].scatter(X_sample[:, i], X_sample[:, j])\n",
    "#     axes[0, 1].set_title('Prior')\n",
    "#     axes[0, 1].scatter(X_prior[:, i], X_prior[:, j])\n",
    "#     axes[1, 0].set_title('Flow sampling')\n",
    "#     axes[1, 0].scatter(X_flow[:, i], X_flow[:, j])\n",
    "#     axes[1, 1].set_title('Map from samples to prior')\n",
    "#     axes[1, 1].scatter(X_sample_prior[:, i], X_sample_prior[:, j]) \n",
    "#     plt.show()\n",
    "    \n",
    "    print('computing Arc model...')\n",
    "    W1 = samples(model1)\n",
    "    W2 = samples(model2)\n",
    "    \n",
    "#     W1[:, 785:] = 2000*W1[:, 785:]\n",
    "#     W2[:, 785:] = 2000*W2[:, 785:]\n",
    "    \n",
    "#     flow.cpu()\n",
    "    W_pre = 1/np.sqrt(2)*flow.nvp.g(torch.FloatTensor(W1).cuda())+1/np.sqrt(2)*flow.nvp.g(torch.FloatTensor(W2).cuda())\n",
    "    W = flow.nvp.f(W_pre)[0]\n",
    "#     W[:, 785:] = 1/2000*W[:, 785:]\n",
    "    B = []\n",
    "    B.append(list(model1.parameters())[-1].data.cpu().numpy())\n",
    "    B.append(list(model2.parameters())[-1].data.cpu().numpy())\n",
    "    B = np.array(B)\n",
    "    \n",
    "#     model_sampled = get_model(torch.tensor(W1).cuda(), B)\n",
    "#     test(model_sampled)\n",
    "    \n",
    "    model_sampled = get_model(W, B)\n",
    "    test(model_sampled)\n",
    "    \n",
    "\n",
    "    \n",
    "    if N==2000:\n",
    "        print('computing Sampling from flow model...')\n",
    "        \n",
    "        B = []\n",
    "        B.append(flow.b2.data.cpu().numpy())\n",
    "        B = np.array(B)\n",
    "    \n",
    "        X_flow = flow.nvp.sample(N, ).data.cpu()\n",
    "#         X_flow[:, :784] = X_flow[:, :784]\n",
    "#         X_flow[:, 785:] = 1/2000*X_flow[:, 785:]\n",
    "        model_flow = get_model(X_flow, B)\n",
    "        test(model_flow)\n",
    "#         return model_sampled, model_flow\n",
    "    \n",
    "#     return model_sampled\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing Arc model...\n",
      "{'nll': 0.043516448573271437, 'loss': 0.043516448573271437, 'accuracy': 98.98666666666666}\n",
      "{'nll': 0.07036074814796447, 'loss': 0.07036074814796447, 'accuracy': 97.92}\n",
      "{'nll': 894916328.7168, 'loss': 894916328.7168, 'accuracy': 16.58}\n",
      "{'nll': 731623296.3848, 'loss': 731623296.3848, 'accuracy': 16.82}\n",
      "computing Sampling from flow model...\n",
      "{'nll': 0.8460212607701619, 'loss': 0.8460212607701619, 'accuracy': 79.60833333333333}\n",
      "{'nll': 0.8191173463821411, 'loss': 0.8191173463821411, 'accuracy': 79.87}\n"
     ]
    }
   ],
   "source": [
    "test_flow(model1, model2, GF, N=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainig mean and covariance matrix One hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gaussian_model(nn.Module):\n",
    "    def __init__(self, n_dim=795):\n",
    "        super(Gaussian_model, self).__init__()\n",
    "        self.A = nn.Linear(n_dim, n_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.in_dim = n_dim\n",
    "        data_mean = torch.FloatTensor(np.random.normal(size=(n_dim, )))\n",
    "        self.mean= nn.Parameter(data = data_mean, requires_grad=True)\n",
    "        \n",
    "        data_b2 = torch.FloatTensor(np.random.normal(size=(10, )))\n",
    "        self.b2 = nn.Parameter(data = data_b2, requires_grad=True)\n",
    "\n",
    "    def sample(self, K, cuda=True):\n",
    "        \n",
    "        if cuda:\n",
    "            shape = torch.Size((K, self.in_dim))\n",
    "            e = torch.cuda.FloatTensor(shape)\n",
    "            torch.randn(shape, out=e)   \n",
    "        else:          \n",
    "            e = torch.randn((K, self.in_dim))\n",
    "        W = (self.mean + self.A(e))       \n",
    "        return W\n",
    "    \n",
    "\n",
    "    def forward(self, x, K=2000):\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        W = self.sample(K)\n",
    "        W1 = W[:, :784]\n",
    "        b1 = W[:, 784:785]\n",
    "        W2 =  W[:, 785:].transpose(0,1)\n",
    "        \n",
    "        x = F.linear(x, W1, b1[:, 0])\n",
    "        x = self.relu(x)\n",
    "        x = F.linear(x, W2, self.b2) \n",
    "        x = 1/K*x\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masks tensor([[0., 1., 0.,  ..., 0., 1., 0.],\n",
      "        [1., 0., 1.,  ..., 1., 0., 1.]]) torch.Size([2, 795])\n"
     ]
    }
   ],
   "source": [
    "GM = Gaussian_model()\n",
    "GM.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = F.cross_entropy\n",
    "regularizer = None \n",
    "optimizer = torch.optim.Adam(\n",
    "    filter(lambda param: param.requires_grad, GM.parameters()),\n",
    "    lr=1e-4,\n",
    "#     momentum=0.9,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7fc91755f730>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 717, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 713, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ep    tr_loss     tr_acc     te_nll     te_acc       time\n",
      "----  ---------  ---------  ---------  ---------  ---------\n",
      "   0     0.4760    85.6850     0.3189    90.9500    17.9283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7fc91755f730>\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 717, in __del__\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 704, in _shutdown_workers\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "    self.worker_result_queue.close()\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 134, in close\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "    self._reader.close()\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n",
      "    close()\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/threading.py\", line 917, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/threading.py\", line 865, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "\n",
      "    self._close()\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7fc91755f730>\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 717, in __del__\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 704, in _shutdown_workers\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "    self.worker_result_queue.close()\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 134, in close\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n",
      "    close()\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/threading.py\", line 917, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/threading.py\", line 865, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "    self._reader.close()\n",
      "\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ep    tr_loss     tr_acc     te_nll     te_acc       time\n",
      "----  ---------  ---------  ---------  ---------  ---------\n",
      "   1     0.3574    90.4917     0.2769    91.7400    18.0539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7fc91755f730>\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 717, in __del__\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 704, in _shutdown_workers\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "    self.worker_result_queue.close()\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n",
      "    close()\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/threading.py\", line 917, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/threading.py\", line 865, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 134, in close\n",
      "\n",
      "    self._reader.close()\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7fc91755f730>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 717, in __del__\n",
      "Traceback (most recent call last):\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 704, in _shutdown_workers\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "    self.worker_result_queue.close()\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/home/anokhin/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 134, in close\n",
      "OSError: [Errno 9] Bad file descriptor\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid 32204) is killed by signal: Aborted. ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-60f8d48473b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtrain_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtest_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtime_ep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_ep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dnn-mode-connectivity/utils.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(test_loader, model, criterion, regularizer, cuda, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    599\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMP_STATUS_CHECK_INTERVAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;31m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;31m# Python can still get and update the process status successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0m_error_if_any_worker_fails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprevious_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0mprevious_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 32204) is killed by signal: Aborted. "
     ]
    }
   ],
   "source": [
    "columns = ['ep', 'tr_loss', 'tr_acc', 'te_nll', 'te_acc', 'time']\n",
    "for epoch in range(0, 10 + 1):\n",
    "    time_ep = time.time()\n",
    "\n",
    "\n",
    "    train_res = utils.train(loaders['train'], GM, optimizer, criterion, regularizer, cuda=True)\n",
    "    test_res = utils.test(loaders['test'], GM, criterion, regularizer, cuda=True)\n",
    "\n",
    "    time_ep = time.time() - time_ep\n",
    "    values = [epoch, train_res['loss'], train_res['accuracy'], test_res['nll'],\n",
    "              test_res['accuracy'], time_ep]\n",
    "\n",
    "    table = tabulate.tabulate([values], columns, tablefmt='simple', floatfmt='9.4f')\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GM(X)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_res = utils.test(loaders['test'], GM, criterion, regularizer, cuda=True)\n",
    "# test_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = GM.sample(2000).data.numpy()\n",
    "sns.kdeplot(samples[:, 0], samples[:, 70], shade=True,  cbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a3e6529e8>"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a3e66b7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.kdeplot(samples[:, 0], samples[:, 70], shade=True,  cbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embeddeds = TSNE(n_components=2).fit_transform(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a362774e0>"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a3087f400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.kdeplot(X_embeddeds[:, 0], X_embeddeds[:, 1], shade=True,  cbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainig mean and covariance matrix Several hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMMultyLayer(nn.Module):\n",
    "    def __init__(self, n_dim=809):\n",
    "        super(GMMultyLayer, self).__init__()\n",
    "        self.n_dim = n_dim\n",
    "        self.A = nn.Linear(n_dim, n_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        data_mean = torch.FloatTensor(np.random.normal(size=(n_dim, )))\n",
    "        self.mean= nn.Parameter(data = data_mean, requires_grad=True)\n",
    "        \n",
    "        data_bf = torch.FloatTensor(np.random.normal(size=(10, )))\n",
    "        self.bf = nn.Parameter(data = data_bf, requires_grad=True)\n",
    "\n",
    "    def sample(self, K):\n",
    "        e = torch.randn((K, self.mean.size()[0]))\n",
    "        W = (self.mean + self.A(e))       \n",
    "        return W\n",
    "    \n",
    "\n",
    "    def forward(self, x, K=4000):\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        W = self.sample(K)\n",
    "        W1 = W[:, :784]\n",
    "        b1 = W[:, 784]\n",
    "        \n",
    "        W2 = W[:, 785]\n",
    "        b2 = W[:, 786]\n",
    "        Wf =  W[:, -10:].transpose(0,1)\n",
    "        \n",
    "        x = F.linear(x, W1, b1)\n",
    "        x = self.relu(x)\n",
    "        for i in range(int(self.n_dim-784-10/2), 2):\n",
    "            Wi = W[:, 785+i]\n",
    "            bi = W[:, 786+i]\n",
    "            x = self.relu(Wi*x+bi)\n",
    "            \n",
    "        x = F.linear(x, Wf, self.bf) \n",
    "        x = 1/K*x\n",
    "#         print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "GML = GMMultyLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = F.cross_entropy\n",
    "regularizer = None \n",
    "optimizer = torch.optim.SGD(\n",
    "    filter(lambda param: param.requires_grad, GML.parameters()),\n",
    "    lr=0.01,\n",
    "    momentum=0.9,\n",
    "    weight_decay=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ep         lr    tr_loss     tr_acc     te_nll     te_acc       time\n",
      "----  ---------  ---------  ---------  ---------  ---------  ---------\n",
      "   0     0.0010     2.7916    14.3017     2.2235    14.8000    93.5746\n",
      "  ep         lr    tr_loss     tr_acc     te_nll     te_acc       time\n",
      "----  ---------  ---------  ---------  ---------  ---------  ---------\n",
      "   1     0.0010     2.1833    15.8317     2.1439    18.0300    91.0075\n",
      "  ep         lr    tr_loss     tr_acc     te_nll     te_acc       time\n",
      "----  ---------  ---------  ---------  ---------  ---------  ---------\n",
      "   2     0.0010     2.0937    24.0500     2.0191    30.7600    90.9785\n",
      "  ep         lr    tr_loss     tr_acc     te_nll     te_acc       time\n",
      "----  ---------  ---------  ---------  ---------  ---------  ---------\n",
      "   3     0.0010     1.9095    36.9383     1.7213    47.6100    90.6315\n",
      "  ep         lr    tr_loss     tr_acc     te_nll     te_acc       time\n",
      "----  ---------  ---------  ---------  ---------  ---------  ---------\n",
      "   4     0.0010     1.4738    59.3883     1.1794    67.9500    90.9084\n",
      "  ep         lr    tr_loss     tr_acc     te_nll     te_acc       time\n",
      "----  ---------  ---------  ---------  ---------  ---------  ---------\n",
      "   5     0.0010     1.0308    71.7517     0.8680    74.5800    92.7320\n",
      "  ep         lr    tr_loss     tr_acc     te_nll     te_acc       time\n",
      "----  ---------  ---------  ---------  ---------  ---------  ---------\n",
      "   6     0.0010     0.8114    75.2483     0.7091    76.9900    91.3537\n",
      "  ep         lr    tr_loss     tr_acc     te_nll     te_acc       time\n",
      "----  ---------  ---------  ---------  ---------  ---------  ---------\n",
      "   7     0.0010     0.6591    83.7533     0.5690    87.6800    91.7474\n",
      "  ep         lr    tr_loss     tr_acc     te_nll     te_acc       time\n",
      "----  ---------  ---------  ---------  ---------  ---------  ---------\n",
      "   8     0.0010     0.5372    87.2150     0.4731    88.2000    92.4704\n",
      "  ep         lr    tr_loss     tr_acc     te_nll     te_acc       time\n",
      "----  ---------  ---------  ---------  ---------  ---------  ---------\n",
      "   9     0.0010     0.4687    87.5850     0.4266    88.3400    91.7914\n",
      "  ep         lr    tr_loss     tr_acc     te_nll     te_acc       time\n",
      "----  ---------  ---------  ---------  ---------  ---------  ---------\n",
      "  10     0.0010     0.4312    88.0667     0.3999    88.9800    92.3218\n"
     ]
    }
   ],
   "source": [
    "columns = ['ep', 'lr', 'tr_loss', 'tr_acc', 'te_nll', 'te_acc', 'time']\n",
    "for epoch in range(0, 10 + 1):\n",
    "    time_ep = time.time()\n",
    "\n",
    "    lr = 1e-3\n",
    "    utils.adjust_learning_rate(optimizer, lr)\n",
    "\n",
    "    train_res = utils.train(loaders['train'], GML, optimizer, criterion, regularizer)\n",
    "    test_res = utils.test(loaders['test'], GML, criterion, regularizer)\n",
    "\n",
    "    time_ep = time.time() - time_ep\n",
    "    values = [epoch, lr, train_res['loss'], train_res['accuracy'], test_res['nll'],\n",
    "              test_res['accuracy'], time_ep]\n",
    "\n",
    "    table = tabulate.tabulate([values], columns, tablefmt='simple', floatfmt='9.4f')\n",
    "    print(table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
