{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import tabulate\n",
    "import time\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import curves\n",
    "import data\n",
    "import models\n",
    "import utils\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Using train (45000) + validation (5000)\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "loaders, num_classes = data.loaders(\n",
    "    \"CIFAR10\",\n",
    "    \"data\",\n",
    "    128,\n",
    "    1,\n",
    "    \"VGG\",\n",
    "    False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture = getattr(models, \"VGG16\")\n",
    "model1 = architecture.base(num_classes=10, **architecture.kwargs)\n",
    "model2 = architecture.base(num_classes=10, **architecture.kwargs)\n",
    "\n",
    "model1.load_state_dict(torch.load(\"curves/curve1/checkpoint-100.pt\")['model_state'])\n",
    "model2.load_state_dict(torch.load(\"curves/curve2/checkpoint-100.pt\")['model_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGGBase(\n",
       "  (layer_blocks): ModuleList(\n",
       "    (0): ModuleList(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (1): ModuleList(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (2): ModuleList(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (3): ModuleList(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (4): ModuleList(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (activation_blocks): ModuleList(\n",
       "    (0): ModuleList(\n",
       "      (0): ReLU(inplace)\n",
       "      (1): ReLU(inplace)\n",
       "    )\n",
       "    (1): ModuleList(\n",
       "      (0): ReLU(inplace)\n",
       "      (1): ReLU(inplace)\n",
       "    )\n",
       "    (2): ModuleList(\n",
       "      (0): ReLU(inplace)\n",
       "      (1): ReLU(inplace)\n",
       "      (2): ReLU(inplace)\n",
       "    )\n",
       "    (3): ModuleList(\n",
       "      (0): ReLU(inplace)\n",
       "      (1): ReLU(inplace)\n",
       "      (2): ReLU(inplace)\n",
       "    )\n",
       "    (4): ModuleList(\n",
       "      (0): ReLU(inplace)\n",
       "      (1): ReLU(inplace)\n",
       "      (2): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (poolings): ModuleList(\n",
       "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): Dropout(p=0.5)\n",
       "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = architecture.base(num_classes=10, **architecture.kwargs)\n",
    "model3.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = F.cross_entropy\n",
    "regularizer = None \n",
    "optimizer = torch.optim.SGD(\n",
    "    filter(lambda param: param.requires_grad, model3.parameters()),\n",
    "    lr=0.01,\n",
    "    momentum=0.9,\n",
    "    weight_decay=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, optimizer, criterion, regularizer=None, lr_schedule=None):\n",
    "    loss_sum = 0.0\n",
    "    correct = 0.0\n",
    "\n",
    "    num_iters = len(train_loader)\n",
    "    model.train()\n",
    "    for iter, (input, target) in enumerate(train_loader):\n",
    "        if lr_schedule is not None:\n",
    "            lr = lr_schedule(iter / num_iters)\n",
    "            adjust_learning_rate(optimizer, lr)\n",
    "        input = input.cuda(non_blocking=True)\n",
    "        target = target.cuda(non_blocking=True)\n",
    "\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "        if regularizer is not None:\n",
    "            loss += regularizer(model)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        loss_sum += loss.item() * input.size(0)\n",
    "        pred = output.data.argmax(1, keepdim=True)\n",
    "        correct += pred.eq(target.data.view_as(pred)).sum().item()\n",
    "        \n",
    "    grad = np.concatenate([p.grad.data.cpu().numpy().ravel() for p in model.parameters()])\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing gradients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 50\n",
    "l_grad = []\n",
    "for j in range(0, num_points):\n",
    "    for p1, p2, p3 in zip(model1.parameters(), model2.parameters(), model3.parameters()):\n",
    "        alpha = j * 1.0 / (num_points-1)\n",
    "        p3.data.copy_(alpha * p1.data + (1.0 - alpha) * p2.data)        \n",
    "    grad = train(loaders['train'], model3, optimizer, criterion, )\n",
    "    l_grad.append(grad)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = l_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_grad = grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99999994\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0000001\n"
     ]
    }
   ],
   "source": [
    "for i, v in enumerate(l_grad):\n",
    "    print(np.linalg.norm(v))\n",
    "    l_grad[i] = v/np.linalg.norm(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49538140296936034\n"
     ]
    }
   ],
   "source": [
    "s = 0\n",
    "for v in l_grad:\n",
    "    s += v\n",
    "print(np.linalg.norm(s)/num_points)\n",
    "s = s/np.linalg.norm(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4571768\n",
      "0.5298122\n",
      "0.5464061\n",
      "0.517551\n",
      "0.42598894\n"
     ]
    }
   ],
   "source": [
    "for v in l_grad:\n",
    "    print((v*s).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8893923\n",
      "0.8481226\n",
      "0.8375253\n",
      "0.85565865\n",
      "0.9047352\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(l_grad)):\n",
    "    l_grad[i] = l_grad[i]-(l_grad[i]*s).sum()*s\n",
    "    print(np.linalg.norm(l_grad[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1492970720137234e-08\n"
     ]
    }
   ],
   "source": [
    "s = 0\n",
    "for v in l_grad:\n",
    "    s += v\n",
    "print(np.linalg.norm(s)/num_points)\n",
    "s = s/np.linalg.norm(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0019658336\n",
      "-0.0009832255\n",
      "0.0011526728\n",
      "0.0003624293\n",
      "0.0014340992\n"
     ]
    }
   ],
   "source": [
    "for v in l_grad:\n",
    "    print((v*s).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
