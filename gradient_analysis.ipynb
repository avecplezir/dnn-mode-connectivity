{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import tabulate\n",
    "import time\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import curves\n",
    "import data\n",
    "import models\n",
    "import utils\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Using train (45000) + validation (5000)\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "loaders, num_classes = data.loaders(\n",
    "    \"CIFAR10\",\n",
    "    \"data\",\n",
    "    128,\n",
    "    1,\n",
    "    \"VGG\",\n",
    "    False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture = getattr(models, \"VGG16\")\n",
    "model1 = architecture.base(num_classes=10, **architecture.kwargs)\n",
    "model2 = architecture.base(num_classes=10, **architecture.kwargs)\n",
    "model3 = architecture.base(num_classes=10, **architecture.kwargs)\n",
    "\n",
    "model1.load_state_dict(torch.load(\"curves/curve51/checkpoint-100.pt\")['model_state'])\n",
    "model2.load_state_dict(torch.load(\"curves/middle_init5051_21/checkpoint-100.pt\")['model_state'])\n",
    "model3.load_state_dict(torch.load(\"curves/curve50/checkpoint-100.pt\")['model_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(model1, model2):\n",
    "    par1 = np.concatenate([p.data.cpu().numpy().ravel() for p in model1.parameters()])\n",
    "    par2 = np.concatenate([p.data.cpu().numpy().ravel() for p in model2.parameters()])\n",
    "    u = par2 - par1\n",
    "    dx = np.linalg.norm(u)\n",
    "    print('distance: %5.4f' % dx)\n",
    "    return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance: 56.3710\n",
      "distance: 31.5998\n",
      "distance: 21.6775\n",
      "distance: 18.2212\n",
      "distance: 17.0778\n"
     ]
    }
   ],
   "source": [
    "distance = [dist(model3, model2)]\n",
    "for i in range(2, 6):\n",
    "    model1.load_state_dict(torch.load(\"curves/middle_init5051_2\"+str(i-1)+\"/checkpoint-100.pt\")['model_state'])\n",
    "    model2.load_state_dict(torch.load(\"curves/middle_init5051_2\"+str(i)+\"/checkpoint-100.pt\")['model_state'])\n",
    "    model3.load_state_dict(torch.load(\"curves/curve50/checkpoint-100.pt\")['model_state'])\n",
    "    distance.append(dist(model3, model2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance.append(dist(model1, model2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance: 31.5998\n"
     ]
    }
   ],
   "source": [
    "dist(model2, model3)\n",
    "# dist(model2, model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance: 63.1997\n"
     ]
    }
   ],
   "source": [
    "dist(model1, model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.cuda();\n",
    "model2.cuda();\n",
    "model3.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = F.cross_entropy\n",
    "regularizer = None \n",
    "model1.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nll': 0.6022534687042236, 'loss': 0.6022534687042236, 'accuracy': 91.3}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_res = utils.test(loaders['test'], model2, criterion, regularizer)\n",
    "test_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture = getattr(models, \"VGG16\")\n",
    "model1 = architecture.base(num_classes=10, **architecture.kwargs)\n",
    "model2 = architecture.base(num_classes=10, **architecture.kwargs)\n",
    "\n",
    "model1.load_state_dict(torch.load(\"curves/curve50/checkpoint-100.pt\")['model_state'])\n",
    "model2.load_state_dict(torch.load(\"curves/curve51/checkpoint-100.pt\")['model_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = architecture.base(num_classes=10, **architecture.kwargs)\n",
    "model3.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = F.cross_entropy\n",
    "regularizer = None \n",
    "optimizer = torch.optim.SGD(\n",
    "    filter(lambda param: param.requires_grad, model3.parameters()),\n",
    "    lr=0.01,\n",
    "    momentum=0.9,\n",
    "    weight_decay=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res = utils.test(loaders['test'], model3, criterion, regularizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nll': 2.3029834384918213, 'loss': 2.3029834384918213, 'accuracy': 10.28}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, optimizer, criterion, regularizer=None, lr_schedule=None):\n",
    "    loss_sum = 0.0\n",
    "    correct = 0.0\n",
    "\n",
    "    num_iters = len(train_loader)\n",
    "    model.train()\n",
    "    for iter, (input, target) in enumerate(train_loader):\n",
    "        if lr_schedule is not None:\n",
    "            lr = lr_schedule(iter / num_iters)\n",
    "            adjust_learning_rate(optimizer, lr)\n",
    "        input = input.cuda(non_blocking=True)\n",
    "        target = target.cuda(non_blocking=True)\n",
    "\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "        if regularizer is not None:\n",
    "            loss += regularizer(model)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        loss_sum += loss.item() * input.size(0)\n",
    "        pred = output.data.argmax(1, keepdim=True)\n",
    "        correct += pred.eq(target.data.view_as(pred)).sum().item()\n",
    "        \n",
    "    grad = np.concatenate([p.grad.data.cpu().numpy().ravel() for p in model.parameters()])\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing gradients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 15\n",
    "l_grad = []\n",
    "for j in range(0, num_points):\n",
    "    for p1, p2, p3 in zip(model1.parameters(), model2.parameters(), model3.parameters()):\n",
    "        alpha = j * 1.0 / (num_points-1)\n",
    "        p3.data.copy_(alpha * p1.data + (1.0 - alpha) * p2.data)        \n",
    "    grad = train(loaders['train'], model3, optimizer, criterion, )\n",
    "    l_grad.append(grad)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = copy.copy(l_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_grad = copy.copy(grad[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0344283\n",
      "3.3656862\n",
      "1.7700907\n",
      "3.5720978\n",
      "1.4306158\n"
     ]
    }
   ],
   "source": [
    "for i, v in enumerate(l_grad):\n",
    "    print(np.linalg.norm(v))\n",
    "    l_grad[i] = v/np.linalg.norm(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5325227737426758\n"
     ]
    }
   ],
   "source": [
    "s = 0\n",
    "for v in l_grad:\n",
    "    s += v\n",
    "print(np.linalg.norm(s)/num_points)\n",
    "s = s/np.linalg.norm(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38430274\n",
      "0.6172532\n",
      "0.70602906\n",
      "0.59019786\n",
      "0.3648513\n"
     ]
    }
   ],
   "source": [
    "for v in l_grad:\n",
    "    print((v*s).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0000001\n",
      "0.9999999\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(l_grad)):\n",
    "    l_grad[i] = l_grad[i]-(l_grad[i]*s).sum()*s\n",
    "    l_grad[i] = l_grad[i]/np.linalg.norm(l_grad[i])\n",
    "    print(np.linalg.norm(l_grad[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.059120625257492065\n"
     ]
    }
   ],
   "source": [
    "s = 0\n",
    "for v in l_grad:\n",
    "    s += v\n",
    "print(np.linalg.norm(s)/num_points)\n",
    "s = s/np.linalg.norm(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.60078305\n",
      "0.41879392\n",
      "0.83125174\n",
      "0.27660877\n",
      "-0.630264\n"
     ]
    }
   ],
   "source": [
    "for v in l_grad:\n",
    "    print((v*s).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
