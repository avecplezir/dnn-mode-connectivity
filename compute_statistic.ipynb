{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "import tabulate\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import data\n",
    "import models\n",
    "import curves\n",
    "import utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = argparse.ArgumentParser(description='Computes values for plane visualization')\n",
    "# parser.add_argument('--dir', type=str, default='/tmp/plane', metavar='DIR',\n",
    "#                     help='training directory (default: /tmp/plane)')\n",
    "\n",
    "# parser.add_argument('--grid_points', type=int, default=21, metavar='N',\n",
    "#                     help='number of points in the grid (default: 21)')\n",
    "# parser.add_argument('--margin_left', type=float, default=0.2, metavar='M',\n",
    "#                     help='left margin (default: 0.2)')\n",
    "# parser.add_argument('--margin_right', type=float, default=0.2, metavar='M',\n",
    "#                     help='right margin (default: 0.2)')\n",
    "# parser.add_argument('--margin_bottom', type=float, default=0.2, metavar='M',\n",
    "#                     help='bottom margin (default: 0.)')\n",
    "# parser.add_argument('--margin_top', type=float, default=0.2, metavar='M',\n",
    "#                     help='top margin (default: 0.2)')\n",
    "\n",
    "# parser.add_argument('--curve_points', type=int, default=61, metavar='N',\n",
    "#                     help='number of points on the curve (default: 61)')\n",
    "\n",
    "# parser.add_argument('--dataset', type=str, default='CIFAR10', metavar='DATASET',\n",
    "#                     help='dataset name (default: CIFAR10)')\n",
    "# parser.add_argument('--use_test', action='store_true',\n",
    "#                     help='switches between validation and test set (default: validation)')\n",
    "# parser.add_argument('--transform', type=str, default='VGG', metavar='TRANSFORM',\n",
    "#                     help='transform name (default: VGG)')\n",
    "# parser.add_argument('--data_path', type=str, default=None, metavar='PATH',\n",
    "#                     help='path to datasets location (default: None)')\n",
    "# parser.add_argument('--batch_size', type=int, default=128, metavar='N',\n",
    "#                     help='input batch size (default: 128)')\n",
    "# parser.add_argument('--num_workers', type=int, default=4, metavar='N',\n",
    "#                     help='number of workers (default: 4)')\n",
    "\n",
    "# parser.add_argument('--model', type=str, default=None, metavar='MODEL',\n",
    "#                     help='model name (default: None)')\n",
    "# parser.add_argument('--curve', type=str, default=None, metavar='CURVE',\n",
    "#                     help='curve type to use (default: None)')\n",
    "# parser.add_argument('--num_bends', type=int, default=3, metavar='N',\n",
    "#                     help='number of curve bends (default: 3)')\n",
    "\n",
    "# parser.add_argument('--ckpt', type=str, default=None, metavar='CKPT',\n",
    "#                     help='checkpoint to eval (default: None)')\n",
    "\n",
    "# parser.add_argument('--wd', type=float, default=1e-4, metavar='WD',\n",
    "#                     help='weight decay (default: 1e-4)')\n",
    "\n",
    "# args = parser.parse_args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Using train (45000) + validation (5000)\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "loaders, num_classes = data.loaders(\n",
    "    \"CIFAR10\",\n",
    "    \"data\",\n",
    "    128,\n",
    "    1,\n",
    "    \"VGG\",\n",
    "    False)\n",
    "\n",
    "architecture = getattr(models, \"VGG16\")\n",
    "curve = getattr(curves, 'PolyChain')\n",
    "\n",
    "model = curves.CurveNet(\n",
    "            10,\n",
    "            curve,\n",
    "            architecture.curve,\n",
    "            3,\n",
    "            True,\n",
    "            True,\n",
    "            architecture_kwargs=architecture.kwargs,\n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_bn = utils.check_bn(model)\n",
    "test_res = {'loss': None, 'accuracy': None, 'nll': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = F.cross_entropy\n",
    "regularizer = utils.l2_regularizer(1e-4)\n",
    "\n",
    "checkpoint = torch.load(args.ckpt)\n",
    "curve_model.load_state_dict(checkpoint['model_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "torch.cuda.FloatTensor is not enabled.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8e4f683c8e19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m values = [epoch, lr, train_res['loss'], train_res['accuracy'], test_res['nll'],\n\u001b[1;32m      5\u001b[0m           test_res['accuracy'], time_ep]\n",
      "\u001b[0;32m~/Documents/thesis/dnn-mode-connectivity1/utils.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(test_loader, model, criterion, regularizer, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: torch.cuda.FloatTensor is not enabled."
     ]
    }
   ],
   "source": [
    "train_res = utils.test(loaders['train'], model, criterion, regularizer)\n",
    "test_res = utils.test(loaders['test'], model, criterion, regularizer)\n",
    "\n",
    "values = [epoch, lr, train_res['loss'], train_res['accuracy'], test_res['nll'],\n",
    "          test_res['accuracy'], time_ep]\n",
    "\n",
    "table = tabulate.tabulate([values], columns, tablefmt='simple', floatfmt='9.4f')\n",
    "if epoch % 40 == 1 or epoch == start_epoch:\n",
    "    table = table.split('\\n')\n",
    "    table = '\\n'.join([table[1]] + table)\n",
    "else:\n",
    "    table = table.split('\\n')[2]\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture = getattr(models, args.model)\n",
    "curve = getattr(curves, args.curve)\n",
    "\n",
    "curve_model = curves.CurveNet(\n",
    "    num_classes,\n",
    "    curve,\n",
    "    architecture.curve,\n",
    "    args.num_bends,\n",
    "    architecture_kwargs=architecture.kwargs,\n",
    ")\n",
    "curve_model.cuda()\n",
    "\n",
    "checkpoint = torch.load(args.ckpt)\n",
    "curve_model.load_state_dict(checkpoint['model_state'])\n",
    "\n",
    "criterion = F.cross_entropy\n",
    "regularizer = utils.l2_regularizer(args.wd)\n",
    "\n",
    "\n",
    "def get_xy(point, origin, vector_x, vector_y):\n",
    "    return np.array([np.dot(point - origin, vector_x), np.dot(point - origin, vector_y)])\n",
    "\n",
    "\n",
    "w = list()\n",
    "curve_parameters = list(curve_model.net.parameters())\n",
    "for i in range(args.num_bends):\n",
    "    w.append(np.concatenate([\n",
    "        p.data.cpu().numpy().ravel() for p in curve_parameters[i::args.num_bends]\n",
    "    ]))\n",
    "\n",
    "print('Weight space dimensionality: %d' % w[0].shape[0])\n",
    "\n",
    "u = w[2] - w[0]\n",
    "dx = np.linalg.norm(u)\n",
    "u /= dx\n",
    "\n",
    "v = w[1] - w[0]\n",
    "v -= np.dot(u, v) * u\n",
    "dy = np.linalg.norm(v)\n",
    "v /= dy\n",
    "\n",
    "bend_coordinates = np.stack(get_xy(p, w[0], u, v) for p in w)\n",
    "\n",
    "ts = np.linspace(0.0, 1.0, args.curve_points)\n",
    "curve_coordinates = []\n",
    "for t in np.linspace(0.0, 1.0, args.curve_points):\n",
    "    weights = curve_model.weights(torch.Tensor([t]).cuda())\n",
    "    curve_coordinates.append(get_xy(weights, w[0], u, v))\n",
    "curve_coordinates = np.stack(curve_coordinates)\n",
    "\n",
    "G = args.grid_points\n",
    "alphas = np.linspace(0.0 - args.margin_left, 1.0 + args.margin_right, G)\n",
    "betas = np.linspace(0.0 - args.margin_bottom, 1.0 + args.margin_top, G)\n",
    "\n",
    "tr_loss = np.zeros((G, G))\n",
    "tr_nll = np.zeros((G, G))\n",
    "tr_acc = np.zeros((G, G))\n",
    "tr_err = np.zeros((G, G))\n",
    "\n",
    "te_loss = np.zeros((G, G))\n",
    "te_nll = np.zeros((G, G))\n",
    "te_acc = np.zeros((G, G))\n",
    "te_err = np.zeros((G, G))\n",
    "\n",
    "grid = np.zeros((G, G, 2))\n",
    "\n",
    "base_model = architecture.base(num_classes, **architecture.kwargs)\n",
    "base_model.cuda()\n",
    "\n",
    "columns = ['X', 'Y', 'Train loss', 'Train nll', 'Train error (%)', 'Test nll', 'Test error (%)']\n",
    "\n",
    "for i, alpha in enumerate(alphas):\n",
    "    for j, beta in enumerate(betas):\n",
    "        p = w[0] + alpha * dx * u + beta * dy * v\n",
    "\n",
    "        offset = 0\n",
    "        for parameter in base_model.parameters():\n",
    "            size = np.prod(parameter.size())\n",
    "            value = p[offset:offset+size].reshape(parameter.size())\n",
    "            parameter.data.copy_(torch.from_numpy(value))\n",
    "            offset += size\n",
    "\n",
    "        utils.update_bn(loaders['train'], base_model)\n",
    "\n",
    "        tr_res = utils.test(loaders['train'], base_model, criterion, regularizer)\n",
    "        te_res = utils.test(loaders['test'], base_model, criterion, regularizer)\n",
    "\n",
    "        tr_loss_v, tr_nll_v, tr_acc_v = tr_res['loss'], tr_res['nll'], tr_res['accuracy']\n",
    "        te_loss_v, te_nll_v, te_acc_v = te_res['loss'], te_res['nll'], te_res['accuracy']\n",
    "\n",
    "        c = get_xy(p, w[0], u, v)\n",
    "        grid[i, j] = [alpha * dx, beta * dy]\n",
    "\n",
    "        tr_loss[i, j] = tr_loss_v\n",
    "        tr_nll[i, j] = tr_nll_v\n",
    "        tr_acc[i, j] = tr_acc_v\n",
    "        tr_err[i, j] = 100.0 - tr_acc[i, j]\n",
    "\n",
    "        te_loss[i, j] = te_loss_v\n",
    "        te_nll[i, j] = te_nll_v\n",
    "        te_acc[i, j] = te_acc_v\n",
    "        te_err[i, j] = 100.0 - te_acc[i, j]\n",
    "\n",
    "        values = [\n",
    "            grid[i, j, 0], grid[i, j, 1], tr_loss[i, j], tr_nll[i, j], tr_err[i, j],\n",
    "            te_nll[i, j], te_err[i, j]\n",
    "        ]\n",
    "        table = tabulate.tabulate([values], columns, tablefmt='simple', floatfmt='10.4f')\n",
    "        if j == 0:\n",
    "            table = table.split('\\n')\n",
    "            table = '\\n'.join([table[1]] + table)\n",
    "        else:\n",
    "            table = table.split('\\n')[2]\n",
    "        print(table)\n",
    "\n",
    "np.savez(\n",
    "    os.path.join(args.dir, 'plane.npz'),\n",
    "    ts=ts,\n",
    "    bend_coordinates=bend_coordinates,\n",
    "    curve_coordinates=curve_coordinates,\n",
    "    alphas=alphas,\n",
    "    betas=betas,\n",
    "    grid=grid,\n",
    "    tr_loss=tr_loss,\n",
    "    tr_acc=tr_acc,\n",
    "    tr_nll=tr_nll,\n",
    "    tr_err=tr_err,\n",
    "    te_loss=te_loss,\n",
    "    te_acc=te_acc,\n",
    "    te_nll=te_nll,\n",
    "    te_err=te_err\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(args.dir, exist_ok=True)\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "loaders, num_classes = data.loaders(\n",
    "    args.dataset,\n",
    "    args.data_path,\n",
    "    args.batch_size,\n",
    "    args.num_workers,\n",
    "    args.transform,\n",
    "    args.use_test,\n",
    "    shuffle_train=False\n",
    ")\n",
    "\n",
    "architecture = getattr(models, args.model)\n",
    "curve = getattr(curves, args.curve)\n",
    "\n",
    "curve_model = curves.CurveNet(\n",
    "    num_classes,\n",
    "    curve,\n",
    "    architecture.curve,\n",
    "    args.num_bends,\n",
    "    architecture_kwargs=architecture.kwargs,\n",
    ")\n",
    "curve_model.cuda()\n",
    "\n",
    "checkpoint = torch.load(args.ckpt)\n",
    "curve_model.load_state_dict(checkpoint['model_state'])\n",
    "\n",
    "criterion = F.cross_entropy\n",
    "regularizer = utils.l2_regularizer(args.wd)\n",
    "\n",
    "\n",
    "def get_xy(point, origin, vector_x, vector_y):\n",
    "    return np.array([np.dot(point - origin, vector_x), np.dot(point - origin, vector_y)])\n",
    "\n",
    "\n",
    "w = list()\n",
    "curve_parameters = list(curve_model.net.parameters())\n",
    "for i in range(args.num_bends):\n",
    "    w.append(np.concatenate([\n",
    "        p.data.cpu().numpy().ravel() for p in curve_parameters[i::args.num_bends]\n",
    "    ]))\n",
    "\n",
    "print('Weight space dimensionality: %d' % w[0].shape[0])\n",
    "\n",
    "u = w[2] - w[0]\n",
    "dx = np.linalg.norm(u)\n",
    "u /= dx\n",
    "\n",
    "v = w[1] - w[0]\n",
    "v -= np.dot(u, v) * u\n",
    "dy = np.linalg.norm(v)\n",
    "v /= dy\n",
    "\n",
    "bend_coordinates = np.stack(get_xy(p, w[0], u, v) for p in w)\n",
    "\n",
    "ts = np.linspace(0.0, 1.0, args.curve_points)\n",
    "curve_coordinates = []\n",
    "for t in np.linspace(0.0, 1.0, args.curve_points):\n",
    "    weights = curve_model.weights(torch.Tensor([t]).cuda())\n",
    "    curve_coordinates.append(get_xy(weights, w[0], u, v))\n",
    "curve_coordinates = np.stack(curve_coordinates)\n",
    "\n",
    "G = args.grid_points\n",
    "alphas = np.linspace(0.0 - args.margin_left, 1.0 + args.margin_right, G)\n",
    "betas = np.linspace(0.0 - args.margin_bottom, 1.0 + args.margin_top, G)\n",
    "\n",
    "tr_loss = np.zeros((G, G))\n",
    "tr_nll = np.zeros((G, G))\n",
    "tr_acc = np.zeros((G, G))\n",
    "tr_err = np.zeros((G, G))\n",
    "\n",
    "te_loss = np.zeros((G, G))\n",
    "te_nll = np.zeros((G, G))\n",
    "te_acc = np.zeros((G, G))\n",
    "te_err = np.zeros((G, G))\n",
    "\n",
    "grid = np.zeros((G, G, 2))\n",
    "\n",
    "base_model = architecture.base(num_classes, **architecture.kwargs)\n",
    "base_model.cuda()\n",
    "\n",
    "columns = ['X', 'Y', 'Train loss', 'Train nll', 'Train error (%)', 'Test nll', 'Test error (%)']\n",
    "\n",
    "for i, alpha in enumerate(alphas):\n",
    "    for j, beta in enumerate(betas):\n",
    "        p = w[0] + alpha * dx * u + beta * dy * v\n",
    "\n",
    "        offset = 0\n",
    "        for parameter in base_model.parameters():\n",
    "            size = np.prod(parameter.size())\n",
    "            value = p[offset:offset+size].reshape(parameter.size())\n",
    "            parameter.data.copy_(torch.from_numpy(value))\n",
    "            offset += size\n",
    "\n",
    "        utils.update_bn(loaders['train'], base_model)\n",
    "\n",
    "        tr_res = utils.test(loaders['train'], base_model, criterion, regularizer)\n",
    "        te_res = utils.test(loaders['test'], base_model, criterion, regularizer)\n",
    "\n",
    "        tr_loss_v, tr_nll_v, tr_acc_v = tr_res['loss'], tr_res['nll'], tr_res['accuracy']\n",
    "        te_loss_v, te_nll_v, te_acc_v = te_res['loss'], te_res['nll'], te_res['accuracy']\n",
    "\n",
    "        c = get_xy(p, w[0], u, v)\n",
    "        grid[i, j] = [alpha * dx, beta * dy]\n",
    "\n",
    "        tr_loss[i, j] = tr_loss_v\n",
    "        tr_nll[i, j] = tr_nll_v\n",
    "        tr_acc[i, j] = tr_acc_v\n",
    "        tr_err[i, j] = 100.0 - tr_acc[i, j]\n",
    "\n",
    "        te_loss[i, j] = te_loss_v\n",
    "        te_nll[i, j] = te_nll_v\n",
    "        te_acc[i, j] = te_acc_v\n",
    "        te_err[i, j] = 100.0 - te_acc[i, j]\n",
    "\n",
    "        values = [\n",
    "            grid[i, j, 0], grid[i, j, 1], tr_loss[i, j], tr_nll[i, j], tr_err[i, j],\n",
    "            te_nll[i, j], te_err[i, j]\n",
    "        ]\n",
    "        table = tabulate.tabulate([values], columns, tablefmt='simple', floatfmt='10.4f')\n",
    "        if j == 0:\n",
    "            table = table.split('\\n')\n",
    "            table = '\\n'.join([table[1]] + table)\n",
    "        else:\n",
    "            table = table.split('\\n')[2]\n",
    "        print(table)\n",
    "\n",
    "np.savez(\n",
    "    os.path.join(args.dir, 'plane.npz'),\n",
    "    ts=ts,\n",
    "    bend_coordinates=bend_coordinates,\n",
    "    curve_coordinates=curve_coordinates,\n",
    "    alphas=alphas,\n",
    "    betas=betas,\n",
    "    grid=grid,\n",
    "    tr_loss=tr_loss,\n",
    "    tr_acc=tr_acc,\n",
    "    tr_nll=tr_nll,\n",
    "    tr_err=tr_err,\n",
    "    te_loss=te_loss,\n",
    "    te_acc=te_acc,\n",
    "    te_nll=te_nll,\n",
    "    te_err=te_err\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
