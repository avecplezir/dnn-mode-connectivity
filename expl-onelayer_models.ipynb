{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/anokhin/distribution_connector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/anokhin/dnn-mode-connectivity',\n",
       " '/home/anokhin/anaconda3/lib/python37.zip',\n",
       " '/home/anokhin/anaconda3/lib/python3.7',\n",
       " '/home/anokhin/anaconda3/lib/python3.7/lib-dynload',\n",
       " '',\n",
       " '/home/anokhin/anaconda3/lib/python3.7/site-packages',\n",
       " '/home/anokhin/anaconda3/lib/python3.7/site-packages/IPython/extensions',\n",
       " '/home/anokhin/.ipython',\n",
       " '/home/anokhin/distribution_connector']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from connector import Connector\n",
    "from one_layer_utils import samples, make_dataset, get_model, get_b\n",
    "from utils import test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # making CIFAR dataset\n",
    "# import models\n",
    "# architecture = getattr(models, \"LinearOneLayerCF\") #LinearOneLayer LogRegression\n",
    "\n",
    "# dataset, B = make_dataset(model_dir='curves/LinearOneLayer/curve', \n",
    "#              dataset='CIFAR', \n",
    "#              architecture=architecture, \n",
    "#              N_models=21, check=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # making MNIST dataset\n",
    "# import models\n",
    "# architecture = getattr(models, \"LinearOneLayer\") #LinearOneLayer LogRegression\n",
    "\n",
    "# dataset, B = make_dataset(model_dir='curves_mnist/LinearOneLayer/LongTraining/curve', \n",
    "#              dataset='MNIST', \n",
    "#              architecture=architecture, \n",
    "#              N_models=61, check=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.shape, B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask len 10\n"
     ]
    }
   ],
   "source": [
    "from flows.models.RNVP import RealNVP, RealNVP_OneLayer\n",
    "from flows.models.IAF import Flow_IAF\n",
    "flow_RNVP = RealNVP(in_dim=795, dim_middle=1000, N_layers=5, batch_norm=True)\n",
    "flow_IAF = Flow_IAF(in_dim=795, dim_middle=1000, N_layers=5, batch_norm=True)\n",
    "\n",
    "flow_RNVP.load_state_dict(torch.load('/home/anokhin/distribution_connector/flow_models/RealNVP/MNIST/checkpoint-100.pt')['model_state'])\n",
    "flow_IAF.load_state_dict(torch.load('/home/anokhin/distribution_connector/flow_models/Flow_IAF/MNIST/checkpoint-100.pt')['model_state'])\n",
    "\n",
    "flows = [flow_RNVP, flow_IAF]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using train (45000) + validation (5000)\n",
      "len 55000\n"
     ]
    }
   ],
   "source": [
    "import models\n",
    "architecture = getattr(models, \"LinearOneLayer\") #LinearOneLayer LogRegression\n",
    "\n",
    "model1 = architecture.base(num_classes=10, **architecture.kwargs)\n",
    "model2 = architecture.base(num_classes=10, **architecture.kwargs)\n",
    "\n",
    "model1.load_state_dict(torch.load('curves_mnist/LinearOneLayer/LongTraining/curve30/checkpoint-30.pt')['model_state'])\n",
    "model2.load_state_dict(torch.load('curves_mnist/LinearOneLayer/LongTraining/curve40/checkpoint-30.pt')['model_state'])\n",
    "\n",
    "mnist = [samples(model1), samples(model2)]\n",
    "\n",
    "import data\n",
    "loaders, num_classes = data.loaders(\n",
    "    \"MNIST\",\n",
    "    \"data\",\n",
    "    1024,\n",
    "    1,\n",
    "    \"VGG\",\n",
    "    False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def test(dataset, K=80, show=False, verbose=False):\n",
    "    stat = {}\n",
    "    stat['train'] = {}\n",
    "    stat['test'] = {}\n",
    "    \n",
    "    flow_ind = 0\n",
    "    t = np.linspace(0,1, 3)[1:-1]\n",
    "    if verbose:\n",
    "        print('True models: ')\n",
    "        test_model(model1, loaders)\n",
    "        test_model(model2, loaders)\n",
    "    cntr = Connector(*dataset)\n",
    "    funcs = [func for func in dir(cntr) if callable(getattr(cntr, func)) and 'connect' in func] #+ ['flow_connect']\n",
    "    for f in funcs:\n",
    "        func = getattr(cntr, f)\n",
    "        if verbose:\n",
    "            print(func.__name__)\n",
    "        if func.__name__=='flow_connect':\n",
    "            continue\n",
    "            flow = flows[flow_ind] \n",
    "            flow_ind+=1\n",
    "            print(flow.__class__.__name__)\n",
    "            res = func(flow, t=t)\n",
    "        elif func.__name__=='third_cumulant_connect':\n",
    "            continue\n",
    "            res = func(t=t, K=80, coef=0.5)\n",
    "        elif func.__name__=='arc_connect':\n",
    "#             continue\n",
    "            res = func(t=t)\n",
    "        elif 'arc' in func.__name__ and 'PCA' in func.__name__:\n",
    "#             continue\n",
    "            res = func(t=t, K=K)\n",
    "        else:\n",
    "#             continue\n",
    "            res = func(t=t)\n",
    "\n",
    "        b = get_b(model1, model2)\n",
    "        for ind, r in enumerate(res[1:-1]):\n",
    "            if verbose:\n",
    "                print(ind)\n",
    "            model = get_model(r, b, architecture)\n",
    "            train_res, test_res = test_model(model, loaders, verbose=verbose)\n",
    "            stat['train'][func.__name__] = train_res['accuracy']\n",
    "            stat['test'][func.__name__] = test_res['accuracy']\n",
    "        if show:\n",
    "            cntr.show_samples(res, show='hex', limits=False)\n",
    "    return stat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RealNVP\n",
      "RealNVP\n",
      "RealNVP\n"
     ]
    }
   ],
   "source": [
    "mnist_stat = []\n",
    "for i in tqdm(range(1, 5)):\n",
    "    for j in range(i+1, 5):\n",
    "        model1.load_state_dict(torch.load('curves_mnist/LinearOneLayer/LongTraining/curve'+str(30+i)+'/checkpoint-30.pt')['model_state'])\n",
    "        model2.load_state_dict(torch.load('curves_mnist/LinearOneLayer/LongTraining/curve'+str(30+j)+'/checkpoint-30.pt')['model_state'])\n",
    "\n",
    "        mnist = [samples(model1), samples(model2)]\n",
    "        stat = test(mnist, K=70)\n",
    "        mnist_stat.append(stat)\n",
    "        \n",
    "mnist_dict = {'train':{}, 'test':{}}\n",
    "for k1 in mnist_stat[0].keys():\n",
    "    for k2 in stat[k1].keys():\n",
    "        mnist_dict[k1][k2] = []\n",
    "    \n",
    "for stat in mnist_stat:\n",
    "    for k1 in stat.keys():\n",
    "        for k2 in stat[k1].keys():\n",
    "            mnist_dict[k1][k2].append(stat[k1][k2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dict = {'train':{}, 'test':{}}\n",
    "for k1 in mnist_stat[0].keys():\n",
    "    for k2 in stat[k1].keys():\n",
    "        mnist_dict[k1][k2] = []\n",
    "    \n",
    "for stat in mnist_stat:\n",
    "    for k1 in stat.keys():\n",
    "        for k2 in stat[k1].keys():\n",
    "            mnist_dict[k1][k2].append(stat[k1][k2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': {'arc_connect': [97.91636363636364,\n",
       "   97.81636363636363,\n",
       "   97.58727272727273,\n",
       "   97.81272727272727,\n",
       "   97.7909090909091,\n",
       "   97.86727272727273],\n",
       "  'arc_connect_PCA': [97.59454545454545,\n",
       "   97.5490909090909,\n",
       "   97.49272727272728,\n",
       "   97.45454545454545,\n",
       "   97.48727272727272,\n",
       "   97.66545454545455],\n",
       "  'arc_connect_PCA_std': [97.60181818181819,\n",
       "   97.57272727272728,\n",
       "   97.49818181818182,\n",
       "   97.44727272727273,\n",
       "   97.46363636363637,\n",
       "   97.66181818181818],\n",
       "  'arc_connect_std': [97.91636363636364,\n",
       "   97.81636363636363,\n",
       "   97.58727272727273,\n",
       "   97.81272727272727,\n",
       "   97.7909090909091,\n",
       "   97.86727272727273],\n",
       "  'flow_connect': [97.00545454545454,\n",
       "   96.88181818181818,\n",
       "   96.23818181818181,\n",
       "   96.98727272727272,\n",
       "   96.62181818181818,\n",
       "   96.92727272727272],\n",
       "  'inverse_connect': [97.87636363636364,\n",
       "   97.74909090909091,\n",
       "   97.58,\n",
       "   97.84727272727272,\n",
       "   97.79272727272728,\n",
       "   97.84],\n",
       "  'inverse_connect_PCA': [97.66,\n",
       "   97.48181818181818,\n",
       "   97.4290909090909,\n",
       "   97.55818181818182,\n",
       "   97.55636363636364,\n",
       "   97.5909090909091],\n",
       "  'lin_connect': [96.52363636363637,\n",
       "   96.1290909090909,\n",
       "   96.44727272727273,\n",
       "   96.61636363636363,\n",
       "   96.62727272727273,\n",
       "   97.30181818181818],\n",
       "  'lin_connect_PCA': [27.35090909090909,\n",
       "   27.28,\n",
       "   27.27090909090909,\n",
       "   27.645454545454545,\n",
       "   27.543636363636363,\n",
       "   27.69090909090909],\n",
       "  'simul_diag_connect': [97.86545454545454,\n",
       "   97.75272727272727,\n",
       "   97.57454545454546,\n",
       "   97.77090909090909,\n",
       "   97.74545454545455,\n",
       "   97.85090909090908],\n",
       "  'third_cumulant_connect': [81.61636363636363,\n",
       "   78.04545454545455,\n",
       "   79.47636363636363,\n",
       "   83.01454545454546,\n",
       "   81.67090909090909,\n",
       "   80.66363636363636],\n",
       "  'two_simul_diag_connect': [12.238181818181818,\n",
       "   30.56,\n",
       "   31.887272727272727,\n",
       "   15.212727272727273,\n",
       "   14.367272727272727,\n",
       "   13.838181818181818]},\n",
       " 'test': {'arc_connect': [97.64, 97.46, 97.1, 97.36, 97.38, 97.34],\n",
       "  'arc_connect_PCA': [97.56, 97.46, 97.34, 97.38, 97.26, 97.38],\n",
       "  'arc_connect_PCA_std': [97.54, 97.42, 97.26, 97.42, 97.28, 97.46],\n",
       "  'arc_connect_std': [97.64, 97.46, 97.1, 97.36, 97.38, 97.34],\n",
       "  'flow_connect': [96.9, 96.88, 95.84, 96.92, 96.3, 96.66],\n",
       "  'inverse_connect': [97.62, 97.38, 96.94, 97.44, 97.42, 97.24],\n",
       "  'inverse_connect_PCA': [97.46, 97.02, 97.02, 97.26, 97.28, 97.18],\n",
       "  'lin_connect': [96.56, 95.98, 96.08, 96.54, 96.34, 96.8],\n",
       "  'lin_connect_PCA': [28.84, 28.66, 28.7, 29.02, 29.1, 29.12],\n",
       "  'simul_diag_connect': [97.62, 97.32, 97.16, 97.26, 97.34, 97.38],\n",
       "  'third_cumulant_connect': [83.2, 80.12, 81.96, 83.88, 82.6, 81.96],\n",
       "  'two_simul_diag_connect': [12.24, 29.98, 34.36, 14.82, 13.9, 12.98]}}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "==========\n",
      "arc_connect\n",
      "--------------------\n",
      "mean 97.79848484848486\n",
      "2 std 0.20626460490349757\n",
      "arc_connect_PCA\n",
      "--------------------\n",
      "mean 97.54060606060607\n",
      "2 std 0.14401816026698105\n",
      "arc_connect_PCA_std\n",
      "--------------------\n",
      "mean 97.5409090909091\n",
      "2 std 0.15471648290548537\n",
      "arc_connect_std\n",
      "--------------------\n",
      "mean 97.79848484848486\n",
      "2 std 0.20626460490349757\n",
      "flow_connect\n",
      "--------------------\n",
      "mean 96.77696969696969\n",
      "2 std 0.5442923645845906\n",
      "inverse_connect\n",
      "--------------------\n",
      "mean 97.78090909090908\n",
      "2 std 0.19752462621514516\n",
      "inverse_connect_PCA\n",
      "--------------------\n",
      "mean 97.5460606060606\n",
      "2 std 0.14844897525843914\n",
      "lin_connect\n",
      "--------------------\n",
      "mean 96.60757575757576\n",
      "2 std 0.7043334317663482\n",
      "lin_connect_PCA\n",
      "--------------------\n",
      "mean 27.463636363636365\n",
      "2 std 0.3412567923823748\n",
      "simul_diag_connect\n",
      "--------------------\n",
      "mean 97.75999999999999\n",
      "2 std 0.19002102247044605\n",
      "third_cumulant_connect\n",
      "--------------------\n",
      "mean 80.74787878787879\n",
      "2 std 3.232230705746402\n",
      "two_simul_diag_connect\n",
      "--------------------\n",
      "mean 19.683939393939397\n",
      "2 std 16.433317955502165\n",
      "test\n",
      "==========\n",
      "arc_connect\n",
      "--------------------\n",
      "mean 97.38\n",
      "2 std 0.32083225108042807\n",
      "arc_connect_PCA\n",
      "--------------------\n",
      "mean 97.39666666666666\n",
      "2 std 0.188207922846572\n",
      "arc_connect_PCA_std\n",
      "--------------------\n",
      "mean 97.39666666666669\n",
      "2 std 0.19652537297311481\n",
      "arc_connect_std\n",
      "--------------------\n",
      "mean 97.38\n",
      "2 std 0.32083225108042807\n",
      "flow_connect\n",
      "--------------------\n",
      "mean 96.58333333333333\n",
      "2 std 0.7917631520151008\n",
      "inverse_connect\n",
      "--------------------\n",
      "mean 97.33999999999999\n",
      "2 std 0.4214261501141134\n",
      "inverse_connect_PCA\n",
      "--------------------\n",
      "mean 97.20333333333333\n",
      "2 std 0.30847294136691417\n",
      "lin_connect\n",
      "--------------------\n",
      "mean 96.38333333333333\n",
      "2 std 0.5691709370264386\n",
      "lin_connect_PCA\n",
      "--------------------\n",
      "mean 28.906666666666666\n",
      "2 std 0.3685406656289411\n",
      "simul_diag_connect\n",
      "--------------------\n",
      "mean 97.34666666666668\n",
      "2 std 0.28158282775924176\n",
      "third_cumulant_connect\n",
      "--------------------\n",
      "mean 82.28666666666666\n",
      "2 std 2.363462619876934\n",
      "two_simul_diag_connect\n",
      "--------------------\n",
      "mean 19.713333333333335\n",
      "2 std 17.867238796809712\n"
     ]
    }
   ],
   "source": [
    "for k1 in mnist_stat[0].keys():\n",
    "    print(k1)\n",
    "    print('='*10)\n",
    "    for k2 in stat[k1].keys():\n",
    "        print(k2)\n",
    "        print('-'*20)\n",
    "        print('mean', np.array(mnist_dict[k1][k2]).mean())\n",
    "        print('2 std', 2*np.array(mnist_dict[k1][k2]).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# flow = RealNVP(in_dim=3083, dim_middle=1000, N_layers=5, batch_norm=True)\n",
    "# flow.load_state_dict(torch.load('/home/anokhin/distribution_connector/flow_models/RealNVP/CIFAR/checkpoint-100.pt')['model_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask len 10\n"
     ]
    }
   ],
   "source": [
    "from flows.models.RNVP import RealNVP\n",
    "from flows.models.IAF import Flow_IAF\n",
    "flow_RNVP = RealNVP(in_dim=3083, dim_middle=1000, N_layers=5, batch_norm=True)\n",
    "flow_IAF = Flow_IAF(in_dim=3083, dim_middle=1000, N_layers=5, batch_norm=True)\n",
    "\n",
    "flow_RNVP.load_state_dict(torch.load('/home/anokhin/distribution_connector/flow_models/RealNVP/CIFAR/checkpoint-100.pt')['model_state'])\n",
    "flow_IAF.load_state_dict(torch.load('/home/anokhin/distribution_connector/flow_models/Flow_IAF/CIFAR/checkpoint-100.pt')['model_state'])\n",
    "\n",
    "flows = [flow_RNVP, ] #flow_IAF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Using train (45000) + validation (5000)\n",
      "len 45000\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import models\n",
    "architecture = getattr(models, \"LinearOneLayerCF\") #LinearOneLayer LogRegression\n",
    "\n",
    "model1 = architecture.base(num_classes=10, **architecture.kwargs)\n",
    "model2 = architecture.base(num_classes=10, **architecture.kwargs)\n",
    "\n",
    "model1.load_state_dict(torch.load('curves/LinearOneLayer/curve1/checkpoint-400.pt')['model_state'])\n",
    "model2.load_state_dict(torch.load('curves/LinearOneLayer/curve2/checkpoint-400.pt')['model_state'])\n",
    "\n",
    "cifar = [samples(model1), samples(model2)]\n",
    "test_datasets = [cifar]\n",
    "\n",
    "import data\n",
    "loaders, num_classes = data.loaders(\n",
    "    \"CIFAR10\",\n",
    "    \"data\",\n",
    "    128,\n",
    "    1,\n",
    "    \"VGG\",\n",
    "    False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 25%|██▌       | 1/4 [28:44<1:26:13, 1724.37s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████     | 2/4 [48:01<51:48, 1554.12s/it]  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 75%|███████▌  | 3/4 [57:32<20:59, 1259.38s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 4/4 [57:32<00:00, 863.22s/it] \u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "mnist_stat = []\n",
    "for i in tqdm(range(1, 5)):\n",
    "    for j in range(i+1, 5):\n",
    "        model1.load_state_dict(torch.load('curves/LinearOneLayer/curve'+str(1+i)+'/checkpoint-400.pt')['model_state'])\n",
    "        model2.load_state_dict(torch.load('curves/LinearOneLayer/curve'+str(1+j)+'/checkpoint-400.pt')['model_state'])\n",
    "\n",
    "        mnist = [samples(model1), samples(model2)]\n",
    "        stat = test(cifar, K=300)\n",
    "        mnist_stat.append(stat)\n",
    "        \n",
    "mnist_dict = {'train':{}, 'test':{}}\n",
    "for k1 in mnist_stat[0].keys():\n",
    "    for k2 in stat[k1].keys():\n",
    "        mnist_dict[k1][k2] = []\n",
    "    \n",
    "for stat in mnist_stat:\n",
    "    for k1 in stat.keys():\n",
    "        for k2 in stat[k1].keys():\n",
    "            mnist_dict[k1][k2].append(stat[k1][k2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "==========\n",
      "arc_connect\n",
      "--------------------\n",
      "mean 49.08592592592593\n",
      "2 std 0.4062367017977545\n",
      "arc_connect_PCA\n",
      "--------------------\n",
      "mean 49.038148148148146\n",
      "2 std 0.17500460507364218\n",
      "arc_connect_PCA_std\n",
      "--------------------\n",
      "mean 49.17777777777778\n",
      "2 std 0.5553303247143282\n",
      "arc_connect_std\n",
      "--------------------\n",
      "mean 49.227037037037036\n",
      "2 std 0.5727439788377742\n",
      "inverse_connect\n",
      "--------------------\n",
      "mean 40.05148148148148\n",
      "2 std 0.35541123614259573\n",
      "inverse_connect_PCA\n",
      "--------------------\n",
      "mean 36.13296296296296\n",
      "2 std 0.5068967422170262\n",
      "lin_connect\n",
      "--------------------\n",
      "mean 30.03222222222222\n",
      "2 std 0.32386300004531887\n",
      "lin_connect_PCA\n",
      "--------------------\n",
      "mean 10.309259259259258\n",
      "2 std 0.053605273781868704\n",
      "simul_diag_connect\n",
      "--------------------\n",
      "mean 38.26666666666666\n",
      "2 std 0.3044363340363334\n",
      "two_simul_diag_connect\n",
      "--------------------\n",
      "mean 11.60074074074074\n",
      "2 std 0.1968921773267175\n",
      "test\n",
      "==========\n",
      "arc_connect\n",
      "--------------------\n",
      "mean 39.68\n",
      "2 std 0.040000000000001514\n",
      "arc_connect_PCA\n",
      "--------------------\n",
      "mean 40.446666666666665\n",
      "2 std 0.2815828277592401\n",
      "arc_connect_PCA_std\n",
      "--------------------\n",
      "mean 40.38333333333333\n",
      "2 std 0.298812464413533\n",
      "arc_connect_std\n",
      "--------------------\n",
      "mean 39.68\n",
      "2 std 0.040000000000001514\n",
      "inverse_connect\n",
      "--------------------\n",
      "mean 33.86000000000001\n",
      "2 std 0.07302967433402449\n",
      "inverse_connect_PCA\n",
      "--------------------\n",
      "mean 29.736666666666665\n",
      "2 std 0.08137703743822539\n",
      "lin_connect\n",
      "--------------------\n",
      "mean 37.85\n",
      "2 std 0.2100793500878492\n",
      "lin_connect_PCA\n",
      "--------------------\n",
      "mean 12.840000000000002\n",
      "2 std 0.10327955589886455\n",
      "simul_diag_connect\n",
      "--------------------\n",
      "mean 34.21666666666667\n",
      "2 std 0.15902480589169163\n",
      "two_simul_diag_connect\n",
      "--------------------\n",
      "mean 11.92\n",
      "2 std 0.0\n"
     ]
    }
   ],
   "source": [
    "for k1 in mnist_stat[0].keys():\n",
    "    print(k1)\n",
    "    print('='*10)\n",
    "    for k2 in stat[k1].keys():\n",
    "        print(k2)\n",
    "        print('-'*20)\n",
    "        print('mean', np.array(mnist_dict[k1][k2]).mean())\n",
    "        print('2 std', 2*np.array(mnist_dict[k1][k2]).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# test(K=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
