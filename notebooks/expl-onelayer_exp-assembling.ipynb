{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/ivan/distribution_connector')\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from connector_utils import test_models, gather_statistics, test_func\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from connector import Connector\n",
    "# from one_layer_utils import samples, make_dataset, get_model, get_b\n",
    "from utils import test_model\n",
    "from flows.models.utils import test_flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are going to run models on the test set. Are you sure?\n"
     ]
    }
   ],
   "source": [
    "import models\n",
    "architecture = getattr(models, \"LinearOneLayer\") #LinearOneLayer LogRegression\n",
    "\n",
    "import data\n",
    "loaders, num_classes = data.loaders(\n",
    "    \"MNIST\",\n",
    "    \"data\",\n",
    "    1024,\n",
    "    1,\n",
    "    \"VGG\",\n",
    "    True,\n",
    "    shuffle_train=False)\n",
    "\n",
    "model1 = architecture.base(num_classes=10, **architecture.kwargs)\n",
    "model2 = architecture.base(num_classes=10, **architecture.kwargs)\n",
    "\n",
    "model1.load_state_dict(torch.load('curves_mnist/LinearOneLayer/LongTraining/curve16/checkpoint-30.pt')['model_state'])\n",
    "model2.load_state_dict(torch.load('curves_mnist/LinearOneLayer/LongTraining/curve17/checkpoint-30.pt')['model_state'])\n",
    "\n",
    "import pickle\n",
    "data_path = '/home/ivan/dnn-mode-connectivity/data/MNIST.pickle'\n",
    "with open(data_path, 'rb') as handle:\n",
    "    dataset, B = pickle.load(handle)\n",
    "b2 = torch.FloatTensor([np.array(B).mean(0)])\n",
    "b = np.array(B).mean(0)\n",
    "\n",
    "train_dataset, test_dataset = dataset[:-8000], dataset[-8000:]\n",
    "modes = [dataset[-4000:-2000], dataset[-2000:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def samples(model):\n",
    "    p = [list(model.parameters())[i].data.cpu().numpy() for i in range(len(list(model.parameters())))]\n",
    "    return p\n",
    "\n",
    "def samples_per_layer(model, bias=True):\n",
    "    p = samples(model)\n",
    "    if bias:\n",
    "        p = [np.hstack([p[i], p[i+1][:, None]]) for i in range(0, len(p), 2)]        \n",
    "    return p\n",
    "\n",
    "def samples_butterfly(model, bias=True):\n",
    "    if bias:\n",
    "        return None\n",
    "    else:   \n",
    "        p = samples_per_layer(model, bias=bias)\n",
    "        parameters = [np.hstack([p[i], p[i+1].T]) for i in range(0, len(p), 2)]\n",
    "    return parameters\n",
    "\n",
    "def get_model(W, architecture, bias=False, per_layer=True):\n",
    "    model_sampled = architecture.base(num_classes=10, **architecture.kwargs)\n",
    "    model_samples = np.array(W)  \n",
    "\n",
    "    if per_layer:\n",
    "        for parameter, w in zip(model_sampled.parameters(), W):\n",
    "            parameter.data.copy_(torch.from_numpy(w))\n",
    "    else:\n",
    "        for i, parameter in enumerate(model_sampled.parameters()):\n",
    "            w = W[i//2]\n",
    "            if i % 2 == 0:\n",
    "                offset = 0\n",
    "            N = parameter.data.shape[1]\n",
    "            w_part = w[:, offset:offset+N]\n",
    "            offset = N\n",
    "            if i % 2 == 0:\n",
    "                parameter.data.copy_(torch.from_numpy(w_part))\n",
    "            else:\n",
    "                parameter.data.copy_(torch.from_numpy(w_part.T))\n",
    "            \n",
    "\n",
    "    return model_sampled\n",
    "\n",
    "def get_model(W, B, architecture):\n",
    "    model_sampled = architecture.base(num_classes=10, **architecture.kwargs)\n",
    "    model_samples = np.array(W)  # .cpu().data.numpy()\n",
    "    SIZE = model_sampled.middle_dim\n",
    "\n",
    "    offset = 0\n",
    "    for parameter in list(model_sampled.parameters())[:-1]:\n",
    "        size = int(np.prod(parameter.size()) / SIZE)\n",
    "        value = model_samples[:, offset:offset + size]\n",
    "        if size == 10 or size == 1:\n",
    "            value = value.T\n",
    "        value = value.reshape(parameter.size())\n",
    "        parameter.data.copy_(torch.from_numpy(value))\n",
    "        offset += size\n",
    "\n",
    "    list(model_sampled.parameters())[-1].data.copy_(B.mean(0))  # torch.from_numpy(\n",
    "\n",
    "    return model_sampled\n",
    "\n",
    "def samples(model):\n",
    "    p1 = list(model.parameters())[0].data.cpu().numpy()\n",
    "    p2 = list(model.parameters())[1].data.cpu().numpy()\n",
    "    p3 = list(model.parameters())[2].transpose(0, 1).data.cpu().numpy()\n",
    "    samples = np.hstack([p1, p2[:, None], p3])\n",
    "    return samples\n",
    "\n",
    "def transform(x1, x2, E12, E22_inv):\n",
    "#     print(x1.shape, x2.shape, E12.shape, E22_inv.shape)\n",
    "    y1 = x1 - E12 @ E22_inv @ x2\n",
    "    return np.concatenate([y1, x2]).T\n",
    "   \n",
    "def inv_transform(y1, y2, E12, E22_inv):\n",
    "#     print(x1.shape, x2.shape, E12.shape, E22_inv.shape)\n",
    "    x1 = y1 + E12 @ E22_inv @ y2\n",
    "    return np.concatenate([x1, y2]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters1 = samples(model1)\n",
    "# parameters2 = samples(model2)\n",
    "\n",
    "# parameters = np.concatenate([parameters1, parameters2])\n",
    "\n",
    "# p = parameters - parameters.mean(0) \n",
    "# cov = p.T @ p\n",
    "# E12 = cov[:-10, -10:]\n",
    "# E22 = cov[-10:, -10:]\n",
    "# E22_inv = np.linalg.inv(E22)\n",
    "\n",
    "# parameters1_tr = transform(parameters1[:, :-10].T, parameters1[:, -10:].T, E12,  E22_inv)\n",
    "# parameters2_tr = transform(parameters2[:, :-10].T, parameters2[:, -10:].T, E12,  E22_inv)\n",
    "\n",
    "# func = 'arc_connect'\n",
    "# print(func)\n",
    "# cntr = Connector(parameters1_tr, parameters2_tr)\n",
    "# f = getattr(cntr, func)\n",
    "# parameters_res = f()[1]\n",
    "\n",
    "# parameters_res_tr = inv_transform(parameters_res[:, :-10].T, parameters_res[:, -10:].T, E12,  E22_inv)\n",
    "\n",
    "# model = get_model(parameters_res_tr, b2, architecture)\n",
    "# model.cuda();\n",
    "# model.eval();\n",
    "# test_model(model, loaders, cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = get_model(parameters_res_tr, b2, architecture)\n",
    "# model.cuda();\n",
    "# model.eval();\n",
    "# test_model(model, loaders, cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train results {'nll': 0.03932116087873777, 'loss': 0.03932116087873777, 'accuracy': 99.13833333333334}\n",
      "test results {'nll': 0.06698885906934739, 'loss': 0.06698885906934739, 'accuracy': 98.03}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'nll': 0.03932116087873777,\n",
       "  'loss': 0.03932116087873777,\n",
       "  'accuracy': 99.13833333333334},\n",
       " {'nll': 0.06698885906934739, 'loss': 0.06698885906934739, 'accuracy': 98.03})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.cuda();\n",
    "model1.eval();\n",
    "test_model(model1, loaders, cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train results {'nll': 0.03909178083936373, 'loss': 0.03909178083936373, 'accuracy': 99.13666666666667}\n",
      "test results {'nll': 0.06854327906370163, 'loss': 0.06854327906370163, 'accuracy': 98.02}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'nll': 0.03909178083936373,\n",
       "  'loss': 0.03909178083936373,\n",
       "  'accuracy': 99.13666666666667},\n",
       " {'nll': 0.06854327906370163, 'loss': 0.06854327906370163, 'accuracy': 98.02})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.cuda();\n",
    "model2.eval();\n",
    "test_model(model2, loaders, cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model1, model2]\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.03\n",
      "98.02\n",
      "final 98.08\n"
     ]
    }
   ],
   "source": [
    "ensemble_size = 0\n",
    "predictions_sum = 0\n",
    "for model in models:\n",
    "    predictions, targets = utils.predictions(loaders['test'], model)\n",
    "    ensemble_size += 1\n",
    "    predictions_sum += predictions\n",
    "#     print(predictions_sum[:10])\n",
    "    ens_acc = 100.0 * np.mean(np.argmax(predictions, axis=1) == targets)\n",
    "    print(ens_acc)\n",
    "    \n",
    "ens_acc = 100.0 * np.mean(np.argmax(predictions_sum, axis=1) == targets)\n",
    "print('final', ens_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble_size = 0\n",
    "# predictions_sum = 0\n",
    "# for model in models:\n",
    "#     predictions, targets = utils.predictions(loaders['test'], model)\n",
    "#     ensemble_size += 1\n",
    "#     predictions_sum += predictions\n",
    "# #     print(predictions_sum[:10])\n",
    "#     ens_acc = 100.0 * np.mean(np.argmax(predictions, axis=1) == targets)\n",
    "#     print(ens_acc)\n",
    "    \n",
    "# ens_acc = 100.0 * np.mean(np.argmax(predictions_sum, axis=1) == targets)\n",
    "# print('final', ens_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.cpu(); model2.cpu();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask len 2\n"
     ]
    }
   ],
   "source": [
    "from flows.models import RealNVP, RealNVP_OneLayer_full\n",
    "\n",
    "flow = RealNVP_OneLayer_full(in_dim=795, dim_middle=2000, N_layers=1, batch_norm=True, data_b2=b)\n",
    "flow.load_state_dict(torch.load('/home/ivan/distribution_connector/flow_models/RealNVP/MNIST_bijection/checkpoint-20.pt')['model_state'])\n",
    "flow.cuda();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.02\n",
      "97.42\n",
      "98.03\n",
      "final 98.03\n"
     ]
    }
   ],
   "source": [
    "time = [0, 0.5, 1]\n",
    "ensemble_size = 0\n",
    "predictions_sum = 0\n",
    "parameters1 = samples(model1)\n",
    "parameters2 = samples(model2)\n",
    "func = 'flow_connect'\n",
    "for i, t in enumerate(time):\n",
    "\n",
    "    cntr = Connector(parameters1, parameters2)\n",
    "    f = getattr(cntr, func)\n",
    "    parameters_res = f(t=t, model=flow, cuda=True)[1]\n",
    "    model = get_model(parameters_res, b2, architecture)\n",
    "    model.cuda();\n",
    "    predictions, targets = utils.predictions(loaders['test'], model)\n",
    "    ensemble_size += 1\n",
    "    if i==1:\n",
    "        predictions_sum += 0.7*predictions\n",
    "    else:\n",
    "        predictions_sum += predictions\n",
    "    ens_acc = 100.0 * np.mean(np.argmax(predictions, axis=1) == targets)\n",
    "    print(ens_acc)\n",
    "    \n",
    "ens_acc = 100.0 * np.mean(np.argmax(predictions_sum, axis=1) == targets)\n",
    "print('final', ens_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lin_connect\n",
      "(785, 2000)\n",
      "res (785, 2000)\n",
      "(2000, 10)\n",
      "res (2000, 10)\n",
      "train results {'nll': 0.263577197154363, 'loss': 0.263577197154363, 'accuracy': 96.59666666666666}\n",
      "test results {'nll': 0.267538090467453, 'loss': 0.267538090467453, 'accuracy': 95.82}\n",
      "arc_connect\n",
      "(785, 2000)\n",
      "res (785, 2000)\n",
      "(2000, 10)\n",
      "res (2000, 10)\n",
      "train results {'nll': 0.08393143694798151, 'loss': 0.08393143694798151, 'accuracy': 97.68666666666667}\n",
      "test results {'nll': 0.10656597929000855, 'loss': 0.10656597929000855, 'accuracy': 96.83}\n",
      "arc_connect_PCA\n",
      "(785, 2000)\n",
      "res (785, 2000)\n",
      "(2000, 10)\n",
      "res (2000, 10)\n",
      "train results {'nll': 0.0940992805838585, 'loss': 0.0940992805838585, 'accuracy': 97.27833333333334}\n",
      "test results {'nll': 0.11312627819776536, 'loss': 0.11312627819776536, 'accuracy': 96.63}\n"
     ]
    }
   ],
   "source": [
    "param1 = [parameters1[:, :-10].T, parameters1[:, -10:]]\n",
    "param2 = [parameters2[:, :-10].T, parameters2[:, -10:]]\n",
    "\n",
    "for func in ['lin_connect', 'arc_connect', 'arc_connect_PCA']:\n",
    "    parameters_res = []\n",
    "    print(func)\n",
    "    for p1, p2 in zip(param1, param2):\n",
    "        cntr = Connector(p1, p2)\n",
    "        print(p1.shape)\n",
    "        f = getattr(cntr, func)\n",
    "        if 'PCA' in func:\n",
    "            K = min(300, p1.shape[0], p1.shape[1])\n",
    "            res = f(K=K)[1]\n",
    "        elif 'third_cumulant' in func:\n",
    "            K = min(100, p1.shape[0], p1.shape[1])\n",
    "            res = f(K=K)[1] \n",
    "        else:\n",
    "            res = f()[1]\n",
    "            \n",
    "        print('res', res.shape)\n",
    "        parameters_res.append(res)\n",
    "        \n",
    "    parameters_res = np.hstack([parameters_res[0].T, parameters_res[1]])\n",
    "    model = get_model(parameters_res, b2, architecture)\n",
    "    model.cuda();\n",
    "    model.eval();\n",
    "    test_model(model, loaders, cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_res_tr = inv_transform(parameters_res[:, :-10].T, parameters_res[:, -10:].T, E12,  E22_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train results {'nll': 0.07982834839820861, 'loss': 0.07982834839820861, 'accuracy': 97.99666666666667}\n",
      "test results {'nll': 0.10293639920949936, 'loss': 0.10293639920949936, 'accuracy': 97.14}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'nll': 0.07982834839820861,\n",
       "  'loss': 0.07982834839820861,\n",
       "  'accuracy': 97.99666666666667},\n",
       " {'nll': 0.10293639920949936, 'loss': 0.10293639920949936, 'accuracy': 97.14})"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model(parameters_res_tr, b2, architecture)\n",
    "model.cuda();\n",
    "model.eval();\n",
    "test_model(model, loaders, cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters_res_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_new = parameters1[:3]+parameters2[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(param_new, architecture, per_layer=True)\n",
    "model.cuda();\n",
    "model.eval();\n",
    "test_model(model, loaders, cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for func in ['lin_connect', 'arc_connect', 'arc_connect_PCA']:\n",
    "    parameters_res = []\n",
    "    print(func)\n",
    "    for p1, p2 in zip(parameters1, parameters2):\n",
    "        cntr = Connector(p1, p2)\n",
    "        f = getattr(cntr, func)\n",
    "        if 'PCA' in func:\n",
    "            K = min(300, p1.shape[0], p1.shape[1])\n",
    "            res = f(K=K)[1]\n",
    "        elif 'third_cumulant' in func:\n",
    "            K = min(100, p1.shape[0], p1.shape[1])\n",
    "            res = f(K=K)[1] \n",
    "        else:\n",
    "            res = f()[1]\n",
    "        parameters_res.append(res)\n",
    "\n",
    "    model = get_model(parameters_res, architecture, per_layer=True)\n",
    "    model.cuda();\n",
    "    model.eval();\n",
    "    test_model(model, loaders, cuda=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import models\n",
    "# architecture = getattr(models, \"LinearOneLayer\") #LinearOneLayer LogRegression\n",
    "\n",
    "# import data\n",
    "# loaders, num_classes = data.loaders(\n",
    "#     \"MNIST\",\n",
    "#     \"data\",\n",
    "#     1024,\n",
    "#     1,\n",
    "#     \"VGG\",\n",
    "#     True)\n",
    "\n",
    "# import pickle\n",
    "# data_path = '/home/ivan/dnn-mode-connectivity/data/MNIST_PCA.pickle'\n",
    "# with open(data_path, 'rb') as handle:\n",
    "#     dataset, B, transformation = pickle.load(handle)\n",
    "# b2 = torch.FloatTensor([np.array(B).mean(0)])\n",
    "# b = np.array(B).mean(0)\n",
    "\n",
    "# train_dataset, test_dataset = dataset[:-8000], dataset[-8000:]\n",
    "# modes = [dataset[-4000:-2000], dataset[-2000:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 795)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from flows.models import RealNVP, RealNVP_OneLayer_full, IAF_OneLayer_full\n",
    "# flow = RealNVP_OneLayer_full(in_dim=80, dim_middle=200, N_layers=5, batch_norm=False, data_b2=b, transPSA=transformation)\n",
    "# flow.load_state_dict(torch.load('/home/ivan/distribution_connector/flow_models/RealNVP/MNIST_PCA_bijection3/checkpoint-2.pt')['model_state'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow.cuda();\n",
    "# test_flow(flow, architecture, loaders, b2, cntr=None, verbose=True,\n",
    "#               test_sampling=True, test_flow=False, cuda=True, transPSA=transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow.cuda();\n",
    "# stat_dict, stat_dict_mean, stat_dict_std = gather_statistics(dataset[-8000:], \n",
    "#                                                              loaders, b2, architecture, \n",
    "#                                                              flow=flow, K=80, t=0.5, \n",
    "#                                                              verbose=True, func_name=['flow_connect'],\n",
    "#                                                              save_stat=True, path='stat/MNIST/bijectionPCA',\n",
    "#                                                              transPSA=transformation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gavering sample and error time plots on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcs = [func for func in dir(cntr) if callable(getattr(cntr, func)) and 'connect' in func \n",
    "         and 'flow' not in func and 'third_cumulant' not in func]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['arc_connect',\n",
       " 'arc_connect_PCA',\n",
       " 'inverse_connect',\n",
       " 'inverse_connect_PCA',\n",
       " 'lin_connect',\n",
       " 'simul_diag_connect']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for func_name in funcs:\n",
    "#     t = np.linspace(0,1, 61)[1:-1]\n",
    "#     stat = test_func(modes, loaders, b, architecture, func_name, flow=None, K=80, t=t, \n",
    "#                      show=False, verbose=False, save_pic=True, path='MNIST', save_samples=False,\n",
    "#                      test_models=True, compute_distribution_stat=False, show_type='hex')\n",
    "#     t = np.linspace(0,1, 5)[1:-1]\n",
    "#     stat = test_func(modes, loaders, b, architecture, func_name, flow=None, K=80, t=t, \n",
    "#                      show=False, verbose=False, save_pic=False, path='MNIST', save_samples=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## flow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '/home/ivan/distribution_connector/flow_models/Flow_IAF/MNIST_flow/checkpoint-150.pt'\n",
    "# from flows.models import RealNVP, RealNVP_OneLayer_full, IAF_OneLayer_full\n",
    "# flow = IAF_OneLayer_full(in_dim=795, dim_middle=795, N_layers=2, batch_norm=False, data_b2=b)\n",
    "# flow.load_state_dict(torch.load('/home/ivan/distribution_connector/flow_models/Flow_IAF/MNIST_flow/checkpoint-120.pt')['model_state'])\n",
    "\n",
    "\n",
    "# flow.cuda();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask len 2\n"
     ]
    }
   ],
   "source": [
    "from flows.models import RealNVP, RealNVP_OneLayer_full\n",
    "\n",
    "flow = RealNVP_OneLayer_full(in_dim=795, dim_middle=2000, N_layers=1, batch_norm=True, data_b2=b)\n",
    "flow.load_state_dict(torch.load('/home/ivan/distribution_connector/flow_models/RealNVP/MNIST_bijection/checkpoint-20.pt')['model_state'])\n",
    "flow.cuda();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.linspace(0,1, 61)[1:-1]\n",
    "stat = test_func(modes, loaders, b2, architecture, 'flow_connect', flow=flow, K=80, t=t, \n",
    "                     show=False, verbose=False, save_pic=True, path='MNIST', save_samples=False,\n",
    "                     test_models=True, compute_distribution_stat=False, show_type='hex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing mean and std for different methods on MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## flow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint-20.pt -- top for MNIST bijection\n",
    "# checkpoint-7 top for CIFAR bijection\n",
    "# checkpoint-120 top for MNIST Flow IAF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '/home/ivan/distribution_connector/flow_models/Flow_IAF/MNIST_flow/checkpoint-150.pt'\n",
    "# from flows.models import RealNVP, RealNVP_OneLayer_full, IAF_OneLayer_full\n",
    "# flow = IAF_OneLayer_full(in_dim=795, dim_middle=795, N_layers=2, batch_norm=False, data_b2=b)\n",
    "# flow.load_state_dict(torch.load('/home/ivan/distribution_connector/flow_models/Flow_IAF/MNIST_flow/checkpoint-120.pt')['model_state'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from flows.models import RealNVP, RealNVP_OneLayer_full\n",
    "\n",
    "# flow = RealNVP_OneLayer_full(in_dim=795, dim_middle=795, N_layers=1, batch_norm=True, data_b2=b)\n",
    "# flow.load_state_dict(torch.load('/home/ivan/distribution_connector/flow_models/RealNVP/MNIST_flow1/checkpoint-8.pt')['model_state'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b = b2\n",
    "# cuda = True\n",
    "# verbose = True\n",
    "# transPSA = None\n",
    "# model.eval()\n",
    "# res = model.sample(K=2000).cpu().data.numpy()\n",
    "# if transPSA is not None:\n",
    "#     res = transPSA.inverse_transform(res)\n",
    "# m = get_model(res, b, architecture)\n",
    "# if cuda:\n",
    "#     m.cuda()\n",
    "# result_s = test_model(m, loaders, verbose=verbose, cuda=cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling testing\n",
      "train results {'nll': 0.1873208567937215, 'loss': 0.1873208567937215, 'accuracy': 94.21833333333333}\n",
      "test results {'nll': 0.19890189328193664, 'loss': 0.19890189328193664, 'accuracy': 94.02}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(({'nll': 0.1873208567937215,\n",
       "   'loss': 0.1873208567937215,\n",
       "   'accuracy': 94.21833333333333},\n",
       "  {'nll': 0.19890189328193664,\n",
       "   'loss': 0.19890189328193664,\n",
       "   'accuracy': 94.02}),\n",
       " None)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flow.cuda();\n",
    "test_flow(flow, architecture, loaders, b2, cntr=None, verbose=True,\n",
    "              test_sampling=True, test_flow=False, cuda=True, transPSA=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow.cuda();\n",
    "# stat_dict, stat_dict_mean, stat_dict_std = gather_statistics(dataset[-8000:], \n",
    "#                                                              loaders, b2, architecture, \n",
    "#                                                              flow=flow, K=80, t=0.5, \n",
    "#                                                              verbose=True, func_name=['flow_connect'],\n",
    "#                                                              save_stat=True, path='stat/MNIST/IAFflow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## basic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = dataset[-8000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcs = [func for func in dir(cntr) if callable(getattr(cntr, func)) and 'connect' in func \n",
    "         and 'flow' not in func and 'third_cumulant' in func]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_models 4\n",
      "third_cumulant_connect\n",
      "c 1600.3411257129785 512000\n",
      "0.5\n",
      "train results {'nll': 0.8071608489990234, 'loss': 0.8071608489990234, 'accuracy': 75.44}\n",
      "test results {'nll': 0.788148390865326, 'loss': 0.788148390865326, 'accuracy': 76.12}\n",
      "third_cumulant_connect\n",
      "c 1594.631502638252 512000\n",
      "0.5\n",
      "train results {'nll': 0.6341616157531739, 'loss': 0.6341616157531739, 'accuracy': 78.96333333333334}\n",
      "test results {'nll': 0.6215544948577881, 'loss': 0.6215544948577881, 'accuracy': 79.51}\n",
      "third_cumulant_connect\n",
      "c 1602.5800297365204 512000\n",
      "0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 1/4 [01:37<04:51, 97.16s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train results {'nll': 0.7839152718226114, 'loss': 0.7839152718226114, 'accuracy': 72.36}\n",
      "test results {'nll': 0.7712775550842285, 'loss': 0.7712775550842285, 'accuracy': 72.52}\n",
      "third_cumulant_connect\n",
      "c 1601.0657202684679 512000\n",
      "0.5\n",
      "train results {'nll': 0.7509037694613139, 'loss': 0.7509037694613139, 'accuracy': 74.60666666666667}\n",
      "test results {'nll': 0.7424520283699035, 'loss': 0.7424520283699035, 'accuracy': 74.86}\n",
      "third_cumulant_connect\n",
      "c 1617.6414617463297 512000\n",
      "0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 2/4 [02:45<02:57, 88.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train results {'nll': 0.8341048234621684, 'loss': 0.8341048234621684, 'accuracy': 73.07}\n",
      "test results {'nll': 0.8145449273109436, 'loss': 0.8145449273109436, 'accuracy': 73.45}\n",
      "third_cumulant_connect\n",
      "c 1609.567649403868 512000\n",
      "0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 3/4 [03:20<01:12, 72.53s/it]\u001b[A\n",
      "100%|██████████| 4/4 [03:20<00:00, 50.19s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train results {'nll': 0.8697093101183574, 'loss': 0.8697093101183574, 'accuracy': 69.51166666666667}\n",
      "test results {'nll': 0.8651455919265747, 'loss': 0.8651455919265747, 'accuracy': 69.71}\n",
      "saving to  data/stat/MNIST/third_cumulanterror_stat.pickle\n"
     ]
    }
   ],
   "source": [
    "stat_dict, stat_dict_mean, stat_dict_std = gather_statistics(test_dataset, \n",
    "                                                             loaders, b2, architecture, \n",
    "                                                             flow=None, K=80, t=0.5, \n",
    "                                                             verbose=True, func_name=funcs,\n",
    "                                                             save_stat=True, path='stat/MNIST/third_cumulant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'train': {'arc_connect': 97.89348148148149,\n",
       "   'arc_connect_PCA': 97.66703703703703,\n",
       "   'inverse_connect': 97.84737037037036,\n",
       "   'inverse_connect_PCA': 97.46407407407409,\n",
       "   'lin_connect': 96.54114814814814,\n",
       "   'simul_diag_connect': 97.84322222222224},\n",
       "  'test': {'arc_connect': 97.03577777777775,\n",
       "   'arc_connect_PCA': 97.02199999999999,\n",
       "   'inverse_connect': 96.96955555555556,\n",
       "   'inverse_connect_PCA': 96.81,\n",
       "   'lin_connect': 95.87822222222223,\n",
       "   'simul_diag_connect': 97.00844444444445}},\n",
       " {'train': {'arc_connect': 0.11143166107154394,\n",
       "   'arc_connect_PCA': 0.09728974727356571,\n",
       "   'inverse_connect': 0.13658556260530705,\n",
       "   'inverse_connect_PCA': 0.11721224578692356,\n",
       "   'lin_connect': 0.41123118700219913,\n",
       "   'simul_diag_connect': 0.11861827977296019},\n",
       "  'test': {'arc_connect': 0.14210307509205192,\n",
       "   'arc_connect_PCA': 0.13511476603243608,\n",
       "   'inverse_connect': 0.16937736377103318,\n",
       "   'inverse_connect_PCA': 0.16152055252780917,\n",
       "   'lin_connect': 0.40518467059348473,\n",
       "   'simul_diag_connect': 0.1541565662356953}})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_dict_mean, stat_dict_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "You are going to run models on the test set. Are you sure?\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import models\n",
    "architecture = getattr(models, \"LinearOneLayerCF\") #LinearOneLayer LogRegression\n",
    "\n",
    "import data\n",
    "loaders, num_classes = data.loaders(\n",
    "    \"CIFAR10\",\n",
    "    \"data\",\n",
    "    1024,\n",
    "    1,\n",
    "    \"VGG\",\n",
    "    False)\n",
    "\n",
    "model1 = architecture.base(num_classes=10, **architecture.kwargs)\n",
    "model2 = architecture.base(num_classes=10, **architecture.kwargs)\n",
    "\n",
    "model1.load_state_dict(torch.load('curves/LinearOneLayer/curve16/checkpoint-400.pt')['model_state'])\n",
    "model2.load_state_dict(torch.load('curves/LinearOneLayer/curve17/checkpoint-400.pt')['model_state'])\n",
    "\n",
    "import pickle\n",
    "data_path = '/home/ivan/dnn-mode-connectivity/data/CIFAR.pickle'\n",
    "with open(data_path, 'rb') as handle:\n",
    "    dataset, B = pickle.load(handle)\n",
    "b2 =  torch.FloatTensor([np.array(B).mean(0)])\n",
    "b = np.array(B).mean(0)\n",
    "\n",
    "train_dataset, test_dataset = dataset[:-8000], dataset[-8000:]\n",
    "modes = [dataset[-4000:-2000], dataset[-2000:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters1 = samples(model1)\n",
    "parameters2 = samples(model2)\n",
    "\n",
    "parameters = np.concatenate([parameters1, parameters2])\n",
    "\n",
    "cov = parameters.T @ parameters\n",
    "E12 = cov[:-10, -10:]\n",
    "E22 = cov[-10:, -10:]\n",
    "E22_inv = np.linalg.inv(E22)\n",
    "\n",
    "parameters1_tr = transform(parameters1[:, :-10].T, parameters1[:, -10:].T, E12,  E22_inv)\n",
    "parameters2_tr = transform(parameters2[:, :-10].T, parameters2[:, -10:].T, E12,  E22_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lin_connect\n",
      "(2000, 3073)\n",
      "res (2000, 3073)\n",
      "(10, 2000)\n",
      "res (10, 2000)\n",
      "train results {'nll': 1.892354764175415, 'loss': 1.892354764175415, 'accuracy': 31.97}\n",
      "test results {'nll': 2.0686955657958985, 'loss': 2.0686955657958985, 'accuracy': 37.79}\n",
      "arc_connect\n",
      "(2000, 3073)\n",
      "res (2000, 3073)\n",
      "(10, 2000)\n",
      "res (10, 2000)\n",
      "train results {'nll': 1.527513200187683, 'loss': 1.527513200187683, 'accuracy': 50.786}\n",
      "test results {'nll': 2.882915619277954, 'loss': 2.882915619277954, 'accuracy': 40.65}\n",
      "arc_connect_PCA\n",
      "(2000, 3073)\n",
      "res (2000, 3073)\n",
      "(10, 2000)\n",
      "res (10, 2000)\n",
      "train results {'nll': 1.641271957511902, 'loss': 1.641271957511902, 'accuracy': 44.032}\n",
      "test results {'nll': 2.6984750995635984, 'loss': 2.6984750995635984, 'accuracy': 37.42}\n"
     ]
    }
   ],
   "source": [
    "param1 = [parameters1[:, :-10], parameters1[:, -10:].T]\n",
    "param2 = [parameters2[:, :-10], parameters2[:, -10:].T]\n",
    "\n",
    "for func in ['lin_connect', 'arc_connect', 'arc_connect_PCA']:\n",
    "    parameters_res = []\n",
    "    print(func)\n",
    "    for p1, p2 in zip(param1, param2):\n",
    "        cntr = Connector(p1, p2)\n",
    "        print(p1.shape)\n",
    "        f = getattr(cntr, func)\n",
    "        if 'PCA' in func:\n",
    "            K = min(300, p1.shape[0], p1.shape[1])\n",
    "            res = f(K=K)[1]\n",
    "        elif 'third_cumulant' in func:\n",
    "            K = min(100, p1.shape[0], p1.shape[1])\n",
    "            res = f(K=K)[1] \n",
    "        else:\n",
    "            res = f()[1]\n",
    "            \n",
    "        print('res', res.shape)\n",
    "        parameters_res.append(res)\n",
    "        \n",
    "    parameters_res = np.hstack([parameters_res[0], parameters_res[1].T])\n",
    "    model = get_model(parameters_res, b2, architecture)\n",
    "    model.cuda();\n",
    "    model.eval();\n",
    "    test_model(model, loaders, cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lin_connect\n",
      "(2000, 3073)\n",
      "res (2000, 3073)\n",
      "(2000, 10)\n",
      "res (2000, 10)\n",
      "train results {'nll': 1.8912518212890626, 'loss': 1.8912518212890626, 'accuracy': 32.088}\n",
      "test results {'nll': 2.0686955657958985, 'loss': 2.0686955657958985, 'accuracy': 37.79}\n",
      "arc_connect\n",
      "(2000, 3073)\n",
      "res (2000, 3073)\n",
      "(2000, 10)\n",
      "res (2000, 10)\n",
      "train results {'nll': 1.4912290412139892, 'loss': 1.4912290412139892, 'accuracy': 50.816}\n",
      "test results {'nll': 2.6923051845550536, 'loss': 2.6923051845550536, 'accuracy': 40.93}\n",
      "arc_connect_PCA\n",
      "(2000, 3073)\n",
      "res (2000, 3073)\n",
      "(2000, 10)\n",
      "res (2000, 10)\n",
      "train results {'nll': 1.4851501541519165, 'loss': 1.4851501541519165, 'accuracy': 51.288}\n",
      "test results {'nll': 2.8195617031097413, 'loss': 2.8195617031097413, 'accuracy': 40.16}\n"
     ]
    }
   ],
   "source": [
    "param1 = [parameters1[:, :-10], parameters1[:, -10:]]\n",
    "param2 = [parameters2[:, :-10], parameters2[:, -10:]]\n",
    "\n",
    "for func in ['lin_connect', 'arc_connect', 'arc_connect_PCA']:\n",
    "    parameters_res = []\n",
    "    print(func)\n",
    "    for p1, p2 in zip(param1, param2):\n",
    "        cntr = Connector(p1, p2)\n",
    "        print(p1.shape)\n",
    "        f = getattr(cntr, func)\n",
    "        if 'PCA' in func:\n",
    "            K = min(300, p1.shape[0], p1.shape[1])\n",
    "            res = f(K=K)[1]\n",
    "        elif 'third_cumulant' in func:\n",
    "            K = min(100, p1.shape[0], p1.shape[1])\n",
    "            res = f(K=K)[1] \n",
    "        else:\n",
    "            res = f()[1]\n",
    "            \n",
    "        print('res', res.shape)\n",
    "        parameters_res.append(res)\n",
    "        \n",
    "    parameters_res = np.hstack([parameters_res[0], parameters_res[1]])\n",
    "    model = get_model(parameters_res, b2, architecture)\n",
    "    model.cuda();\n",
    "    model.eval();\n",
    "    test_model(model, loaders, cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lin_connect\n",
      "(3073, 2000)\n",
      "res (3073, 2000)\n",
      "(2000, 10)\n",
      "res (2000, 10)\n",
      "train results {'nll': 1.8950114845657349, 'loss': 1.8950114845657349, 'accuracy': 32.046}\n",
      "test results {'nll': 2.0686955657958985, 'loss': 2.0686955657958985, 'accuracy': 37.79}\n",
      "arc_connect\n",
      "(3073, 2000)\n",
      "res (3073, 2000)\n",
      "(2000, 10)\n",
      "res (2000, 10)\n",
      "train results {'nll': 1.6132043946456909, 'loss': 1.6132043946456909, 'accuracy': 43.942}\n",
      "test results {'nll': 2.6095668628692628, 'loss': 2.6095668628692628, 'accuracy': 41.38}\n",
      "arc_connect_PCA\n",
      "(3073, 2000)\n",
      "res (3073, 2000)\n",
      "(2000, 10)\n",
      "res (2000, 10)\n",
      "train results {'nll': 1.6867427646255493, 'loss': 1.6867427646255493, 'accuracy': 40.956}\n",
      "test results {'nll': 2.651808978652954, 'loss': 2.651808978652954, 'accuracy': 40.74}\n"
     ]
    }
   ],
   "source": [
    "param1 = [parameters1[:, :-10].T, parameters1[:, -10:]]\n",
    "param2 = [parameters2[:, :-10].T, parameters2[:, -10:]]\n",
    "\n",
    "for func in ['lin_connect', 'arc_connect', 'arc_connect_PCA']:\n",
    "    parameters_res = []\n",
    "    print(func)\n",
    "    for p1, p2 in zip(param1, param2):\n",
    "        cntr = Connector(p1, p2)\n",
    "        print(p1.shape)\n",
    "        f = getattr(cntr, func)\n",
    "        if 'PCA' in func:\n",
    "            K = min(300, p1.shape[0], p1.shape[1])\n",
    "            res = f(K=K)[1]\n",
    "        elif 'third_cumulant' in func:\n",
    "            K = min(100, p1.shape[0], p1.shape[1])\n",
    "            res = f(K=K)[1] \n",
    "        else:\n",
    "            res = f()[1]\n",
    "            \n",
    "        print('res', res.shape)\n",
    "        parameters_res.append(res)\n",
    "        \n",
    "    parameters_res = np.hstack([parameters_res[0].T, parameters_res[1]])\n",
    "    model = get_model(parameters_res, b2, architecture)\n",
    "    model.cuda();\n",
    "    model.eval();\n",
    "    test_model(model, loaders, cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lin_connect\n",
      "(3073, 2000)\n",
      "res (3073, 2000)\n",
      "(10, 2000)\n",
      "res (10, 2000)\n",
      "train results {'nll': 1.894404046974182, 'loss': 1.894404046974182, 'accuracy': 32.104}\n",
      "test results {'nll': 2.0686955657958985, 'loss': 2.0686955657958985, 'accuracy': 37.79}\n",
      "arc_connect\n",
      "(3073, 2000)\n",
      "res (3073, 2000)\n",
      "(10, 2000)\n",
      "res (10, 2000)\n",
      "train results {'nll': 1.5941276955795287, 'loss': 1.5941276955795287, 'accuracy': 44.44}\n",
      "test results {'nll': 2.962168966674805, 'loss': 2.962168966674805, 'accuracy': 41.61}\n",
      "arc_connect_PCA\n",
      "(3073, 2000)\n",
      "res (3073, 2000)\n",
      "(10, 2000)\n",
      "res (10, 2000)\n",
      "train results {'nll': 1.7525887490463257, 'loss': 1.7525887490463257, 'accuracy': 37.204}\n",
      "test results {'nll': 2.861420792388916, 'loss': 2.861420792388916, 'accuracy': 37.24}\n"
     ]
    }
   ],
   "source": [
    "param1 = [parameters1[:, :-10].T, parameters1[:, -10:].T]\n",
    "param2 = [parameters2[:, :-10].T, parameters2[:, -10:].T]\n",
    "\n",
    "for func in ['lin_connect', 'arc_connect', 'arc_connect_PCA']:\n",
    "    parameters_res = []\n",
    "    print(func)\n",
    "    for p1, p2 in zip(param1, param2):\n",
    "        cntr = Connector(p1, p2)\n",
    "        print(p1.shape)\n",
    "        f = getattr(cntr, func)\n",
    "        if 'PCA' in func:\n",
    "            K = min(300, p1.shape[0], p1.shape[1])\n",
    "            res = f(K=K)[1]\n",
    "        elif 'third_cumulant' in func:\n",
    "            K = min(100, p1.shape[0], p1.shape[1])\n",
    "            res = f(K=K)[1] \n",
    "        else:\n",
    "            res = f()[1]\n",
    "            \n",
    "        print('res', res.shape)\n",
    "        parameters_res.append(res)\n",
    "        \n",
    "    parameters_res = np.hstack([parameters_res[0].T, parameters_res[1].T])\n",
    "    model = get_model(parameters_res, b2, architecture)\n",
    "    model.cuda();\n",
    "    model.eval();\n",
    "    test_model(model, loaders, cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train results {'nll': 0.8493014687347412, 'loss': 0.8493014687347412, 'accuracy': 70.424}\n",
      "test results {'nll': 1.313883560180664, 'loss': 1.313883560180664, 'accuracy': 58.9}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'nll': 0.8493014687347412, 'loss': 0.8493014687347412, 'accuracy': 70.424},\n",
       " {'nll': 1.313883560180664, 'loss': 1.313883560180664, 'accuracy': 58.9})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.cuda();\n",
    "model1.eval();\n",
    "test_model(model1, loaders, cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arc_connect\n"
     ]
    }
   ],
   "source": [
    "func = 'arc_connect'\n",
    "parameters_res = []\n",
    "print(func)\n",
    "cntr = Connector(parameters1_tr, parameters2_tr)\n",
    "f = getattr(cntr, func)\n",
    "parameters_res = f()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_res_tr = inv_transform(parameters_res[:, :-10].T, parameters_res[:, -10:].T, E12,  E22_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train results {'nll': 1.4964728350067138, 'loss': 1.4964728350067138, 'accuracy': 51.208}\n",
      "test results {'nll': 2.692305062484741, 'loss': 2.692305062484741, 'accuracy': 40.93}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'nll': 1.4964728350067138, 'loss': 1.4964728350067138, 'accuracy': 51.208},\n",
       " {'nll': 2.692305062484741, 'loss': 2.692305062484741, 'accuracy': 40.93})"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model(parameters_res_tr, b2, architecture)\n",
    "model.cuda();\n",
    "model.eval();\n",
    "test_model(model, loaders, cuda=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gavering sample and error time plots on CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for func_name in funcs:\n",
    "#     t = np.linspace(0,1, 61)[1:-1]\n",
    "#     stat = test_func(modes, loaders, b2, architecture, func_name, flow=None, K=400, t=t, \n",
    "#                      show=False, verbose=False, save_pic=True, path='CIFAR', save_samples=False)\n",
    "#     t = np.linspace(0,1, 5)[1:-1]\n",
    "#     stat = test_func(modes, loaders, b2, architecture, func_name, flow=None, K=400, t=t, \n",
    "#                      show=False, verbose=False, save_pic=False, path='CIFAR', save_samples=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNVP flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = np.linspace(0,1, 61)[1:-1]\n",
    "# stat = test_func(modes, loaders, b2, architecture, func_name='flow_connect', flow=flow, K=400, t=t, \n",
    "#                  show=False, verbose=False, save_pic=True, test_models=True, path='CIFAR', save_samples=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = np.linspace(0,1, 5)[1:-1]\n",
    "# stat = test_func(modes, loaders, b2, architecture, func_name='flow_connect', flow=flow, K=400, t=t, \n",
    "#                  show=False, verbose=False, save_pic=False, path='CIFAR', save_samples=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing mean and std for different methods on CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train results {'nll': 0.8489676392555237, 'loss': 0.8489676392555237, 'accuracy': 70.572}\n",
      "test results {'nll': 1.313883560180664, 'loss': 1.313883560180664, 'accuracy': 58.9}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'nll': 0.8489676392555237, 'loss': 0.8489676392555237, 'accuracy': 70.572},\n",
       " {'nll': 1.313883560180664, 'loss': 1.313883560180664, 'accuracy': 58.9})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.cuda()\n",
    "test_model(model1, loaders, cuda=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask len 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flows.models import RealNVP, RealNVP_OneLayer_full, IAF_OneLayer_full\n",
    "\n",
    "flow = RealNVP_OneLayer_full(in_dim=3083, dim_middle=3000, N_layers=1, batch_norm=False, data_b2=b)\n",
    "flow.load_state_dict(torch.load('/home/ivan/distribution_connector/flow_models/RealNVP/CIFAR_test1/checkpoint-7.pt')['model_state'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from flows.models import RealNVP, RealNVP_OneLayer_full, IAF_OneLayer_full\n",
    "# flow = IAF_OneLayer_full(in_dim=3083, dim_middle=3000, N_layers=1, batch_norm=False, data_b2=b)\n",
    "# flow.load_state_dict(torch.load('/home/ivan/distribution_connector/flow_models/RealNVP/CIFAR_test1/checkpoint-7.pt')['model_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_models 4\n",
      "flow_connect\n",
      "0.5\n",
      "train results {'nll': 1.0533692544174194, 'loss': 1.0533692544174194, 'accuracy': 63.456}\n",
      "test results {'nll': 1.6187260831832886, 'loss': 1.6187260831832886, 'accuracy': 53.59}\n",
      "flow_connect\n",
      "0.5\n",
      "train results {'nll': 1.0545070586013794, 'loss': 1.0545070586013794, 'accuracy': 63.1}\n",
      "test results {'nll': 1.7111023202896118, 'loss': 1.7111023202896118, 'accuracy': 52.64}\n",
      "flow_connect\n",
      "0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 25%|██▌       | 1/4 [01:00<03:01, 60.47s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train results {'nll': 1.0488071635627747, 'loss': 1.0488071635627747, 'accuracy': 63.788}\n",
      "test results {'nll': 1.5592954841613769, 'loss': 1.5592954841613769, 'accuracy': 55.26}\n",
      "flow_connect\n",
      "0.5\n",
      "train results {'nll': 1.0633495126342773, 'loss': 1.0633495126342773, 'accuracy': 63.462}\n",
      "test results {'nll': 1.5593252670288087, 'loss': 1.5593252670288087, 'accuracy': 54.64}\n",
      "flow_connect\n",
      "0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 50%|█████     | 2/4 [01:41<01:49, 54.79s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train results {'nll': 1.0475879463577271, 'loss': 1.0475879463577271, 'accuracy': 63.818}\n",
      "test results {'nll': 1.5472380882263184, 'loss': 1.5472380882263184, 'accuracy': 54.58}\n",
      "flow_connect\n",
      "0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 75%|███████▌  | 3/4 [02:03<00:44, 44.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 4/4 [02:03<00:00, 30.96s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train results {'nll': 1.0577251321029664, 'loss': 1.0577251321029664, 'accuracy': 63.144}\n",
      "test results {'nll': 1.6692164546966552, 'loss': 1.6692164546966552, 'accuracy': 52.93}\n",
      "saving to  data/stat/CIFAR/bijectionerror_stat.pickle\n"
     ]
    }
   ],
   "source": [
    "flow.cuda();\n",
    "stat_dict, stat_dict_mean, stat_dict_std = gather_statistics(dataset[-8000:], \n",
    "                                                             loaders, b2, architecture, \n",
    "                                                             flow=flow, K=80, t=0.5, \n",
    "                                                             verbose=True, func_name=['flow_connect'],\n",
    "                                                             save_stat=True, path='stat/CIFAR/bijection')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## basic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = dataset[-8000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcs = [func for func in dir(cntr) if callable(getattr(cntr, func)) and 'connect' in func \n",
    "         and 'flow' not in func and 'third_cumulant' in func]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['third_cumulant_connect']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_models 4\n",
      "third_cumulant_connect\n",
      "c 49339.753945420765 8000000\n",
      "0.5\n",
      "train results {'nll': 192.03328536132813, 'loss': 192.03328536132813, 'accuracy': 10.95}\n",
      "test results {'nll': 159.18884404296875, 'loss': 159.18884404296875, 'accuracy': 11.4}\n",
      "third_cumulant_connect\n",
      "c 49147.18525962689 8000000\n",
      "0.5\n",
      "train results {'nll': 197.92421240234376, 'loss': 197.92421240234376, 'accuracy': 10.81}\n",
      "test results {'nll': 172.68769267578125, 'loss': 172.68769267578125, 'accuracy': 11.54}\n",
      "third_cumulant_connect\n",
      "c 49338.789716830164 8000000\n",
      "0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 1/4 [19:02<57:07, 1142.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train results {'nll': 200.2789377734375, 'loss': 200.2789377734375, 'accuracy': 11.184}\n",
      "test results {'nll': 174.5269504638672, 'loss': 174.5269504638672, 'accuracy': 12.38}\n",
      "third_cumulant_connect\n",
      "c 49031.59461684667 8000000\n",
      "0.5\n",
      "train results {'nll': 196.78189912109374, 'loss': 196.78189912109374, 'accuracy': 10.758}\n",
      "test results {'nll': 166.34349104003905, 'loss': 166.34349104003905, 'accuracy': 11.96}\n",
      "third_cumulant_connect\n",
      "c 49216.40067193843 8000000\n",
      "0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 2/4 [32:55<34:59, 1049.84s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train results {'nll': 203.76456399902344, 'loss': 203.76456399902344, 'accuracy': 10.178}\n",
      "test results {'nll': 165.93680776367188, 'loss': 165.93680776367188, 'accuracy': 11.31}\n",
      "third_cumulant_connect\n",
      "c 49634.76412962114 8000000\n",
      "0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 3/4 [39:04<14:05, 845.57s/it] \u001b[A\n",
      "100%|██████████| 4/4 [39:04<00:00, 586.23s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train results {'nll': 204.2034564892578, 'loss': 204.2034564892578, 'accuracy': 10.938}\n",
      "test results {'nll': 168.1272219970703, 'loss': 168.1272219970703, 'accuracy': 12.78}\n",
      "saving to  data/stat/CIFAR/third_cumulanterror_stat.pickle\n"
     ]
    }
   ],
   "source": [
    "stat_dict, stat_dict_mean, stat_dict_std = gather_statistics(test_dataset, \n",
    "                                                             loaders, b2, architecture, \n",
    "                                                             flow=None, K=200, t=0.5, \n",
    "                                                             verbose=True, func_name=funcs,\n",
    "                                                             save_stat=True, path='stat/CIFAR/third_cumulant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/stat/CIFAR/third_cumulanterror_stat.pickle', 'rb') as handle:\n",
    "        load = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': {'third_cumulant_connect': 10.802999999999999},\n",
       " 'test': {'third_cumulant_connect': 11.895000000000001}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': {'third_cumulant_connect': 0.31029394665918486},\n",
       " 'test': {'third_cumulant_connect': 0.5378893938348291}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'train': {'flow_connect': 63.60966666666667},\n",
       "  'test': {'flow_connect': 53.94}},\n",
       " {'train': {'flow_connect': 0.353156087618808},\n",
       "  'test': {'flow_connect': 0.9552137631615929}})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_dict_mean, stat_dict_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
