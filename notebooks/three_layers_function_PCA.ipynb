{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/ivan/distribution_connector')\n",
    "import os\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from connector_utils import test_models, gather_statistics, test_func\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from connector import Connector\n",
    "# from one_layer_utils import samples, make_dataset, get_model, get_b\n",
    "from utils import test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "You are going to run models on the test set. Are you sure?\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import models\n",
    "architecture = getattr(models, \"Linear3NoBias\") #LinearOneLayer LogRegression\n",
    "\n",
    "import data\n",
    "loaders, num_classes = data.loaders(\n",
    "    \"CIFAR10\",\n",
    "    \"data\",\n",
    "    1024,\n",
    "    1,\n",
    "    \"VGG\",\n",
    "    True,\n",
    "    shuffle_train=False)\n",
    "\n",
    "model1 = architecture.base(num_classes=10, **architecture.kwargs)\n",
    "model2 = architecture.base(num_classes=10, **architecture.kwargs)\n",
    "\n",
    "model1.load_state_dict(torch.load('curves/Linear3NoBias/curve1/checkpoint-100.pt')['model_state'])\n",
    "model2.load_state_dict(torch.load('curves/Linear3NoBias/curve2/checkpoint-100.pt')['model_state'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train results {'nll': 0.4516510422611237, 'loss': 0.4516510422611237, 'accuracy': 84.766}\n",
      "test results {'nll': 1.2863960428237915, 'loss': 1.2863960428237915, 'accuracy': 60.34}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'nll': 0.4516510422611237, 'loss': 0.4516510422611237, 'accuracy': 84.766},\n",
       " {'nll': 1.2863960428237915, 'loss': 1.2863960428237915, 'accuracy': 60.34})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.cuda();\n",
    "model1.eval();\n",
    "test_model(model1, loaders, cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(W, architecture, bias=False, per_layer=True):\n",
    "    model_sampled = architecture.base(num_classes=10, **architecture.kwargs)\n",
    "    model_samples = np.array(W)  \n",
    "\n",
    "    if per_layer:\n",
    "        for parameter, w in zip(model_sampled.parameters(), W):\n",
    "            parameter.data.copy_(torch.from_numpy(w))\n",
    "    else:\n",
    "        for i, parameter in enumerate(model_sampled.parameters()):\n",
    "            w = W[i//2]\n",
    "            if i % 2 == 0:\n",
    "                offset = 0\n",
    "            N = parameter.data.shape[1]\n",
    "            w_part = w[:, offset:offset+N]\n",
    "            offset = N\n",
    "            if i % 2 == 0:\n",
    "                parameter.data.copy_(torch.from_numpy(w_part))\n",
    "            else:\n",
    "                parameter.data.copy_(torch.from_numpy(w_part.T))\n",
    "            \n",
    "\n",
    "    return model_sampled\n",
    "\n",
    "def samples(model):\n",
    "    p = [list(model.parameters())[i].data.cpu().numpy() for i in range(len(list(model.parameters())))]\n",
    "    return p\n",
    "\n",
    "def samples_per_layer(model, bias=True):\n",
    "    p = samples(model)\n",
    "    if bias:\n",
    "        p = [np.hstack([p[i], p[i+1][:, None]]) for i in range(0, len(p), 2)]        \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l torch.Size([1024, 6144])\n"
     ]
    }
   ],
   "source": [
    "layer = 0\n",
    "model1.cuda()\n",
    "model1.eval()\n",
    "functions = []\n",
    "targ = []\n",
    "for X, y in loaders['test']:\n",
    "    functions.append(model1(X.cuda(), N=layer))\n",
    "    targ.append(y)\n",
    "\n",
    "print('l', functions[0].shape)\n",
    "targ = np.concatenate(targ)\n",
    "funcs = np.concatenate([p.cpu().data.numpy() for p in functions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X(data='test'):\n",
    "    dataset = []\n",
    "    for X, y in loaders[data]:\n",
    "        dataset.append(X)\n",
    "\n",
    "    dataset = np.concatenate([p.view(-1,3*32*32).cpu().data.numpy() for p in dataset])\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_X()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3072)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcs = get_funcs(model1, data='test')\n",
    "funcs2  = get_funcs(model2, data='test')\n",
    "\n",
    "# funcs2 = funcs2[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_init, Sigma_init, V_init = np.linalg.svd(funcs.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = 6144\n",
    "U, Sigma, V = U_init[:, :comp], Sigma_init[:comp], V_init[:comp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_funcs(model1, data='test', layer=0):\n",
    "    model1.cuda()\n",
    "    model1.eval()\n",
    "    functions = []\n",
    "    for X, y in loaders[data]:\n",
    "        functions.append(model1(X.cuda(), N=layer))\n",
    "\n",
    "    funcs = np.concatenate([p.cpu().data.numpy() for p in functions])\n",
    "    \n",
    "    return funcs\n",
    "\n",
    "def get_alpha(funcs, V):\n",
    "    alpha = funcs.T @ V.T\n",
    "    return alpha\n",
    "\n",
    "def get_betas(funcs, V):\n",
    "#     betas = np.linalg.inv(funcs.T @ V.T)\n",
    "    f_inv = np.linalg.pinv(funcs.T)\n",
    "    betas = V @ f_inv\n",
    "    return betas\n",
    "\n",
    "def accuracy(pred):\n",
    "    ens_acc = 100.0 * np.mean(np.argmax(pred, axis=1) == targ)\n",
    "    print(ens_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha1 = get_alpha(funcs, V)\n",
    "alpha2 = get_alpha(funcs2, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas1 = get_betas(funcs, V)\n",
    "betas2 =  get_betas(funcs2, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "W10 = list(model1.parameters())[0].data.cpu().numpy()\n",
    "W20 = list(model2.parameters())[0].data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "W11 = list(model1.parameters())[-2].data.cpu().numpy()\n",
    "W21 = list(model2.parameters())[-2].data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "W12 = list(model1.parameters())[-1].data.cpu().numpy()\n",
    "W22 = list(model2.parameters())[-1].data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wmodel1 = samples_per_layer(model1, bias=False)\n",
    "Wmodel2 = samples_per_layer(model2, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3072, 6144)\n",
      "(2000, 6144)\n",
      "(10, 2000)\n"
     ]
    }
   ],
   "source": [
    "Wmodel = []\n",
    "for i, (S1, S2) in enumerate(zip(Wmodel1, Wmodel2)):\n",
    "    if i==0:\n",
    "        print(S1.T.shape)\n",
    "        cntr = Connector(S1.T, S2.T)\n",
    "        S = cntr.arc_connect(t=0.5)[1].T\n",
    "    else:\n",
    "        print(S1.shape)\n",
    "        cntr = Connector(S1, S2)\n",
    "        S = cntr.arc_connect(t=0.5)[1]\n",
    "    Wmodel.append(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(Wmodel, architecture, bias=False, per_layer=True)\n",
    "funcs3 =  get_funcs(model, data='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train results {'nll': 1.2921134415817261, 'loss': 1.2921134415817261, 'accuracy': 56.298}\n",
      "test results {'nll': 1.6340929803848268, 'loss': 1.6340929803848268, 'accuracy': 42.44}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'nll': 1.2921134415817261, 'loss': 1.2921134415817261, 'accuracy': 56.298},\n",
       " {'nll': 1.6340929803848268, 'loss': 1.6340929803848268, 'accuracy': 42.44})"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda();\n",
    "model.eval();\n",
    "test_model(model, loaders, cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha3 = get_alpha(funcs3, V) \n",
    "betas3 =  get_betas(funcs3, V)\n",
    "# W31 = list(model.parameters())[-2].data.cpu().numpy()\n",
    "# W31 = list(model.parameters())[-2].data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.029999999999994\n"
     ]
    }
   ],
   "source": [
    "pred = np.maximum(funcs3 @ betas3.T @ alpha2.T @ W21.T, 0) @ W22.T\n",
    "accuracy(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.19\n"
     ]
    }
   ],
   "source": [
    "pred = np.maximum(funcs3 @ betas3.T @ alpha1.T @ W11.T, 0) @ W12.T\n",
    "accuracy(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.54\n"
     ]
    }
   ],
   "source": [
    "pred = np.maximum(funcs2 @ betas2.T @ (alpha1.T @ W11.T + alpha2.T @ W21.T)/2, 0) @ (W12.T+W22.T)/2\n",
    "accuracy(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.34\n",
      "60.34\n",
      "60.099999999999994\n",
      "60.050000000000004\n",
      "60.12\n"
     ]
    }
   ],
   "source": [
    "pred = np.maximum(funcs @ W11.T, 0) @ W12.T\n",
    "accuracy(pred)\n",
    "pred = np.maximum(funcs @ betas1.T @ alpha1.T @ W11.T, 0) @ W12.T\n",
    "accuracy(pred)\n",
    "pred = np.maximum(funcs2 @ betas2.T @ alpha2.T @ W21.T, 0) @ W22.T\n",
    "accuracy(pred)\n",
    "pred = np.maximum(funcs @ betas1.T @ alpha2.T @ W21.T, 0) @ W22.T\n",
    "accuracy(pred)\n",
    "pred = np.maximum(funcs2 @ betas2.T  @ alpha1.T @ W11.T, 0) @ W12.T\n",
    "accuracy(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = get_funcs(model1, data='test', layer=1)\n",
    "g2 = get_funcs(model2, data='test', layer=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6144, 2000)\n"
     ]
    }
   ],
   "source": [
    "Wh1 = alpha1.T @ W11.T\n",
    "Wh2 = alpha2.T @ W21.T\n",
    "cntr = Connector(Wh1.T, Wh2.T)\n",
    "Wh = cntr.arc_connect(t=0.5)[1].T\n",
    "print(Wh1.shape)\n",
    "\n",
    "g3 = np.maximum(funcs2 @ betas2.T @ Wh, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_init2, Sigma_init2, V_init2 = np.linalg.svd(g1.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000, 2000), (2000,), (10000, 10000))"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U_init2.shape, Sigma_init2.shape, V_init2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = 2000\n",
    "U2, Sigma2, V2 = U_init2[:, :comp], Sigma_init2[:comp], V_init2[:comp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha12 = get_alpha(g1, V2)\n",
    "alpha22 = get_alpha(g2, V2)\n",
    "\n",
    "betas12 = get_betas(g1, V2)\n",
    "betas22 =  get_betas(g2, V2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha32 = get_alpha(g3, V2) \n",
    "betas32 =  get_betas(g3, V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00974413,  0.01173222,  0.00887076, ...,  0.00287552,\n",
       "         0.00735211,  0.00917149],\n",
       "       [-0.00934512, -0.00041445, -0.00482961, ...,  0.00019445,\n",
       "         0.00409823,  0.00771557],\n",
       "       [ 0.00780636, -0.01256509, -0.00753748, ..., -0.00167393,\n",
       "        -0.00991292, -0.00814729],\n",
       "       ...,\n",
       "       [-0.00226622,  0.00241323, -0.00196166, ..., -0.00138159,\n",
       "         0.00022485,  0.00020743],\n",
       "       [ 0.01009552, -0.00078211, -0.00042527, ..., -0.00056638,\n",
       "        -0.00158174, -0.00494823],\n",
       "       [ 0.00178276, -0.00328206, -0.00023848, ...,  0.0019458 ,\n",
       "         0.00532567, -0.00387456]], dtype=float32)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01011109, -0.01019042,  0.00757564, ..., -0.00211355,\n",
       "         0.00237924, -0.00440493],\n",
       "       [ 0.01068594, -0.00065097, -0.01435278, ...,  0.00312119,\n",
       "        -0.00088184,  0.00192975],\n",
       "       [ 0.00805384, -0.00334248, -0.00803568, ...,  0.00328906,\n",
       "         0.00528805, -0.00202743],\n",
       "       ...,\n",
       "       [ 0.00340781,  0.00052418, -0.00194526, ...,  0.00181662,\n",
       "         0.00428702, -0.00453944],\n",
       "       [ 0.0067509 ,  0.00476765, -0.01002657, ..., -0.00612088,\n",
       "         0.00396887, -0.00070291],\n",
       "       [ 0.01001711,  0.00791248, -0.00736805, ...,  0.00261683,\n",
       "         0.00293513,  0.00477807]], dtype=float32)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g3 @ betas32.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00974413, -0.00934511,  0.00780636, ..., -0.00226623,\n",
       "         0.01009551,  0.00178275],\n",
       "       [ 0.01173222, -0.00041445, -0.01256509, ...,  0.00241323,\n",
       "        -0.00078211, -0.00328206],\n",
       "       [ 0.00887076, -0.00482961, -0.00753749, ..., -0.00196166,\n",
       "        -0.00042527, -0.00023847],\n",
       "       ...,\n",
       "       [ 0.00287552,  0.00019444, -0.00167394, ..., -0.0013816 ,\n",
       "        -0.00056638,  0.00194579],\n",
       "       [ 0.00735211,  0.00409823, -0.00991292, ...,  0.00022486,\n",
       "        -0.00158173,  0.00532567],\n",
       "       [ 0.00917149,  0.00771557, -0.0081473 , ...,  0.00020742,\n",
       "        -0.00494823, -0.00387455]], dtype=float32)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1 @ betas12.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0101224 , -0.00952203,  0.0061153 , ..., -0.00277059,\n",
       "         0.00187412,  0.00129607],\n",
       "       [ 0.01069099, -0.00068937, -0.01286153, ...,  0.00157149,\n",
       "        -0.00330083, -0.00549832],\n",
       "       [ 0.00870076, -0.00488605, -0.00746369, ...,  0.00711501,\n",
       "        -0.00533918,  0.00135434],\n",
       "       ...,\n",
       "       [ 0.00385828, -0.00038704, -0.00200862, ...,  0.00919093,\n",
       "         0.00178433, -0.00742358],\n",
       "       [ 0.00639355,  0.0043392 , -0.0106674 , ..., -0.00374491,\n",
       "        -0.00068105,  0.00098946],\n",
       "       [ 0.00950932,  0.00721175, -0.00737754, ...,  0.00190379,\n",
       "        -0.00362128,  0.00741634]], dtype=float32)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g2 @ betas22.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.13\n"
     ]
    }
   ],
   "source": [
    "pred = g3 @ betas32.T @ alpha12.T @ W12.T\n",
    "accuracy(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.440000000000005\n"
     ]
    }
   ],
   "source": [
    "pred = g3 @ betas32.T @ alpha22.T @ W22.T\n",
    "accuracy(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.13\n"
     ]
    }
   ],
   "source": [
    "pred = g3 @ betas32.T @ (alpha12.T @ W12.T + alpha22.T @ W22.T)/2\n",
    "accuracy(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.86\n"
     ]
    }
   ],
   "source": [
    "pred = g1 @ betas12.T @ (alpha12.T @ W12.T + alpha22.T @ W22.T)/2\n",
    "accuracy(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.34\n"
     ]
    }
   ],
   "source": [
    "pred = g1 @ betas12.T @ alpha12.T @ W12.T\n",
    "accuracy(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.95\n"
     ]
    }
   ],
   "source": [
    "pred = g2 @ betas22.T @ alpha12.T @ W12.T\n",
    "accuracy(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.4\n"
     ]
    }
   ],
   "source": [
    "pred = g2 @ betas22.T @ alpha22.T @ W22.T\n",
    "accuracy(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.699999999999996\n"
     ]
    }
   ],
   "source": [
    "pred = g1 @ betas12.T @ alpha22.T @ W22.T\n",
    "accuracy(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_svd(model, TSVD=None, data='train', N_comp=200, layer=0):\n",
    "    \n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    functions = []\n",
    "    targ = []\n",
    "    for X, y in loaders[data]:\n",
    "        functions.append(model(X.cuda(), N=layer))\n",
    "        targ.append(y)\n",
    "        \n",
    "    print('l', functions[0].shape)\n",
    "    targ = np.concatenate(targ)\n",
    "    funcs = np.concatenate([p.cpu().data.numpy() for p in functions])\n",
    "    \n",
    "    print(funcs.T[:1])\n",
    "    \n",
    "    if TSVD is None:\n",
    "        TSVD = TruncatedSVD(n_components=N_comp, n_iter=5, random_state=1)\n",
    "        TSVD.fit(funcs.T)\n",
    "    funcs_PCA = TSVD.transform(funcs.T).T\n",
    "    funcs_PCA_inv = TSVD.inverse_transform(funcs_PCA.T).T\n",
    "    functions_PCA = [torch.FloatTensor(funcs_PCA_inv[i*1024:(i+1)*1024]).cuda() for i in range(len(functions))]\n",
    "    \n",
    "    pred = []\n",
    "    for f in functions_PCA:\n",
    "        pred.append(model.last_layers(f, N=layer+1).cpu().data.numpy())\n",
    "    \n",
    "    pred = np.concatenate(pred)\n",
    "\n",
    "    ens_acc = 100.0 * np.mean(np.argmax(pred, axis=1) == targ)\n",
    "\n",
    "    return ens_acc, TSVD, funcs_PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_interpolation(model1, model2, funcs_PCA1, funcs_PCA2, TSVD=None, layer=0, t=0.5, func='arc_connect'):\n",
    "    \n",
    "    targ = []\n",
    "    functions = 0\n",
    "    for X, y in loaders['test']:\n",
    "        functions+=1\n",
    "        targ.append(y)\n",
    "    targ = np.concatenate(targ)\n",
    "    \n",
    "    model1.cuda()\n",
    "    model1.eval()\n",
    "    model2.cuda()\n",
    "    model2.eval()\n",
    "    \n",
    "    \n",
    "    print('funcs_PCA', funcs_PCA1.shape)\n",
    "    cntr = Connector(funcs_PCA1.T, funcs_PCA2.T)\n",
    "    method = getattr(cntr, 'arc_connect')\n",
    "    funcs_PCA = method(t=t)[1].T\n",
    "    funcs_PCA_inv = TSVD.inverse_transform(funcs_PCA.T).T\n",
    "    functions_PCA = [torch.FloatTensor(funcs_PCA_inv[i*1024:(i+1)*1024]).cuda() for i in range(functions)]\n",
    "    \n",
    "    pred = []\n",
    "    ll1 = list(model1.parameters())[-1].cpu().data.numpy()\n",
    "    ll2 = list(model2.parameters())[-1].cpu().data.numpy()\n",
    "    print('ll', ll1.shape)\n",
    "    cntr = Connector(ll1.T, ll2.T)\n",
    "    method = getattr(cntr, func)\n",
    "    ll = method(t=t)[1].T\n",
    "    ll = torch.FloatTensor(ll.T).cuda()\n",
    "    for f in functions_PCA:\n",
    "#         print('ll, f', ll.shape, f.shape)\n",
    "        p = f@ll\n",
    "#         print('p', p.shape)\n",
    "        pred.append(p.cpu().data.numpy())\n",
    "    \n",
    "    pred = np.concatenate(pred)\n",
    "\n",
    "    ens_acc = 100.0 * np.mean(np.argmax(pred, axis=1) == targ)\n",
    "\n",
    "    return ens_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l torch.Size([1024, 2000])\n",
      "[[0. 0. 0. ... 0. 0. 0.]]\n",
      "59.440000000000005\n"
     ]
    }
   ],
   "source": [
    "layer = 1\n",
    "acc, TSVD, funcs_PCA2 = accuracy_svd(model2, TSVD=None, data='test', N_comp=500, layer=layer)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "funcs_PCA (500, 2000)\n",
      "ll (10, 2000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "54.52"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_interpolation(model1, model2, funcs_PCA1, funcs_PCA2, TSVD=TSVD, layer=layer, \n",
    "                       t=0.5, func='arc_connect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l torch.Size([1024, 2000])\n",
      "[[0. 0. 0. ... 0. 0. 0.]]\n",
      "59.21999999999999\n"
     ]
    }
   ],
   "source": [
    "acc, _, funcs_PCA1 = accuracy_svd(model1, TSVD=TSVD, data='test', layer=layer)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l torch.Size([1024, 2000])\n",
      "[[0. 0. 0. ... 0. 0. 0.]]\n",
      "59.440000000000005\n"
     ]
    }
   ],
   "source": [
    "acc, _, _ = accuracy_svd(model2, TSVD=TSVD, data='test', layer=layer)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model1.cuda()\n",
    "functions = []\n",
    "targ = []\n",
    "for X, y in loaders['train']:\n",
    "    functions.append(model1(X.cuda(), N=0))\n",
    "    targ.append(y)\n",
    "targ = np.concatenate(targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcs = np.concatenate([p.cpu().data.numpy() for p in functions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 6144)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "funcs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(algorithm='randomized', n_components=100, n_iter=5,\n",
       "       random_state=1, tol=0.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# transPSA = PCA(n_components=2000, svd_solver='full', random_state=1)\n",
    "# U, Sigma, V = np.linalg.svd(funcs[:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcs_PCA = TSVD.transform(funcs.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcs_PCA.shape\n",
    "funcs_PCA_inv = TSVD.inverse_transform(funcs_PCA.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 6144)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "funcs_PCA_inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcs_PCA_inv = transPSA.inverse_transform(funcs_PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions_PCA = [torch.FloatTensor(funcs_PCA_inv[i*1024:(i+1)*1024]).cuda() for i in range(len(functions))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "for f in functions_PCA:\n",
    "    pred.append(model1.last_layers(f, N=1).cpu().data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.concatenate(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.912\n"
     ]
    }
   ],
   "source": [
    "ens_acc = 100.0 * np.mean(np.argmax(pred, axis=1) == targ)\n",
    "print(ens_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6144, 1024)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (6144,1024) and (50000,100) not aligned: 1024 (dim 1) != 50000 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-244f9377f853>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTSVD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTSVD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/all/anaconda/lib/python3.6/site-packages/sklearn/decomposition/truncated_svd.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \"\"\"\n\u001b[1;32m    209\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/all/anaconda/lib/python3.6/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (6144,1024) and (50000,100) not aligned: 1024 (dim 1) != 50000 (dim 0)"
     ]
    }
   ],
   "source": [
    "functions_test = []\n",
    "targ_test = []\n",
    "for X, y in loaders['test']:\n",
    "    functions_test.append(model1(X.cuda(), N=0))\n",
    "    targ_test.append(y)\n",
    "    \n",
    "functions_test = np.concatenate([p.cpu().data.numpy() for p in functions])\n",
    "targ_test = np.concatenate(targ_test)\n",
    "\n",
    " \n",
    "x = TSVD.transform(functions_test.cpu().data.numpy().T)\n",
    "x = TSVD.inverse_transform(x).T\n",
    "functions_PCA = [torch.FloatTensor(funcs_PCA_inv[i*1024:(i+1)*1024]).cuda() for i in range(len(functions))]\n",
    "\n",
    "y_hat = model2.last_layers(torch.FloatTensor(x).cuda(), N=1).cpu().data.numpy()\n",
    "pred_test.append(y_hat)\n",
    "targ_test.append(y)\n",
    "targ_test = np.concatenate(targ_test)\n",
    "pred_test = np.concatenate(pred_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.449999999999996\n"
     ]
    }
   ],
   "source": [
    "ens_acc = 100.0 * np.mean(np.argmax(pred_test, axis=1) == targ_test)\n",
    "print(ens_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train results {'nll': 0.4526240879917145, 'loss': 0.4526240879917145, 'accuracy': 84.736}\n",
      "test results {'nll': 1.2863960428237915, 'loss': 1.2863960428237915, 'accuracy': 60.34}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'nll': 0.4526240879917145, 'loss': 0.4526240879917145, 'accuracy': 84.736},\n",
       " {'nll': 1.2863960428237915, 'loss': 1.2863960428237915, 'accuracy': 60.34})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.cuda();\n",
    "model1.eval();\n",
    "test_model(model1, loaders, cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2.cuda();\n",
    "# model2.eval();\n",
    "# test_model(model2, loaders, cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def samples(model):\n",
    "    p = [list(model.parameters())[i].data.cpu().numpy() for i in range(len(list(model.parameters())))]\n",
    "    return p\n",
    "\n",
    "def samples_per_layer(model, bias=True):\n",
    "    p = samples(model)\n",
    "    if bias:\n",
    "        p = [np.hstack([p[i], p[i+1][:, None]]) for i in range(0, len(p), 2)]        \n",
    "    return p\n",
    "\n",
    "def samples_butterfly(model, bias=True):\n",
    "    if bias:\n",
    "        return None\n",
    "    else:   \n",
    "        p = samples_per_layer(model, bias=bias)\n",
    "        parameters = [np.hstack([p[i], p[i+1].T]) for i in range(0, len(p), 2)]\n",
    "    return parameters\n",
    "\n",
    "def get_model(W, architecture, bias=False, per_layer=True):\n",
    "    model_sampled = architecture.base(num_classes=10, **architecture.kwargs)\n",
    "    model_samples = np.array(W)  \n",
    "\n",
    "    if per_layer:\n",
    "        for parameter, w in zip(model_sampled.parameters(), W):\n",
    "            parameter.data.copy_(torch.from_numpy(w))\n",
    "    else:\n",
    "        for i, parameter in enumerate(model_sampled.parameters()):\n",
    "            w = W[i//2]\n",
    "            if i % 2 == 0:\n",
    "                offset = 0\n",
    "            N = parameter.data.shape[1]\n",
    "            w_part = w[:, offset:offset+N]\n",
    "            offset = N\n",
    "            if i % 2 == 0:\n",
    "                parameter.data.copy_(torch.from_numpy(w_part))\n",
    "            else:\n",
    "                parameter.data.copy_(torch.from_numpy(w_part.T))\n",
    "            \n",
    "\n",
    "    return model_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(x1, x2, E12, E22_inv, second=False):\n",
    "    y1 = x1 - E12 @ E22_inv @ x2\n",
    "    return y1.T\n",
    "   \n",
    "def inv_transform(y1, y2, E12, E22_inv, second=False):\n",
    "    x1 = y1 + E12 @ E22_inv @ y2\n",
    "    return x1.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters1 = samples_per_layer(model1, bias=False)\n",
    "parameters2 = samples_per_layer(model2, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_simple(W1, W2, lines=True, func='arc_connect'):\n",
    "    \n",
    "    if lines:    \n",
    "        print('W1', W1.shape)\n",
    "        cntr = Connector(W1, W2)\n",
    "        f = getattr(cntr, func)\n",
    "        p_res = f()[1]\n",
    "    else:\n",
    "        print('W1', W1.T.shape)\n",
    "        cntr = Connector(W1.T, W2.T)\n",
    "        f = getattr(cntr, func)\n",
    "        p_res = f()[1].T\n",
    "        \n",
    "    return p_res\n",
    "\n",
    "def connect_cov(W1, W2, P1, P2, P_f, lines=True, inverse=False,  func='arc_connect'):\n",
    "        \n",
    "        if inverse:\n",
    "            P1, W1 = P1.T, W1.T\n",
    "            P2, W2 = P2.T, W2.T\n",
    " \n",
    "        p1 = np.hstack([P1, W1.T])\n",
    "        p2 = np.hstack([P2, W2.T])\n",
    "        len_x2 = len(W1)\n",
    "        p = np.concatenate([p1,p2])\n",
    "        \n",
    "        print('p', p.shape)\n",
    "        print('len', len_x2)\n",
    "        \n",
    "        mu1 = p.mean(0)[:-len_x2]\n",
    "        mu2 = p.mean(0)[len_x2:]\n",
    "\n",
    "        print('p', p.shape)\n",
    "\n",
    "        p = p - p.mean(0)    \n",
    "        cov = p.T @ p\n",
    "\n",
    "        E12 = cov[:-len_x2, -len_x2:]\n",
    "        E22 = cov[-len_x2:, -len_x2:]\n",
    "        E22_inv = np.linalg.inv(E22)\n",
    "\n",
    "        \n",
    "        print(1, P1.T.shape, W1.shape)\n",
    "        W1 = transform(P1.T, W1, E12,  E22_inv)\n",
    "        W2 = transform(P2.T, W2, E12,  E22_inv)\n",
    "        print('W1', W1.shape)\n",
    "    \n",
    "        p_res = connect_simple(W1, W2, lines=lines, func=func)\n",
    "        \n",
    "        print(2, p_res.T.shape, P_f.shape)\n",
    "        p_res_tr = inv_transform(p_res.T, P_f, E12,  E22_inv)\n",
    "        \n",
    "        return p_res_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters_res_tr = []\n",
    "# parameters_res = []\n",
    "\n",
    "# print(3)\n",
    "# p_res = connect_simple(parameters1[0], parameters2[0], lines=False)\n",
    "# parameters_res_tr.append(p_res)\n",
    "\n",
    "\n",
    "# print(2)\n",
    "# p_res = connect_simple(parameters1[-2], parameters2[-2], lines=False)\n",
    "# parameters_res_tr.append(p_res)\n",
    "\n",
    "\n",
    "# print(1)\n",
    "# print('parameters', parameters2[-1].shape)\n",
    "# # p_res = connect_simple(parameters1[-1], parameters2[-1], lines=True)\n",
    "# p_res = connect_cov(parameters1[1], parameters2[1], parameters1[-1],  parameters2[-1], parameters_res_tr[-1].T, \n",
    "#                     lines=False, inverse=True).T\n",
    "\n",
    "\n",
    "# parameters_res_tr.append(p_res)\n",
    "    \n",
    "# model = get_model(parameters_res_tr, architecture, per_layer=True)\n",
    "# model.cuda();\n",
    "# model.eval();\n",
    "# test_model(model, loaders, cuda=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6144, 3072)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters1[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_mean = []\n",
    "for i, (p1, p2) in enumerate(zip(parameters1, parameters2)):\n",
    "    p = np.concatenate([p1.T,p2.T])\n",
    "#     print(p.shape)\n",
    "    mean = p.mean(0)\n",
    "    p_mean.append(mean)\n",
    "#     print(p1.T.shape, mean.shape)\n",
    "    parameters1[i] = (p1.T - mean).T\n",
    "    parameters2[i] = (p2.T - mean).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12288, 3072)\n",
      "(4000, 6144)\n",
      "(20, 2000)\n"
     ]
    }
   ],
   "source": [
    "p_mean = []\n",
    "for i, (p1, p2) in enumerate(zip(parameters1, parameters2)):\n",
    "    p = np.concatenate([p1,p2])\n",
    "    print(p.shape)\n",
    "    mean = p.mean(0)\n",
    "    p_mean.append(mean)\n",
    "    parameters1[i] = p1 - mean\n",
    "    parameters2[i] = p2 - mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(parameters1[0][:, 1], bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters1[0] -= parameters1[0].mean(0)\n",
    "# parameters1[0][:, 1].mean(), parameters1[0].T[:, 1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.006478533, -3.176718e-05)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters1[0][:, 1].mean(), parameters1[0].T[:, 1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 2000)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack([ parameters2[-1],  parameters1[-1]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "parameters (10, 2000)\n",
      "W1 (2000, 10)\n",
      "2\n",
      "parameters (2000, 6144)\n",
      "W1 (2000, 6144)\n",
      "3\n",
      "parameters (6144, 3072)\n",
      "W1 (3072, 6144)\n",
      "train results {'nll': 1.271210627593994, 'loss': 1.271210627593994, 'accuracy': 57.922}\n",
      "test results {'nll': 1.6456598905563355, 'loss': 1.6456598905563355, 'accuracy': 42.36}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'nll': 1.271210627593994, 'loss': 1.271210627593994, 'accuracy': 57.922},\n",
       " {'nll': 1.6456598905563355, 'loss': 1.6456598905563355, 'accuracy': 42.36})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_res_tr = []\n",
    "parameters_res = []\n",
    "func = 'arc_connect'\n",
    "\n",
    "print(1)\n",
    "print('parameters', parameters2[-1].shape)\n",
    "p_res = connect_simple(parameters1[-1], parameters2[-1], lines=False, func=func)\n",
    "parameters_res_tr.insert(0, p_res)\n",
    "parameters_res.insert(0, p_res)\n",
    "\n",
    "print(2)\n",
    "print('parameters', parameters2[-2].shape)\n",
    "p_res = connect_simple(parameters1[-2], parameters2[-2], lines=True, func=func)\n",
    "# p_res = connect_cov(parameters1[-1], parameters2[-1], parameters1[-2],  parameters2[-2], parameters_res[0], \n",
    "#                     lines=False, func=func)\n",
    "parameters_res_tr.insert(0, p_res)\n",
    "parameters_res.insert(0, p_res)\n",
    "\n",
    "print(3)\n",
    "print('parameters', parameters2[0].shape)\n",
    "p_res = connect_simple(parameters1[0], parameters2[0], lines=False, func=func)\n",
    "# p_res = connect_cov(parameters1[1], parameters2[1], parameters1[0],  parameters2[0], parameters_res[0], \n",
    "#                     lines=False, func=func)\n",
    "\n",
    "\n",
    "parameters_res_tr.insert(0, p_res)\n",
    "parameters_res.insert(0, p_res)\n",
    "\n",
    "for i, (p, m) in enumerate(zip(parameters_res_tr, p_mean)):\n",
    "    parameters_res_tr[i] = (p.T + m).T\n",
    "\n",
    "    \n",
    "model = get_model(parameters_res_tr, architecture, per_layer=True)\n",
    "model.cuda();\n",
    "model.eval();\n",
    "test_model(model, loaders, cuda=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "parameters (6144, 3072)\n",
      "train results {'nll': 1.3164503594589234, 'loss': 1.3164503594589234, 'accuracy': 57.19}\n",
      "test results {'nll': 1.6831079917907714, 'loss': 1.6831079917907714, 'accuracy': 41.08}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'nll': 1.3164503594589234, 'loss': 1.3164503594589234, 'accuracy': 57.19},\n",
       " {'nll': 1.6831079917907714, 'loss': 1.6831079917907714, 'accuracy': 41.08})"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_res_tr = []\n",
    "parameters_res = []\n",
    "func = 'arc_connect'\n",
    "\n",
    "\n",
    "print(1)\n",
    "p_res = connect_simple(parameters1[-1], parameters2[-1], lines=False, func=func)\n",
    "parameters_res_tr.insert(0, p_res)\n",
    "parameters_res.insert(0, p_res)\n",
    "\n",
    "print(2)\n",
    "p_res = connect_simple(parameters1[-2], parameters2[-2], lines=False, func=func)\n",
    "# p_res = connect_cov(parameters1[-1], parameters2[-1], parameters1[-2],  parameters2[-2], parameters_res[0], \n",
    "#                     lines=False, func=func)\n",
    "parameters_res_tr.insert(0, p_res)\n",
    "parameters_res.insert(0, p_res)\n",
    "\n",
    "print(3)\n",
    "p_res = connect_simple(parameters1[0], parameters2[0], lines=False, func=func)\n",
    "# p_res = connect_cov(parameters1[1], parameters2[1], parameters1[0],  parameters2[0], parameters_res[0], \n",
    "#                     lines=False, func=func)\n",
    "print('parameters', parameters2[0].shape)\n",
    "\n",
    "parameters_res_tr.insert(0, p_res)\n",
    "parameters_res.insert(0, p_res)\n",
    "\n",
    "# for i, (p, m) in enumerate(zip(parameters_res_tr, p_mean)):\n",
    "#     parameters_res_tr[i] = p + m\n",
    "\n",
    "    \n",
    "model = get_model(parameters_res_tr, architecture, per_layer=True)\n",
    "model.cuda();\n",
    "model.eval();\n",
    "test_model(model, loaders, cuda=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters1 = samples_butterfly(model1, bias=False)\n",
    "# parameters2 = samples_butterfly(model2, bias=False)\n",
    "# for func in ['lin_connect', 'arc_connect', 'arc_connect_PCA', 'inverse_connect_PCA', \n",
    "#              'third_cumulant_connect']:\n",
    "#     parameters_res = []\n",
    "#     print(func)\n",
    "#     for p1, p2 in zip(parameters1, parameters2):\n",
    "#         cntr = Connector(p1, p2)\n",
    "#         f = getattr(cntr, func)\n",
    "#         if 'PCA' in func:\n",
    "#             res = f(K=300)[1]\n",
    "#         elif 'third_cumulant' in func:\n",
    "#             res = f(K=100)[1] \n",
    "#         else:\n",
    "#             res = f()[1]\n",
    "#         parameters_res.append(res)\n",
    "\n",
    "#     model = get_model(parameters_res, architecture, per_layer=False)\n",
    "#     model.cuda();\n",
    "#     model.eval();\n",
    "#     test_model(model, loaders, cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lin_connect\n",
      "train results {'nll': 1.9955093453598023, 'loss': 1.9955093453598023, 'accuracy': 51.474}\n",
      "test results {'nll': 2.162593546295166, 'loss': 2.162593546295166, 'accuracy': 29.76}\n",
      "arc_connect\n",
      "train results {'nll': 1.3757157013320922, 'loss': 1.3757157013320922, 'accuracy': 50.706}\n",
      "test results {'nll': 1.6448731899261475, 'loss': 1.6448731899261475, 'accuracy': 42.03}\n",
      "arc_connect_PCA\n",
      "train results {'nll': 1.5449913298034668, 'loss': 1.5449913298034668, 'accuracy': 42.81}\n",
      "test results {'nll': 1.722438893699646, 'loss': 1.722438893699646, 'accuracy': 36.14}\n"
     ]
    }
   ],
   "source": [
    "parameters1 = samples_per_layer(model1, bias=False)\n",
    "parameters2 = samples_per_layer(model2, bias=False)\n",
    "for func in ['lin_connect', 'arc_connect', 'arc_connect_PCA']:\n",
    "    parameters_res = []\n",
    "    print(func)\n",
    "    for p1, p2 in zip(parameters1, parameters2):\n",
    "        cntr = Connector(p1, p2)\n",
    "        f = getattr(cntr, func)\n",
    "        if 'PCA' in func:\n",
    "            K = min(300, p1.shape[0], p1.shape[1])\n",
    "            res = f(K=K)[1]\n",
    "        elif 'third_cumulant' in func:\n",
    "            K = min(100, p1.shape[0], p1.shape[1])\n",
    "            res = f(K=K)[1] \n",
    "        else:\n",
    "            res = f()[1]\n",
    "        parameters_res.append(res)\n",
    "\n",
    "    model = get_model(parameters_res, architecture, per_layer=True)\n",
    "    model.cuda();\n",
    "    model.eval();\n",
    "    test_model(model, loaders, cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arc_connect\n",
      "train results {'nll': 1.3138795108032226, 'loss': 1.3138795108032226, 'accuracy': 57.49}\n",
      "test results {'nll': 1.6831079917907714, 'loss': 1.6831079917907714, 'accuracy': 41.08}\n",
      "arc_connect_PCA\n",
      "train results {'nll': 1.3796758843994141, 'loss': 1.3796758843994141, 'accuracy': 55.522}\n",
      "test results {'nll': 1.7231661840438843, 'loss': 1.7231661840438843, 'accuracy': 39.77}\n"
     ]
    }
   ],
   "source": [
    "# columns\n",
    "parameters1 = samples_per_layer(model1, bias=False)\n",
    "parameters2 = samples_per_layer(model2, bias=False)\n",
    "for func in ['arc_connect', 'arc_connect_PCA']:\n",
    "    parameters_res = []\n",
    "    print(func)\n",
    "    for p1, p2 in zip(parameters1, parameters2):\n",
    "        cntr = Connector(p1.T, p2.T)\n",
    "        f = getattr(cntr, func)\n",
    "        if 'PCA' in func:\n",
    "            K = min(300, p1.shape[0], p1.shape[1])\n",
    "            res = f(K=K)[1]\n",
    "        elif 'third_cumulant' in func:\n",
    "            K = min(100, p1.shape[0], p1.shape[1])\n",
    "            res = f(K=K)[1] \n",
    "        else:\n",
    "            res = f()[1]\n",
    "        parameters_res.append(res.T)\n",
    "\n",
    "    model = get_model(parameters_res, architecture, per_layer=True)\n",
    "    model.cuda();\n",
    "    model.eval();\n",
    "    test_model(model, loaders, cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arc_connect\n",
      "last\n",
      "train results {'nll': 1.402382646522522, 'loss': 1.402382646522522, 'accuracy': 49.57}\n",
      "test results {'nll': 1.6654330642700195, 'loss': 1.6654330642700195, 'accuracy': 41.36}\n",
      "arc_connect_PCA\n",
      "last\n",
      "train results {'nll': 1.4344119925308227, 'loss': 1.4344119925308227, 'accuracy': 48.944}\n",
      "test results {'nll': 1.6590761445999145, 'loss': 1.6590761445999145, 'accuracy': 41.85}\n"
     ]
    }
   ],
   "source": [
    "# one last column and lines\n",
    "parameters1 = samples_per_layer(model1, bias=False)\n",
    "parameters2 = samples_per_layer(model2, bias=False)\n",
    "for func in ['arc_connect', 'arc_connect_PCA']:\n",
    "    parameters_res = []\n",
    "    print(func)\n",
    "    for ind, (p1, p2) in enumerate(zip(parameters1, parameters2)):\n",
    "        if ind==len(parameters1)-1:\n",
    "            print('last')\n",
    "            p1, p2 = p1.T, p2.T\n",
    "        cntr = Connector(p1, p2)\n",
    "        f = getattr(cntr, func)\n",
    "        if 'PCA' in func:\n",
    "            K = min(300, p1.shape[0], p1.shape[1])\n",
    "            res = f(K=K)[1]\n",
    "        elif 'third_cumulant' in func:\n",
    "            K = min(100, p1.shape[0], p1.shape[1])\n",
    "            res = f(K=K)[1] \n",
    "        else:\n",
    "            res = f()[1]\n",
    "            \n",
    "        if ind==len(parameters1)-1:\n",
    "            res = res.T\n",
    "        parameters_res.append(res)\n",
    "\n",
    "    model = get_model(parameters_res, architecture, per_layer=True)\n",
    "    model.cuda();\n",
    "    model.eval();\n",
    "    test_model(model, loaders, cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arc_connect\n",
      "last\n",
      "last\n",
      "train results {'nll': 1.3678412181472779, 'loss': 1.3678412181472779, 'accuracy': 53.644}\n",
      "test results {'nll': 1.6921545532226563, 'loss': 1.6921545532226563, 'accuracy': 40.73}\n",
      "arc_connect_PCA\n",
      "last\n",
      "last\n",
      "train results {'nll': 1.4357195449066162, 'loss': 1.4357195449066162, 'accuracy': 51.714}\n",
      "test results {'nll': 1.7344378902435302, 'loss': 1.7344378902435302, 'accuracy': 39.71}\n"
     ]
    }
   ],
   "source": [
    "# all columns except first lines\n",
    "parameters1 = samples_per_layer(model1, bias=False)\n",
    "parameters2 = samples_per_layer(model2, bias=False)\n",
    "for func in ['arc_connect', 'arc_connect_PCA']:\n",
    "    parameters_res = []\n",
    "    print(func)\n",
    "    for ind, (p1, p2) in enumerate(zip(parameters1, parameters2)):\n",
    "        if ind!=0:\n",
    "            print('last')\n",
    "            p1, p2 = p1.T, p2.T\n",
    "        cntr = Connector(p1, p2)\n",
    "        f = getattr(cntr, func)\n",
    "        if 'PCA' in func:\n",
    "            K = min(300, p1.shape[0], p1.shape[1])\n",
    "            res = f(K=K)[1]\n",
    "        elif 'third_cumulant' in func:\n",
    "            K = min(100, p1.shape[0], p1.shape[1])\n",
    "            res = f(K=K)[1] \n",
    "        else:\n",
    "            res = f()[1]\n",
    "            \n",
    "        if ind!=0:\n",
    "            res = res.T\n",
    "        parameters_res.append(res)\n",
    "\n",
    "    model = get_model(parameters_res, architecture, per_layer=True)\n",
    "    model.cuda();\n",
    "    model.eval();\n",
    "    test_model(model, loaders, cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
